{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Found 6883 images belonging to 1 classes.\n",
      "Found 6883 images belonging to 1 classes.\n",
      "\n",
      "Validation\n",
      "Found 764 images belonging to 1 classes.\n",
      "Found 764 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "bs = 8\n",
    "img_w = 256\n",
    "img_h = 256\n",
    "validation_split = 0.1\n",
    "dataset_dir = os.path.join(cwd, \"Segmentation_Dataset\")\n",
    "\n",
    "# Image and masks data generators\n",
    "image_data_gen = ImageDataGenerator(rotation_range = 90,\n",
    "                                    width_shift_range = 10,\n",
    "                                    height_shift_range = 10,\n",
    "                                    zoom_range = 0.3,\n",
    "                                    horizontal_flip = True,\n",
    "                                    vertical_flip = True,\n",
    "                                    fill_mode = 'constant',\n",
    "                                    cval = 0,\n",
    "                                    rescale = 1./255,\n",
    "                                    validation_split = validation_split)\n",
    "mask_data_gen = ImageDataGenerator(rotation_range = 90,\n",
    "                                    width_shift_range = 10,\n",
    "                                    height_shift_range = 10,\n",
    "                                    zoom_range = 0.3,\n",
    "                                    horizontal_flip = True,\n",
    "                                    vertical_flip = True,\n",
    "                                    fill_mode = 'constant',\n",
    "                                    cval = 0,\n",
    "                                    validation_split = validation_split)\n",
    "\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, \"training\")\n",
    "train_img_dir = os.path.join(train_dir, \"images\")\n",
    "train_mask_dir = os.path.join(train_dir, \"masks\")\n",
    "\n",
    "# train generators\n",
    "print(\"Training\")\n",
    "train_img_gen = image_data_gen.flow_from_directory(train_img_dir,\n",
    "                                                   target_size = (img_h, img_w),\n",
    "                                                   batch_size = bs,\n",
    "                                                   class_mode = None,\n",
    "                                                   shuffle = True,\n",
    "                                                   interpolation = 'bilinear',\n",
    "                                                   seed = SEED,\n",
    "                                                   subset = 'training')\n",
    "train_mask_gen = image_data_gen.flow_from_directory(train_mask_dir,\n",
    "                                                   target_size = (img_h, img_w),\n",
    "                                                   batch_size = bs,\n",
    "                                                   class_mode = None,\n",
    "                                                   shuffle = True,\n",
    "                                                   interpolation = 'bilinear',\n",
    "                                                   color_mode = 'grayscale',\n",
    "                                                   seed = SEED,\n",
    "                                                   subset = 'training')\n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "\n",
    "# validation generators\n",
    "print(\"\\nValidation\")\n",
    "validation_img_gen = image_data_gen.flow_from_directory(train_img_dir,\n",
    "                                                   target_size = (img_h, img_w),\n",
    "                                                   batch_size = bs,\n",
    "                                                   class_mode = None,\n",
    "                                                   shuffle = True,\n",
    "                                                   interpolation = 'bilinear',\n",
    "                                                   seed = SEED,\n",
    "                                                   subset = 'validation')\n",
    "validation_mask_gen = image_data_gen.flow_from_directory(train_mask_dir,\n",
    "                                                   target_size = (img_h, img_w),\n",
    "                                                   batch_size = bs,\n",
    "                                                   class_mode = None,\n",
    "                                                   shuffle = True,\n",
    "                                                   interpolation = 'bilinear',\n",
    "                                                   color_mode = 'grayscale',\n",
    "                                                   seed = SEED,\n",
    "                                                   subset = 'validation')\n",
    "validation_gen = zip(validation_img_gen, validation_mask_gen)\n",
    "\n",
    "# datasets\n",
    "\n",
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(y_, tf.int32)\n",
    "    return x_, y_\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                              output_types = (tf.float32, tf.float32),\n",
    "                                              output_shapes = ([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "train_dataset = train_dataset.map(prepare_target).repeat()\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_generator(lambda: validation_gen,\n",
    "                                              output_types = (tf.float32, tf.float32),\n",
    "                                              output_shapes = ([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "validation_dataset = validation_dataset.map(prepare_target).repeat()\n",
    "\n",
    "# write filenames to JSON file\n",
    "\n",
    "filenames = {\n",
    "    \"training\" : {},\n",
    "    \"validation\" : {}\n",
    "}\n",
    "\n",
    "filenames[\"training\"] = [fn.replace(\"img/\",\"\") for fn in train_img_gen.filenames]\n",
    "filenames[\"validation\"] = [fn.replace(\"img/\",\"\") for fn in validation_img_gen.filenames]\n",
    "\n",
    "\n",
    "\n",
    "with open('dataset_split.json', 'w') as file:\n",
    "    json.dump(filenames, file, indent=4)\n",
    "\n",
    "    \n",
    "# TODO: load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 [datascience]",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
