{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "bs = 8\n",
    "img_w = 256\n",
    "img_h = 256\n",
    "\n",
    "classes = [\n",
    "    'owl',              # 0\n",
    "    'galaxy',           # 1\n",
    "    'lightning',        # 2\n",
    "    'wine-bottle',      # 3\n",
    "    't-shirt',          # 4\n",
    "    'waterfall',        # 5\n",
    "    'sword',            # 6\n",
    "    'school-bus',       # 7\n",
    "    'calculator',       # 8\n",
    "    'sheet-music',      # 9\n",
    "    'airplanes',        # 10\n",
    "    'lightbulb',        # 11\n",
    "    'skyscraper',       # 12\n",
    "    'mountain-bike',    # 13\n",
    "    'fireworks',        # 14\n",
    "    'computer-monitor', # 15\n",
    "    'bear',             # 16\n",
    "    'grand-piano',      # 17\n",
    "    'kangaroo',         # 18\n",
    "    'laptop'            # 19\n",
    "]\n",
    "\n",
    "data_gen = ImageDataGenerator(rotation_range = 10,\n",
    "                              width_shift_range = 10,\n",
    "                              height_shift_range = 10,\n",
    "                              zoom_range = 0.3,\n",
    "                              horizontal_flip = True,\n",
    "                              vertical_flip = True,\n",
    "                              rescale = 1./255, \n",
    "                              validation_split = 0.1)\n",
    "\n",
    "training_dir = os.path.join(cwd, \"Classification_Dataset\", \"training\")\n",
    "training_generator = data_gen.flow_from_directory(training_dir,\n",
    "                                        batch_size = bs,\n",
    "                                        classes = classes,\n",
    "                                        class_mode = 'categorical',\n",
    "                                        shuffle = True,\n",
    "                                        seed = SEED,\n",
    "                                        subset = 'training')\n",
    "validation_generator = data_gen.flow_from_directory(training_dir,\n",
    "                                        batch_size = bs,\n",
    "                                        classes = classes,\n",
    "                                        class_mode = 'categorical',\n",
    "                                        shuffle = True,\n",
    "                                        seed = SEED,\n",
    "                                        subset = 'validation')\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_generator(lambda: training_generator,\n",
    "                                              output_types = (tf.float32, tf.float32),\n",
    "                                              output_shapes = ([None, img_w, img_h, 3], [None, len(classes)]))\n",
    "validation_dataset = tf.data.Dataset.from_generator(lambda: validation_generator,\n",
    "                                              output_types = (tf.float32, tf.float32),\n",
    "                                              output_shapes = ([None, img_w, img_h, 3], [None, len(classes)]))\n",
    "\n",
    "training_dataset = training_dataset.repeat()\n",
    "validation_dataset = validation_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, conv_depth, start_num_filters, kernel_size, pool_size, fc_units, num_classes):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(conv_depth):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(filters = start_num_filters,\n",
    "                             kernel_size = kernel_size,\n",
    "                             strides = (1, 1),\n",
    "                             padding = 'same',\n",
    "                             activation = 'relu',\n",
    "                             input_shape = input_shape))\n",
    "        else:\n",
    "            model.add(Conv2D(filters = start_num_filters,\n",
    "                             kernel_size = kernel_size,\n",
    "                             strides = (1, 1),\n",
    "                             padding = 'same',\n",
    "                             activation = 'relu'))\n",
    "            \n",
    "        model.add(MaxPool2D(pool_size = pool_size))\n",
    "        start_num_filters *= 2\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for i in range(len(fc_units)):\n",
    "        model.add(Dense(units = fc_units[i], activation = 'relu'))\n",
    "    \n",
    "    model.add(Dense(units = num_classes, activation = 'softmax'))\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, model_name):\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # General experiments folder\n",
    "    exps_dir = os.path.join(cwd, 'classification_experiments')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "    \n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    \n",
    "    # This experiment folder\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "    \n",
    "    # Checpoints folder\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    \n",
    "    # Checkpoints callback\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       save_best_only=True, \n",
    "                                                       monitor='val_loss', \n",
    "                                                       mode = 'min')\n",
    "    \n",
    "    # Tensorboard folder\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "    \n",
    "    # Tensorboard callback\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                                 profile_batch=0,\n",
    "                                                 histogram_freq=1)  # if 1 shows weights histograms\n",
    "    \n",
    "    # Early stopping callback\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                   patience=10,\n",
    "                                                   mode = 'min')\n",
    "    \n",
    "    callbacks= [ckpt_callback, tb_callback, es_callback]\n",
    "    \n",
    "    model.fit(x=training_dataset,\n",
    "              epochs=100,\n",
    "              steps_per_epoch=len(training_generator),\n",
    "              validation_data=validation_dataset,\n",
    "              validation_steps=len(validation_generator), \n",
    "              callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_depth = 5\n",
    "start_num_filters = 8\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [512]\n",
    "num_classes = len(classes)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "fit_model(model = model, model_name = \"CNN_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 [datascience]",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
