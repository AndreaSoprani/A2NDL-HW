{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I started from the model seen in class and explored the hyperparameters space manually to find the direction in which the model could give better results.\n",
    "\n",
    "In the end I found that the only approach that resulted in a better performance was increasing the number of filters of the convolutional layers (only that model is uncommented).\n",
    "\n",
    "The model building and training are encapsulated in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section all the datasets are loaded and the \"dataset_split.json\" file is written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Found 1406 images belonging to 20 classes.\n",
      "\n",
      "Validation\n",
      "Found 148 images belonging to 20 classes.\n",
      "\n",
      "To predict\n",
      "Found 500 images.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "bs = 8\n",
    "img_w = 256\n",
    "img_h = 256\n",
    "validation_split = 0.1\n",
    "\n",
    "classes = [\n",
    "    'owl',              # 0\n",
    "    'galaxy',           # 1\n",
    "    'lightning',        # 2\n",
    "    'wine-bottle',      # 3\n",
    "    't-shirt',          # 4\n",
    "    'waterfall',        # 5\n",
    "    'sword',            # 6\n",
    "    'school-bus',       # 7\n",
    "    'calculator',       # 8\n",
    "    'sheet-music',      # 9\n",
    "    'airplanes',        # 10\n",
    "    'lightbulb',        # 11\n",
    "    'skyscraper',       # 12\n",
    "    'mountain-bike',    # 13\n",
    "    'fireworks',        # 14\n",
    "    'computer-monitor', # 15\n",
    "    'bear',             # 16\n",
    "    'grand-piano',      # 17\n",
    "    'kangaroo',         # 18\n",
    "    'laptop'            # 19\n",
    "]\n",
    "\n",
    "# LOAD TRAINING AND VALIDATION SETS\n",
    "\n",
    "data_gen = ImageDataGenerator(rotation_range = 10,\n",
    "                              width_shift_range = 10,\n",
    "                              height_shift_range = 10,\n",
    "                              zoom_range = 0.3,\n",
    "                              horizontal_flip = True,\n",
    "                              vertical_flip = True,\n",
    "                              rescale = 1./255, \n",
    "                              validation_split = validation_split)\n",
    "\n",
    "training_dir = os.path.join(cwd, \"Classification_Dataset\", \"training\")\n",
    "\n",
    "print(\"Training\")\n",
    "\n",
    "training_generator = data_gen.flow_from_directory(training_dir,\n",
    "                                        batch_size = bs,\n",
    "                                        classes = classes,\n",
    "                                        class_mode = 'categorical',\n",
    "                                        shuffle = True,\n",
    "                                        seed = SEED,\n",
    "                                        subset = 'training')\n",
    "\n",
    "print(\"\\nValidation\")\n",
    "\n",
    "validation_generator = data_gen.flow_from_directory(training_dir,\n",
    "                                        batch_size = bs,\n",
    "                                        classes = classes,\n",
    "                                        class_mode = 'categorical',\n",
    "                                        shuffle = True,\n",
    "                                        seed = SEED,\n",
    "                                        subset = 'validation')\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_generator(lambda: training_generator,\n",
    "                                              output_types = (tf.float32, tf.float32),\n",
    "                                              output_shapes = ([None, img_w, img_h, 3], [None, len(classes)]))\n",
    "validation_dataset = tf.data.Dataset.from_generator(lambda: validation_generator,\n",
    "                                              output_types = (tf.float32, tf.float32),\n",
    "                                              output_shapes = ([None, img_w, img_h, 3], [None, len(classes)]))\n",
    "\n",
    "training_dataset = training_dataset.repeat()\n",
    "validation_dataset = validation_dataset.repeat()\n",
    "\n",
    "# WRITE FILENAMES TO JSON FILE\n",
    "\n",
    "filenames = {\n",
    "    \"training\" : {},\n",
    "    \"validation\" : {}\n",
    "}\n",
    "\n",
    "for c in classes:\n",
    "    filenames[\"training\"][c] = []\n",
    "    filenames[\"validation\"][c] = []\n",
    "    \n",
    "    for fn in training_generator.filenames:\n",
    "        if c in fn:\n",
    "            filenames[\"training\"][c].append(fn.replace(c + \"/\", \"\"))\n",
    "    \n",
    "    for fn in validation_generator.filenames:\n",
    "        if c in fn:\n",
    "            filenames[\"validation\"][c].append(fn.replace(c + \"/\", \"\"))\n",
    "\n",
    "with open('dataset_split.json', 'w') as file:\n",
    "    json.dump(filenames, file, indent=4)\n",
    "    \n",
    "\n",
    "# LOAD TEST SET filenames\n",
    "\n",
    "print(\"\\nTo predict\")\n",
    "\n",
    "test_dir = os.path.join(cwd, \"Classification_Dataset\", \"test\")\n",
    "test_filenames = next(os.walk(test_dir))[2]\n",
    "test_filenames = list(filter(lambda fn: fn[-4:] == '.jpg', test_filenames))\n",
    "\n",
    "print(\"Found \" + str(len(test_filenames)) + \" images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building, fitting and predicting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions are used to build and train models and to predict the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, \n",
    "                conv_depth, start_num_filters, kernel_size, pool_size, \n",
    "                fc_units, num_classes, kernel_regularizer = None, dropout = None):\n",
    "    \"\"\"\n",
    "    This function is used to build automatically the model given some hyperparameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape: tuple of ints\n",
    "        the input_shape to be fed to the first layer of the model.\n",
    "    conv_depth: int\n",
    "        the number of convolutional blocks used (convolution + activation + pooling).\n",
    "    start_num_filters: int\n",
    "        the number of convolutional filters used in the first convolutional layer, it's multiplied by two in every subsequent layer.\n",
    "    kernel_size: pair of ints\n",
    "        the size of the kernels of the convolutional layers.\n",
    "    pool_size: pair of ints\n",
    "        the pool size for the pooling layers.\n",
    "    fc_units: list of ints\n",
    "        number of neurons in each hidden layer, the number of hidden layers is given by the length of this list.\n",
    "    num_classes: int\n",
    "        number of outputs.\n",
    "    kernel_regularizer: regularizer, optional\n",
    "        regularizer used in the fully connected layers.\n",
    "    dropout: float, optional\n",
    "        dropout ratio used in the fully connected layers.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    kernel_constraint = MaxNorm(3) if dropout else None\n",
    "    \n",
    "    for i in range(conv_depth):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(filters = start_num_filters,\n",
    "                             kernel_size = kernel_size,\n",
    "                             strides = (1, 1),\n",
    "                             padding = 'same',\n",
    "                             activation = 'relu',\n",
    "                             input_shape = input_shape))\n",
    "        else:\n",
    "            model.add(Conv2D(filters = start_num_filters,\n",
    "                             kernel_size = kernel_size,\n",
    "                             strides = (1, 1),\n",
    "                             padding = 'same',\n",
    "                             activation = 'relu'))\n",
    "            \n",
    "        model.add(MaxPool2D(pool_size = pool_size))\n",
    "        start_num_filters *= 2\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if dropout:\n",
    "        model.add(Dropout(dropout))\n",
    "    \n",
    "    for i in range(len(fc_units)):\n",
    "        model.add(Dense(units = fc_units[i], \n",
    "                        activation = 'relu', \n",
    "                        kernel_regularizer = kernel_regularizer,\n",
    "                        kernel_constraint = kernel_constraint))\n",
    "        if dropout:\n",
    "            model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(units = num_classes, \n",
    "                    activation = 'softmax', \n",
    "                    kernel_regularizer = kernel_regularizer,\n",
    "                    kernel_constraint = kernel_constraint))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(results, results_dir='./'):\n",
    "    \"\"\"\n",
    "    Function used to write a prediction dictionary to a csv file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results: dict\n",
    "        predictions\n",
    "    results_dir: string, optional\n",
    "        the directory\n",
    "    \"\"\"\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, model_name = datetime.now().strftime('%b%d_%H-%M-%S')):\n",
    "    \"\"\"\n",
    "    Function used to fit the model (and save the checkpoints).\n",
    "    It saves all the checkpoints that increased the performance and returns the best one.\n",
    "    The performance evaluated is the validation accuracy.\n",
    "    Early stopping is used with 20 epochs of patience.\n",
    "    It also uses a tensorboard callback for visualization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: keras model\n",
    "        model to fit.\n",
    "    model_name: string, optional\n",
    "        name of the model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    keras model: the best model.\n",
    "    string: the directory of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # General experiments folder\n",
    "    exps_dir = os.path.join(cwd, 'classification_experiments')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "    \n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    \n",
    "    # This experiment folder\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "    \n",
    "    # Checpoints folder\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    \n",
    "    # Checkpoints callback, best one will be the last saved\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       save_best_only=True, \n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode = 'max')\n",
    "    \n",
    "    # Tensorboard folder\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "    \n",
    "    # Tensorboard callback\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                                 profile_batch=0,\n",
    "                                                 histogram_freq=1)  # if 1 shows weights histograms\n",
    "    \n",
    "    # Early stopping callback\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                                   patience=20,\n",
    "                                                   mode = 'max')\n",
    "    \n",
    "    callbacks= [ckpt_callback, tb_callback, es_callback]\n",
    "    \n",
    "    model.fit(x=training_dataset,\n",
    "              epochs=150,\n",
    "              steps_per_epoch=len(training_generator),\n",
    "              validation_data=validation_dataset,\n",
    "              validation_steps=len(validation_generator), \n",
    "              callbacks=callbacks)\n",
    "    \n",
    "    # Load best model (last one saved)\n",
    "    latest = tf.train.latest_checkpoint(ckpt_dir)\n",
    "    print(\"Latest model: \" + latest)\n",
    "    model.load_weights(os.path.join(ckpt_dir, latest))\n",
    "    \n",
    "    return (model, exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, exp_dir):\n",
    "    \"\"\"\n",
    "    Function used to make predictions and write them to file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: keras model\n",
    "    exp_dir: the directory where the predictions must be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for image_name in test_filenames:\n",
    "        img = Image.open(os.path.join(test_dir,image_name)).convert('RGB').resize((img_w, img_h))\n",
    "        img_array = np.array(img)\n",
    "        img_array = np.expand_dims(img_array, 0)\n",
    "        img_array = np.divide(img_array,255)\n",
    "        tensor = tf.convert_to_tensor(img_array, dtype = tf.float32)\n",
    "        \n",
    "        prediction = np.argmax(model.predict(tensor))\n",
    "        results[image_name] = prediction\n",
    "\n",
    "    create_csv(results = results, results_dir=exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_1: as seen in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 4,303,460\n",
      "Trainable params: 4,303,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 49s 278ms/step - loss: 2.9091 - accuracy: 0.0932 - val_loss: 2.7470 - val_accuracy: 0.1284\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 46s 264ms/step - loss: 2.6566 - accuracy: 0.1743 - val_loss: 2.4705 - val_accuracy: 0.2635\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 48s 270ms/step - loss: 2.4184 - accuracy: 0.2404 - val_loss: 2.3710 - val_accuracy: 0.2770\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 44s 248ms/step - loss: 2.2187 - accuracy: 0.3065 - val_loss: 2.0683 - val_accuracy: 0.3311\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 2.0257 - accuracy: 0.3627 - val_loss: 2.0919 - val_accuracy: 0.3919\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 1.8869 - accuracy: 0.4054 - val_loss: 1.8476 - val_accuracy: 0.4189\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 43s 244ms/step - loss: 1.7507 - accuracy: 0.4545 - val_loss: 1.8178 - val_accuracy: 0.4324\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 1.5929 - accuracy: 0.4929 - val_loss: 1.7133 - val_accuracy: 0.4595\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 42s 241ms/step - loss: 1.5568 - accuracy: 0.5064 - val_loss: 1.8668 - val_accuracy: 0.3986\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 1.4564 - accuracy: 0.5391 - val_loss: 1.6456 - val_accuracy: 0.4662\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 43s 242ms/step - loss: 1.4543 - accuracy: 0.5519 - val_loss: 1.7438 - val_accuracy: 0.4595\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 43s 246ms/step - loss: 1.3034 - accuracy: 0.5889 - val_loss: 1.4958 - val_accuracy: 0.5676\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 44s 248ms/step - loss: 1.2498 - accuracy: 0.6124 - val_loss: 1.6282 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 1.1873 - accuracy: 0.6330 - val_loss: 1.5082 - val_accuracy: 0.5676\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 1.1158 - accuracy: 0.6565 - val_loss: 1.6930 - val_accuracy: 0.5135\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.1032 - accuracy: 0.6522 - val_loss: 1.6462 - val_accuracy: 0.4730\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 1.0305 - accuracy: 0.6664 - val_loss: 1.4605 - val_accuracy: 0.5946\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 45s 257ms/step - loss: 0.9556 - accuracy: 0.6735 - val_loss: 1.7085 - val_accuracy: 0.5676\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 45s 258ms/step - loss: 0.9341 - accuracy: 0.7006 - val_loss: 1.6849 - val_accuracy: 0.5338\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 45s 258ms/step - loss: 0.8112 - accuracy: 0.7468 - val_loss: 1.5701 - val_accuracy: 0.5270\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 47s 265ms/step - loss: 0.8645 - accuracy: 0.7226 - val_loss: 1.9257 - val_accuracy: 0.4730\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 47s 268ms/step - loss: 0.7766 - accuracy: 0.7518 - val_loss: 1.9539 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 46s 260ms/step - loss: 0.7639 - accuracy: 0.7532 - val_loss: 1.6760 - val_accuracy: 0.5068\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 45s 257ms/step - loss: 0.7693 - accuracy: 0.7468 - val_loss: 1.6980 - val_accuracy: 0.5473\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 0.7310 - accuracy: 0.7582 - val_loss: 1.7496 - val_accuracy: 0.5676\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 47s 265ms/step - loss: 0.6553 - accuracy: 0.7923 - val_loss: 2.2587 - val_accuracy: 0.5338\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 0.6446 - accuracy: 0.7824 - val_loss: 1.9974 - val_accuracy: 0.5405\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.6285 - accuracy: 0.7987 - val_loss: 2.2505 - val_accuracy: 0.5068\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 0.6305 - accuracy: 0.8080 - val_loss: 2.2138 - val_accuracy: 0.5068\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 0.5555 - accuracy: 0.8172 - val_loss: 2.3982 - val_accuracy: 0.5203\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.6043 - accuracy: 0.8137 - val_loss: 2.1700 - val_accuracy: 0.5270\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 0.4836 - accuracy: 0.8428 - val_loss: 2.2218 - val_accuracy: 0.5541\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 42s 241ms/step - loss: 0.5085 - accuracy: 0.8343 - val_loss: 2.1356 - val_accuracy: 0.5135\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 42s 241ms/step - loss: 0.5110 - accuracy: 0.8279 - val_loss: 2.2120 - val_accuracy: 0.5541\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 42s 240ms/step - loss: 0.4993 - accuracy: 0.8421 - val_loss: 2.3426 - val_accuracy: 0.4797\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 42s 240ms/step - loss: 0.4390 - accuracy: 0.8677 - val_loss: 2.5547 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 42s 240ms/step - loss: 0.4191 - accuracy: 0.8599 - val_loss: 2.1964 - val_accuracy: 0.5068\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_1_Nov20_23-01-06\\ckpts\\cp_17.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_1\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 8\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_2: as seen in class + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 4,303,460\n",
      "Trainable params: 4,303,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 3.6555 - accuracy: 0.0953 - val_loss: 3.0336 - val_accuracy: 0.0946\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.8511 - accuracy: 0.1166 - val_loss: 2.9256 - val_accuracy: 0.1216\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.7741 - accuracy: 0.1501 - val_loss: 2.7470 - val_accuracy: 0.1284\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.6950 - accuracy: 0.1686 - val_loss: 2.6644 - val_accuracy: 0.1419\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 45s 256ms/step - loss: 2.6162 - accuracy: 0.2034 - val_loss: 2.5293 - val_accuracy: 0.2365\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 2.5278 - accuracy: 0.2468 - val_loss: 2.5217 - val_accuracy: 0.2230\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.4525 - accuracy: 0.2532 - val_loss: 2.4113 - val_accuracy: 0.2162\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.4009 - accuracy: 0.2980 - val_loss: 2.3755 - val_accuracy: 0.2770\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 2.3341 - accuracy: 0.3001 - val_loss: 2.2431 - val_accuracy: 0.3514\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.3239 - accuracy: 0.3037 - val_loss: 2.2820 - val_accuracy: 0.3243\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.2490 - accuracy: 0.3414 - val_loss: 2.4800 - val_accuracy: 0.3243\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.2095 - accuracy: 0.3677 - val_loss: 2.1975 - val_accuracy: 0.3919\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 2.1268 - accuracy: 0.3855 - val_loss: 2.3122 - val_accuracy: 0.3378\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.0895 - accuracy: 0.3962 - val_loss: 2.1277 - val_accuracy: 0.4122\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.0541 - accuracy: 0.4225 - val_loss: 2.1966 - val_accuracy: 0.4122\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.0546 - accuracy: 0.4310 - val_loss: 2.1351 - val_accuracy: 0.4257\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.9891 - accuracy: 0.4516 - val_loss: 2.3153 - val_accuracy: 0.4392\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.9523 - accuracy: 0.4730 - val_loss: 2.0738 - val_accuracy: 0.4865\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.9167 - accuracy: 0.4744 - val_loss: 2.0532 - val_accuracy: 0.4932\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8842 - accuracy: 0.5028 - val_loss: 2.1231 - val_accuracy: 0.4122\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8600 - accuracy: 0.4865 - val_loss: 2.0460 - val_accuracy: 0.4662\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8132 - accuracy: 0.5220 - val_loss: 2.3096 - val_accuracy: 0.4730\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8401 - accuracy: 0.5178 - val_loss: 2.2290 - val_accuracy: 0.4459\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8104 - accuracy: 0.5135 - val_loss: 2.1513 - val_accuracy: 0.4459\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.7850 - accuracy: 0.5292 - val_loss: 2.1144 - val_accuracy: 0.4595\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.7341 - accuracy: 0.5413 - val_loss: 1.9929 - val_accuracy: 0.5270\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.7097 - accuracy: 0.5512 - val_loss: 1.9775 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.6960 - accuracy: 0.5477 - val_loss: 2.0953 - val_accuracy: 0.4932\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.6734 - accuracy: 0.5683 - val_loss: 2.1239 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.6947 - accuracy: 0.5590 - val_loss: 2.1378 - val_accuracy: 0.4797\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.6428 - accuracy: 0.5882 - val_loss: 2.0345 - val_accuracy: 0.5203\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.6197 - accuracy: 0.5654 - val_loss: 2.1091 - val_accuracy: 0.4662\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.6154 - accuracy: 0.5846 - val_loss: 2.0825 - val_accuracy: 0.4595\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.6199 - accuracy: 0.5839 - val_loss: 1.8027 - val_accuracy: 0.5405\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.5769 - accuracy: 0.5946 - val_loss: 2.1531 - val_accuracy: 0.4865\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.5971 - accuracy: 0.5925 - val_loss: 1.9421 - val_accuracy: 0.5676\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.5824 - accuracy: 0.5925 - val_loss: 2.1518 - val_accuracy: 0.4797\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.5432 - accuracy: 0.5932 - val_loss: 2.0868 - val_accuracy: 0.4797\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.5563 - accuracy: 0.5775 - val_loss: 2.1136 - val_accuracy: 0.4865\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.5176 - accuracy: 0.6038 - val_loss: 2.1095 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.5354 - accuracy: 0.6095 - val_loss: 1.9282 - val_accuracy: 0.5473\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 1.5249 - accuracy: 0.6074 - val_loss: 2.1732 - val_accuracy: 0.4797\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.4778 - accuracy: 0.6166 - val_loss: 1.9621 - val_accuracy: 0.5676\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4746 - accuracy: 0.6287 - val_loss: 2.1180 - val_accuracy: 0.4932\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.5019 - accuracy: 0.6110 - val_loss: 2.0450 - val_accuracy: 0.5135\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4734 - accuracy: 0.6174 - val_loss: 2.0432 - val_accuracy: 0.4662\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4259 - accuracy: 0.6422 - val_loss: 2.4736 - val_accuracy: 0.4595\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 1.4535 - accuracy: 0.6181 - val_loss: 1.9619 - val_accuracy: 0.5541\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.3787 - accuracy: 0.6415 - val_loss: 2.1634 - val_accuracy: 0.5541\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 1.3837 - accuracy: 0.6430 - val_loss: 2.1950 - val_accuracy: 0.5135\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 44s 249ms/step - loss: 1.3766 - accuracy: 0.6550 - val_loss: 2.3018 - val_accuracy: 0.5338\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4334 - accuracy: 0.6430 - val_loss: 1.8959 - val_accuracy: 0.5270\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 44s 249ms/step - loss: 1.4178 - accuracy: 0.6323 - val_loss: 2.0797 - val_accuracy: 0.5338\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 1.3697 - accuracy: 0.6643 - val_loss: 1.9166 - val_accuracy: 0.5541\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.3662 - accuracy: 0.6529 - val_loss: 1.9274 - val_accuracy: 0.5608\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4100 - accuracy: 0.6358 - val_loss: 1.9789 - val_accuracy: 0.5541\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_2_Nov20_23-28-47\\ckpts\\cp_36.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_2\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 8\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#alpha = 0.01\n",
    "#kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units, \n",
    "#                   kernel_regularizer = kernel_regularizer,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_3: 7 layers, start_num_filters = 4 [REMOVED]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_4: 7 layers, start_num_filters = 4, regularization [REMOVED]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_5: 6 layers, start_num_filters = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 2,501,476\n",
      "Trainable params: 2,501,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 45s 256ms/step - loss: 2.9838 - accuracy: 0.0690 - val_loss: 2.8412 - val_accuracy: 0.1149\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.8148 - accuracy: 0.1110 - val_loss: 2.8153 - val_accuracy: 0.1081\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.6576 - accuracy: 0.1479 - val_loss: 2.5510 - val_accuracy: 0.2095\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 2.5211 - accuracy: 0.2027 - val_loss: 2.4197 - val_accuracy: 0.1959\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.3724 - accuracy: 0.2546 - val_loss: 2.4009 - val_accuracy: 0.2230\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 2.2760 - accuracy: 0.2809 - val_loss: 2.3923 - val_accuracy: 0.2635\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 2.1928 - accuracy: 0.3065 - val_loss: 2.1146 - val_accuracy: 0.3514\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 2.0702 - accuracy: 0.3578 - val_loss: 2.0326 - val_accuracy: 0.4189\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 1.9805 - accuracy: 0.3826 - val_loss: 2.0510 - val_accuracy: 0.3986\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.9000 - accuracy: 0.3990 - val_loss: 1.9549 - val_accuracy: 0.3986\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.7965 - accuracy: 0.4452 - val_loss: 1.8950 - val_accuracy: 0.3986\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.7187 - accuracy: 0.4502 - val_loss: 1.8447 - val_accuracy: 0.3851\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 1.6715 - accuracy: 0.4680 - val_loss: 1.8762 - val_accuracy: 0.4595\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.5857 - accuracy: 0.4858 - val_loss: 1.8337 - val_accuracy: 0.4392\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 1.4982 - accuracy: 0.5256 - val_loss: 1.7891 - val_accuracy: 0.4189\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 1.5027 - accuracy: 0.5149 - val_loss: 1.8263 - val_accuracy: 0.4324\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.4042 - accuracy: 0.5576 - val_loss: 1.7453 - val_accuracy: 0.4865\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.3626 - accuracy: 0.5733 - val_loss: 1.9205 - val_accuracy: 0.4257\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.2982 - accuracy: 0.5868 - val_loss: 1.6737 - val_accuracy: 0.4865\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.3054 - accuracy: 0.5733 - val_loss: 1.7532 - val_accuracy: 0.4797\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 1.2441 - accuracy: 0.6010 - val_loss: 1.7671 - val_accuracy: 0.4730\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 1.1893 - accuracy: 0.6309 - val_loss: 1.6640 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.1361 - accuracy: 0.6188 - val_loss: 1.7287 - val_accuracy: 0.4595\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.1158 - accuracy: 0.6259 - val_loss: 1.7721 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 1.0768 - accuracy: 0.6508 - val_loss: 1.7584 - val_accuracy: 0.5338\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 1.0429 - accuracy: 0.6735 - val_loss: 1.7848 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.0094 - accuracy: 0.6607 - val_loss: 1.9963 - val_accuracy: 0.4932\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.0031 - accuracy: 0.6721 - val_loss: 1.7169 - val_accuracy: 0.5203\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 0.9381 - accuracy: 0.6984 - val_loss: 1.7113 - val_accuracy: 0.5608\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.9056 - accuracy: 0.7034 - val_loss: 1.6554 - val_accuracy: 0.5135\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.9110 - accuracy: 0.7155 - val_loss: 1.8202 - val_accuracy: 0.4730\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.8730 - accuracy: 0.7169 - val_loss: 1.7981 - val_accuracy: 0.5135\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.8721 - accuracy: 0.7048 - val_loss: 1.7160 - val_accuracy: 0.5270\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.8349 - accuracy: 0.7105 - val_loss: 1.8651 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.7939 - accuracy: 0.7432 - val_loss: 1.9764 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.7029 - accuracy: 0.7653 - val_loss: 1.9269 - val_accuracy: 0.5135\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 0.7373 - accuracy: 0.7610 - val_loss: 1.8278 - val_accuracy: 0.5676\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.7062 - accuracy: 0.7596 - val_loss: 1.9294 - val_accuracy: 0.4662\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.6755 - accuracy: 0.7760 - val_loss: 1.8987 - val_accuracy: 0.5203\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.6954 - accuracy: 0.7724 - val_loss: 1.8681 - val_accuracy: 0.5676\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.6631 - accuracy: 0.7895 - val_loss: 2.0983 - val_accuracy: 0.4797\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 0.6510 - accuracy: 0.7774 - val_loss: 1.9891 - val_accuracy: 0.4865\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.6201 - accuracy: 0.7930 - val_loss: 1.7770 - val_accuracy: 0.5135\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.6469 - accuracy: 0.7909 - val_loss: 1.8901 - val_accuracy: 0.5270\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.5802 - accuracy: 0.8073 - val_loss: 2.1137 - val_accuracy: 0.5203\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.6049 - accuracy: 0.8001 - val_loss: 1.7168 - val_accuracy: 0.5203\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.5772 - accuracy: 0.8080 - val_loss: 1.8568 - val_accuracy: 0.5068\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.5277 - accuracy: 0.8321 - val_loss: 2.4065 - val_accuracy: 0.4797\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.5233 - accuracy: 0.8265 - val_loss: 2.0271 - val_accuracy: 0.5270\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.5222 - accuracy: 0.8257 - val_loss: 1.9213 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.4986 - accuracy: 0.8421 - val_loss: 2.2352 - val_accuracy: 0.5270\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.5086 - accuracy: 0.8279 - val_loss: 2.3813 - val_accuracy: 0.4865\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.5084 - accuracy: 0.8321 - val_loss: 2.2214 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.4766 - accuracy: 0.8528 - val_loss: 2.2990 - val_accuracy: 0.5203\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.4883 - accuracy: 0.8329 - val_loss: 2.2449 - val_accuracy: 0.5270\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.4589 - accuracy: 0.8435 - val_loss: 2.0119 - val_accuracy: 0.5270\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 0.5056 - accuracy: 0.8407 - val_loss: 2.1454 - val_accuracy: 0.4595\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_5_Nov21_00-10-31\\ckpts\\cp_37.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_5\"\n",
    "#conv_depth = 6\n",
    "#start_num_filters = 8\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_6: 6 layers, start_num_filters = 8, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 2,501,476\n",
      "Trainable params: 2,501,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 47s 268ms/step - loss: 3.8180 - accuracy: 0.0754 - val_loss: 2.9566 - val_accuracy: 0.1014\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.8870 - accuracy: 0.1031 - val_loss: 2.8446 - val_accuracy: 0.1284\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 2.8250 - accuracy: 0.1230 - val_loss: 2.7682 - val_accuracy: 0.1216\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.7820 - accuracy: 0.1309 - val_loss: 2.7013 - val_accuracy: 0.1419\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.7217 - accuracy: 0.1408 - val_loss: 2.6878 - val_accuracy: 0.1554\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 2.6855 - accuracy: 0.1515 - val_loss: 2.6591 - val_accuracy: 0.1622\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 2.6357 - accuracy: 0.1693 - val_loss: 2.6431 - val_accuracy: 0.1689\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 2.5869 - accuracy: 0.2084 - val_loss: 2.5924 - val_accuracy: 0.1757\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.4863 - accuracy: 0.2404 - val_loss: 2.4729 - val_accuracy: 0.2568\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 2.4313 - accuracy: 0.2560 - val_loss: 2.5013 - val_accuracy: 0.2162\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 2.3832 - accuracy: 0.2760 - val_loss: 2.4477 - val_accuracy: 0.2365\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 49s 277ms/step - loss: 2.2972 - accuracy: 0.2909 - val_loss: 2.3036 - val_accuracy: 0.2703\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 46s 263ms/step - loss: 2.3105 - accuracy: 0.3058 - val_loss: 2.2529 - val_accuracy: 0.3041\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.2534 - accuracy: 0.3151 - val_loss: 2.3395 - val_accuracy: 0.3243\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 47s 264ms/step - loss: 2.2453 - accuracy: 0.3172 - val_loss: 2.1147 - val_accuracy: 0.3851\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 2.1526 - accuracy: 0.3535 - val_loss: 2.2049 - val_accuracy: 0.3378\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.1055 - accuracy: 0.3770 - val_loss: 2.0406 - val_accuracy: 0.4054\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 2.0314 - accuracy: 0.4054 - val_loss: 2.1495 - val_accuracy: 0.3514\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 49s 276ms/step - loss: 2.0179 - accuracy: 0.4083 - val_loss: 2.1311 - val_accuracy: 0.4122\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 48s 271ms/step - loss: 1.9772 - accuracy: 0.4218 - val_loss: 2.0199 - val_accuracy: 0.3919\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 47s 269ms/step - loss: 1.9145 - accuracy: 0.4467 - val_loss: 2.2352 - val_accuracy: 0.3986\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.9081 - accuracy: 0.4445 - val_loss: 2.1233 - val_accuracy: 0.3919\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 47s 267ms/step - loss: 1.8236 - accuracy: 0.4694 - val_loss: 1.9406 - val_accuracy: 0.4392\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 46s 260ms/step - loss: 1.8306 - accuracy: 0.4758 - val_loss: 2.0871 - val_accuracy: 0.4257\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 48s 271ms/step - loss: 1.7502 - accuracy: 0.4922 - val_loss: 2.1833 - val_accuracy: 0.3716\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.7479 - accuracy: 0.5050 - val_loss: 2.0103 - val_accuracy: 0.4392\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 48s 271ms/step - loss: 1.7171 - accuracy: 0.5206 - val_loss: 1.8724 - val_accuracy: 0.4459\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.6559 - accuracy: 0.5391 - val_loss: 1.9603 - val_accuracy: 0.4662\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.6429 - accuracy: 0.5533 - val_loss: 1.9266 - val_accuracy: 0.4122\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 46s 262ms/step - loss: 1.6641 - accuracy: 0.5341 - val_loss: 2.1091 - val_accuracy: 0.4527\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.5960 - accuracy: 0.5498 - val_loss: 1.9251 - val_accuracy: 0.4459\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.5975 - accuracy: 0.5583 - val_loss: 2.2008 - val_accuracy: 0.4392\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.6182 - accuracy: 0.5533 - val_loss: 1.9325 - val_accuracy: 0.4662\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 47s 264ms/step - loss: 1.5398 - accuracy: 0.5797 - val_loss: 1.9839 - val_accuracy: 0.5068\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.5863 - accuracy: 0.5747 - val_loss: 2.0210 - val_accuracy: 0.4730\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 48s 270ms/step - loss: 1.5337 - accuracy: 0.5782 - val_loss: 2.0621 - val_accuracy: 0.4257\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 1.4787 - accuracy: 0.6074 - val_loss: 1.9683 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 46s 260ms/step - loss: 1.4641 - accuracy: 0.6067 - val_loss: 1.9559 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 46s 261ms/step - loss: 1.4275 - accuracy: 0.6316 - val_loss: 1.7732 - val_accuracy: 0.4730\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.4783 - accuracy: 0.6017 - val_loss: 1.9598 - val_accuracy: 0.4595\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 49s 276ms/step - loss: 1.4090 - accuracy: 0.6145 - val_loss: 1.7292 - val_accuracy: 0.5676\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.4167 - accuracy: 0.6330 - val_loss: 1.8955 - val_accuracy: 0.5608\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.4311 - accuracy: 0.6138 - val_loss: 2.0268 - val_accuracy: 0.4932\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.3521 - accuracy: 0.6430 - val_loss: 1.8189 - val_accuracy: 0.5676\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.3208 - accuracy: 0.6565 - val_loss: 1.8182 - val_accuracy: 0.5338\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.3268 - accuracy: 0.6522 - val_loss: 2.2323 - val_accuracy: 0.5135\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.3518 - accuracy: 0.6501 - val_loss: 1.9879 - val_accuracy: 0.5068\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 49s 277ms/step - loss: 1.3167 - accuracy: 0.6558 - val_loss: 1.7400 - val_accuracy: 0.5878\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.3474 - accuracy: 0.6444 - val_loss: 2.1203 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.2378 - accuracy: 0.6757 - val_loss: 1.9985 - val_accuracy: 0.5203\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 49s 279ms/step - loss: 1.2902 - accuracy: 0.6572 - val_loss: 1.9804 - val_accuracy: 0.5946\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.2561 - accuracy: 0.6686 - val_loss: 2.0657 - val_accuracy: 0.5270\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 49s 277ms/step - loss: 1.2037 - accuracy: 0.6821 - val_loss: 1.9057 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 49s 277ms/step - loss: 1.2087 - accuracy: 0.6892 - val_loss: 1.9795 - val_accuracy: 0.5270\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 47s 266ms/step - loss: 1.2573 - accuracy: 0.6771 - val_loss: 1.8774 - val_accuracy: 0.5743\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.2460 - accuracy: 0.6707 - val_loss: 1.9330 - val_accuracy: 0.5270\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.2558 - accuracy: 0.6728 - val_loss: 1.8554 - val_accuracy: 0.5338\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.2106 - accuracy: 0.6892 - val_loss: 1.8759 - val_accuracy: 0.5878\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1811 - accuracy: 0.6977 - val_loss: 1.9851 - val_accuracy: 0.5608\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1834 - accuracy: 0.7013 - val_loss: 1.8546 - val_accuracy: 0.5270\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.1387 - accuracy: 0.7084 - val_loss: 1.9112 - val_accuracy: 0.6149\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1380 - accuracy: 0.7198 - val_loss: 2.0327 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.1552 - accuracy: 0.7084 - val_loss: 2.2612 - val_accuracy: 0.5135\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1430 - accuracy: 0.7176 - val_loss: 2.0367 - val_accuracy: 0.5473\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1102 - accuracy: 0.7119 - val_loss: 1.9397 - val_accuracy: 0.5270\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 46s 261ms/step - loss: 1.0949 - accuracy: 0.7276 - val_loss: 1.7657 - val_accuracy: 0.5608\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.1005 - accuracy: 0.7191 - val_loss: 2.1581 - val_accuracy: 0.5608\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.0786 - accuracy: 0.7340 - val_loss: 1.7758 - val_accuracy: 0.5946\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.0812 - accuracy: 0.7454 - val_loss: 1.9042 - val_accuracy: 0.5338\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.0885 - accuracy: 0.7255 - val_loss: 2.0797 - val_accuracy: 0.5743\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.1048 - accuracy: 0.7269 - val_loss: 2.1508 - val_accuracy: 0.5068\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.0725 - accuracy: 0.7404 - val_loss: 1.8255 - val_accuracy: 0.5473\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.0760 - accuracy: 0.7290 - val_loss: 1.9802 - val_accuracy: 0.5676\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 49s 276ms/step - loss: 1.0730 - accuracy: 0.7361 - val_loss: 1.8091 - val_accuracy: 0.5946\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 49s 276ms/step - loss: 1.0546 - accuracy: 0.7404 - val_loss: 1.8101 - val_accuracy: 0.5878\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.0219 - accuracy: 0.7432 - val_loss: 2.1542 - val_accuracy: 0.5270\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.0544 - accuracy: 0.7376 - val_loss: 2.0346 - val_accuracy: 0.5405\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.0331 - accuracy: 0.7440 - val_loss: 2.0019 - val_accuracy: 0.5608\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.0286 - accuracy: 0.7440 - val_loss: 2.2923 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.0482 - accuracy: 0.7390 - val_loss: 1.8332 - val_accuracy: 0.5608\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.0348 - accuracy: 0.7440 - val_loss: 2.1126 - val_accuracy: 0.5743\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_6_Nov21_00-53-02\\ckpts\\cp_61.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_6\"\n",
    "#conv_depth = 6\n",
    "#start_num_filters = 8\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#alpha = 0.01\n",
    "#kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units, \n",
    "#                   kernel_regularizer = kernel_regularizer,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_7: as seen in class, start_num_filters = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 8,791,988\n",
      "Trainable params: 8,791,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 99s 562ms/step - loss: 2.8972 - accuracy: 0.0875 - val_loss: 2.7022 - val_accuracy: 0.1081\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 98s 558ms/step - loss: 2.7065 - accuracy: 0.1316 - val_loss: 2.6947 - val_accuracy: 0.1757\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 98s 558ms/step - loss: 2.5516 - accuracy: 0.1949 - val_loss: 2.4172 - val_accuracy: 0.2095\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 98s 558ms/step - loss: 2.3640 - accuracy: 0.2532 - val_loss: 2.3124 - val_accuracy: 0.3041\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 98s 556ms/step - loss: 2.1954 - accuracy: 0.2966 - val_loss: 2.1619 - val_accuracy: 0.3581\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 98s 557ms/step - loss: 2.0998 - accuracy: 0.3471 - val_loss: 2.0640 - val_accuracy: 0.3784\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 1.9812 - accuracy: 0.3841 - val_loss: 2.0952 - val_accuracy: 0.3649\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 98s 557ms/step - loss: 1.9340 - accuracy: 0.3947 - val_loss: 1.9206 - val_accuracy: 0.3851\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 98s 556ms/step - loss: 1.8071 - accuracy: 0.4253 - val_loss: 1.9181 - val_accuracy: 0.3986\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 98s 558ms/step - loss: 1.6721 - accuracy: 0.4765 - val_loss: 1.7081 - val_accuracy: 0.4662\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 97s 551ms/step - loss: 1.5799 - accuracy: 0.5064 - val_loss: 1.7799 - val_accuracy: 0.4459\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 1.4793 - accuracy: 0.5405 - val_loss: 1.8082 - val_accuracy: 0.4662\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 1.4539 - accuracy: 0.5398 - val_loss: 1.6699 - val_accuracy: 0.4662\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 97s 552ms/step - loss: 1.3749 - accuracy: 0.5669 - val_loss: 1.6642 - val_accuracy: 0.4595\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 97s 553ms/step - loss: 1.2682 - accuracy: 0.5967 - val_loss: 1.6936 - val_accuracy: 0.5068\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 97s 548ms/step - loss: 1.2504 - accuracy: 0.5910 - val_loss: 1.6707 - val_accuracy: 0.4730\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 1.1581 - accuracy: 0.6273 - val_loss: 1.8111 - val_accuracy: 0.4392\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 97s 554ms/step - loss: 1.1469 - accuracy: 0.6337 - val_loss: 1.8391 - val_accuracy: 0.5203\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 1.0689 - accuracy: 0.6629 - val_loss: 1.7674 - val_accuracy: 0.5068\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 1.0130 - accuracy: 0.6735 - val_loss: 1.7317 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 96s 547ms/step - loss: 0.9506 - accuracy: 0.6899 - val_loss: 1.7209 - val_accuracy: 0.4932\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 97s 554ms/step - loss: 0.9485 - accuracy: 0.6771 - val_loss: 1.4913 - val_accuracy: 0.5676\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 97s 553ms/step - loss: 0.8763 - accuracy: 0.7134 - val_loss: 1.4843 - val_accuracy: 0.5946\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 0.8764 - accuracy: 0.7105 - val_loss: 1.7341 - val_accuracy: 0.5203\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.8133 - accuracy: 0.7326 - val_loss: 2.0408 - val_accuracy: 0.4595\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.7925 - accuracy: 0.7525 - val_loss: 1.5959 - val_accuracy: 0.5541\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 97s 548ms/step - loss: 0.8010 - accuracy: 0.7368 - val_loss: 1.8813 - val_accuracy: 0.5203\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 0.7249 - accuracy: 0.7667 - val_loss: 1.9638 - val_accuracy: 0.5068\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.7150 - accuracy: 0.7767 - val_loss: 1.9456 - val_accuracy: 0.5405\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.6578 - accuracy: 0.7845 - val_loss: 1.7925 - val_accuracy: 0.5608\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.6361 - accuracy: 0.7916 - val_loss: 1.9528 - val_accuracy: 0.5068\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.6222 - accuracy: 0.8051 - val_loss: 2.0748 - val_accuracy: 0.4932\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 0.5897 - accuracy: 0.8094 - val_loss: 1.9595 - val_accuracy: 0.5473\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.5774 - accuracy: 0.8016 - val_loss: 2.3125 - val_accuracy: 0.5203\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.6123 - accuracy: 0.7959 - val_loss: 1.9707 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.6161 - accuracy: 0.8037 - val_loss: 1.9784 - val_accuracy: 0.5541\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.4835 - accuracy: 0.8457 - val_loss: 1.9426 - val_accuracy: 0.5541\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.5430 - accuracy: 0.8208 - val_loss: 2.0098 - val_accuracy: 0.5608\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.4652 - accuracy: 0.8407 - val_loss: 2.4830 - val_accuracy: 0.5608\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.4825 - accuracy: 0.8563 - val_loss: 2.1359 - val_accuracy: 0.5608\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.4558 - accuracy: 0.8556 - val_loss: 2.2354 - val_accuracy: 0.5473\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.4451 - accuracy: 0.8570 - val_loss: 1.9202 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.4876 - accuracy: 0.8364 - val_loss: 2.1253 - val_accuracy: 0.6216\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.4237 - accuracy: 0.8556 - val_loss: 2.3714 - val_accuracy: 0.5203\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.4422 - accuracy: 0.8506 - val_loss: 2.2115 - val_accuracy: 0.5135\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.4104 - accuracy: 0.8684 - val_loss: 2.4195 - val_accuracy: 0.5135\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.4427 - accuracy: 0.8585 - val_loss: 2.3719 - val_accuracy: 0.5405\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 97s 551ms/step - loss: 0.3387 - accuracy: 0.8805 - val_loss: 2.3236 - val_accuracy: 0.5338\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3951 - accuracy: 0.8777 - val_loss: 2.3652 - val_accuracy: 0.5270\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3985 - accuracy: 0.8670 - val_loss: 2.2349 - val_accuracy: 0.5878\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3297 - accuracy: 0.8947 - val_loss: 2.5815 - val_accuracy: 0.5541\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.3746 - accuracy: 0.8734 - val_loss: 2.5103 - val_accuracy: 0.5135\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 96s 547ms/step - loss: 0.3577 - accuracy: 0.8798 - val_loss: 2.1850 - val_accuracy: 0.5473\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3043 - accuracy: 0.8940 - val_loss: 2.3108 - val_accuracy: 0.5405\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.4345 - accuracy: 0.8649 - val_loss: 2.3146 - val_accuracy: 0.5608\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3068 - accuracy: 0.9004 - val_loss: 2.3883 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 0.2962 - accuracy: 0.9040 - val_loss: 2.5287 - val_accuracy: 0.5608\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.2721 - accuracy: 0.9033 - val_loss: 2.5102 - val_accuracy: 0.5203\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 99s 560ms/step - loss: 0.3278 - accuracy: 0.8976 - val_loss: 2.2006 - val_accuracy: 0.5473\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.3719 - accuracy: 0.8777 - val_loss: 2.1357 - val_accuracy: 0.5811\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.2796 - accuracy: 0.9104 - val_loss: 2.3019 - val_accuracy: 0.5946\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 96s 547ms/step - loss: 0.3339 - accuracy: 0.8947 - val_loss: 2.2726 - val_accuracy: 0.5743\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.2582 - accuracy: 0.9189 - val_loss: 2.4863 - val_accuracy: 0.5743\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_7_Nov21_01-58-04\\ckpts\\cp_43.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_7\"\n",
    "conv_depth = 5\n",
    "start_num_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [512]\n",
    "num_classes = len(classes)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_8: as seen in class, start_num_filters = 16, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 4,303,460\n",
      "Trainable params: 4,303,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 3.8077 - accuracy: 0.0896 - val_loss: 2.9401 - val_accuracy: 0.0676\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.9023 - accuracy: 0.1159 - val_loss: 2.7589 - val_accuracy: 0.1486\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 2.7896 - accuracy: 0.1522 - val_loss: 2.6905 - val_accuracy: 0.1622\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.7107 - accuracy: 0.1543 - val_loss: 2.6429 - val_accuracy: 0.1757\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 2.6693 - accuracy: 0.1842 - val_loss: 2.6310 - val_accuracy: 0.1892\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.5683 - accuracy: 0.2119 - val_loss: 2.5806 - val_accuracy: 0.2095\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.5040 - accuracy: 0.2589 - val_loss: 2.4303 - val_accuracy: 0.2703\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.4327 - accuracy: 0.2660 - val_loss: 2.4072 - val_accuracy: 0.2838\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.3503 - accuracy: 0.3001 - val_loss: 2.3053 - val_accuracy: 0.2905\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.2938 - accuracy: 0.2930 - val_loss: 2.3028 - val_accuracy: 0.3311\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 2.2613 - accuracy: 0.3286 - val_loss: 2.1375 - val_accuracy: 0.3851\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 62s 351ms/step - loss: 2.1760 - accuracy: 0.3677 - val_loss: 2.1685 - val_accuracy: 0.3378\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.1641 - accuracy: 0.3784 - val_loss: 2.1020 - val_accuracy: 0.3919\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 62s 351ms/step - loss: 2.1191 - accuracy: 0.4018 - val_loss: 2.2493 - val_accuracy: 0.3716\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 2.0534 - accuracy: 0.4104 - val_loss: 2.0140 - val_accuracy: 0.4122\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.9932 - accuracy: 0.4239 - val_loss: 2.0964 - val_accuracy: 0.3784\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.9565 - accuracy: 0.4559 - val_loss: 2.1893 - val_accuracy: 0.4189\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.9769 - accuracy: 0.4410 - val_loss: 1.9917 - val_accuracy: 0.4189\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.9414 - accuracy: 0.4552 - val_loss: 1.9585 - val_accuracy: 0.4459\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.8828 - accuracy: 0.4858 - val_loss: 2.0643 - val_accuracy: 0.4189\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.9088 - accuracy: 0.4644 - val_loss: 2.0715 - val_accuracy: 0.4054\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.8331 - accuracy: 0.4893 - val_loss: 2.0594 - val_accuracy: 0.4662\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.8597 - accuracy: 0.4772 - val_loss: 1.9616 - val_accuracy: 0.4662\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.8421 - accuracy: 0.4851 - val_loss: 1.9951 - val_accuracy: 0.4122\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7920 - accuracy: 0.4893 - val_loss: 1.9081 - val_accuracy: 0.4527\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7860 - accuracy: 0.4964 - val_loss: 2.0751 - val_accuracy: 0.4324\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.7360 - accuracy: 0.5270 - val_loss: 1.8406 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7421 - accuracy: 0.5320 - val_loss: 1.8984 - val_accuracy: 0.4865\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7370 - accuracy: 0.5263 - val_loss: 1.9804 - val_accuracy: 0.4865\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.7143 - accuracy: 0.5477 - val_loss: 2.0025 - val_accuracy: 0.4730\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7188 - accuracy: 0.5349 - val_loss: 1.8854 - val_accuracy: 0.4595\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.6967 - accuracy: 0.5647 - val_loss: 1.8538 - val_accuracy: 0.5270\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.7022 - accuracy: 0.5469 - val_loss: 1.9694 - val_accuracy: 0.4797\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.6908 - accuracy: 0.5405 - val_loss: 2.0002 - val_accuracy: 0.4595\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.6438 - accuracy: 0.5533 - val_loss: 2.0161 - val_accuracy: 0.4797\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.6574 - accuracy: 0.5498 - val_loss: 1.9146 - val_accuracy: 0.5068\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.6565 - accuracy: 0.5477 - val_loss: 2.0223 - val_accuracy: 0.4932\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.6532 - accuracy: 0.5526 - val_loss: 1.9164 - val_accuracy: 0.4865\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.5997 - accuracy: 0.5690 - val_loss: 1.9824 - val_accuracy: 0.4932\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.5744 - accuracy: 0.5875 - val_loss: 1.8777 - val_accuracy: 0.5135\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.5906 - accuracy: 0.5939 - val_loss: 1.7965 - val_accuracy: 0.5068\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.5810 - accuracy: 0.5875 - val_loss: 1.8336 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.5206 - accuracy: 0.5974 - val_loss: 1.7289 - val_accuracy: 0.5270\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.5814 - accuracy: 0.5825 - val_loss: 2.1436 - val_accuracy: 0.4527\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4928 - accuracy: 0.5882 - val_loss: 1.8292 - val_accuracy: 0.4865\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 62s 351ms/step - loss: 1.5310 - accuracy: 0.5982 - val_loss: 1.8768 - val_accuracy: 0.4459\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.5234 - accuracy: 0.5946 - val_loss: 1.9163 - val_accuracy: 0.4459\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 1.5213 - accuracy: 0.5789 - val_loss: 1.7765 - val_accuracy: 0.5676\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.5079 - accuracy: 0.6010 - val_loss: 1.8600 - val_accuracy: 0.5203\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.4742 - accuracy: 0.5982 - val_loss: 1.7211 - val_accuracy: 0.5743\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4960 - accuracy: 0.5925 - val_loss: 1.7788 - val_accuracy: 0.5541\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4928 - accuracy: 0.5853 - val_loss: 1.6626 - val_accuracy: 0.5405\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4026 - accuracy: 0.6266 - val_loss: 1.9449 - val_accuracy: 0.5068\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4888 - accuracy: 0.5932 - val_loss: 1.9188 - val_accuracy: 0.4865\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4580 - accuracy: 0.6152 - val_loss: 1.9861 - val_accuracy: 0.4730\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4559 - accuracy: 0.6181 - val_loss: 1.8127 - val_accuracy: 0.5270\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4699 - accuracy: 0.6202 - val_loss: 1.7536 - val_accuracy: 0.5608\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4006 - accuracy: 0.6358 - val_loss: 1.7146 - val_accuracy: 0.5338\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4178 - accuracy: 0.6373 - val_loss: 1.8840 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4248 - accuracy: 0.6273 - val_loss: 1.6822 - val_accuracy: 0.5270\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4027 - accuracy: 0.6181 - val_loss: 1.8098 - val_accuracy: 0.5338\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3921 - accuracy: 0.6195 - val_loss: 1.8540 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4280 - accuracy: 0.6159 - val_loss: 1.7076 - val_accuracy: 0.5338\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3686 - accuracy: 0.6401 - val_loss: 1.7530 - val_accuracy: 0.5608\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.3591 - accuracy: 0.6430 - val_loss: 1.7438 - val_accuracy: 0.5338\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.3404 - accuracy: 0.6522 - val_loss: 1.9804 - val_accuracy: 0.5135\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3998 - accuracy: 0.6330 - val_loss: 1.7154 - val_accuracy: 0.5068\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.3726 - accuracy: 0.6458 - val_loss: 1.8012 - val_accuracy: 0.5338\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3568 - accuracy: 0.6465 - val_loss: 1.9722 - val_accuracy: 0.5541\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3060 - accuracy: 0.6358 - val_loss: 1.8379 - val_accuracy: 0.5541\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_8_Nov21_03-40-10\\ckpts\\cp_50.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_8\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 8\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#alpha = 0.01\n",
    "#kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units, \n",
    "#                   kernel_regularizer = kernel_regularizer,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_9: as seen in class, FC has 2 hidden layers of 256 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 2,266,724\n",
      "Trainable params: 2,266,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.8954 - accuracy: 0.0875 - val_loss: 2.7541 - val_accuracy: 0.1689\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 2.7251 - accuracy: 0.1294 - val_loss: 2.6430 - val_accuracy: 0.1419\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.6129 - accuracy: 0.1679 - val_loss: 2.5526 - val_accuracy: 0.2230\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 2.4453 - accuracy: 0.2162 - val_loss: 2.3719 - val_accuracy: 0.2905\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 2.3246 - accuracy: 0.2518 - val_loss: 2.2042 - val_accuracy: 0.2973\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.2635 - accuracy: 0.2774 - val_loss: 2.2870 - val_accuracy: 0.2905\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 2.1219 - accuracy: 0.3179 - val_loss: 2.2069 - val_accuracy: 0.2770\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.0564 - accuracy: 0.3492 - val_loss: 2.1044 - val_accuracy: 0.3446\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.9742 - accuracy: 0.3791 - val_loss: 2.0838 - val_accuracy: 0.3378\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.9022 - accuracy: 0.3983 - val_loss: 1.9358 - val_accuracy: 0.3851\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 1.8194 - accuracy: 0.4139 - val_loss: 2.0345 - val_accuracy: 0.3986\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.7637 - accuracy: 0.4381 - val_loss: 2.0052 - val_accuracy: 0.3919\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 1.6987 - accuracy: 0.4644 - val_loss: 1.8636 - val_accuracy: 0.4459\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.6232 - accuracy: 0.4794 - val_loss: 1.7792 - val_accuracy: 0.4054\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.5991 - accuracy: 0.4964 - val_loss: 1.6642 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.5248 - accuracy: 0.5220 - val_loss: 1.7828 - val_accuracy: 0.4392\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.4975 - accuracy: 0.5341 - val_loss: 1.8457 - val_accuracy: 0.4392\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4248 - accuracy: 0.5391 - val_loss: 1.8343 - val_accuracy: 0.4527\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.3669 - accuracy: 0.5683 - val_loss: 1.7407 - val_accuracy: 0.4932\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.3145 - accuracy: 0.5825 - val_loss: 1.7698 - val_accuracy: 0.4730\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 1.2694 - accuracy: 0.5832 - val_loss: 1.8082 - val_accuracy: 0.4730\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 1.1855 - accuracy: 0.6060 - val_loss: 1.7753 - val_accuracy: 0.4662\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 1.1841 - accuracy: 0.6273 - val_loss: 1.7687 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 1.1678 - accuracy: 0.6444 - val_loss: 1.5685 - val_accuracy: 0.5541\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.0855 - accuracy: 0.6572 - val_loss: 1.6074 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.1280 - accuracy: 0.6337 - val_loss: 1.6889 - val_accuracy: 0.5270\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.0282 - accuracy: 0.6558 - val_loss: 2.1262 - val_accuracy: 0.4392\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.0454 - accuracy: 0.6700 - val_loss: 1.8640 - val_accuracy: 0.4324\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.9873 - accuracy: 0.6707 - val_loss: 1.8557 - val_accuracy: 0.5135\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.9910 - accuracy: 0.6792 - val_loss: 1.7966 - val_accuracy: 0.5338\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 0.9536 - accuracy: 0.6906 - val_loss: 1.5415 - val_accuracy: 0.5811\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.9990 - accuracy: 0.6835 - val_loss: 1.8048 - val_accuracy: 0.5135\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.9004 - accuracy: 0.6984 - val_loss: 1.7591 - val_accuracy: 0.4865\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.8793 - accuracy: 0.7020 - val_loss: 1.9547 - val_accuracy: 0.4595\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.7820 - accuracy: 0.7383 - val_loss: 1.7685 - val_accuracy: 0.4865\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.7627 - accuracy: 0.7504 - val_loss: 1.9211 - val_accuracy: 0.5203\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.8228 - accuracy: 0.7518 - val_loss: 1.8855 - val_accuracy: 0.5135\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.7787 - accuracy: 0.7440 - val_loss: 1.9532 - val_accuracy: 0.5541\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.7868 - accuracy: 0.7319 - val_loss: 2.1406 - val_accuracy: 0.4865\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.6835 - accuracy: 0.7674 - val_loss: 2.4387 - val_accuracy: 0.4324\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.7488 - accuracy: 0.7440 - val_loss: 2.1358 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.7739 - accuracy: 0.7397 - val_loss: 1.8341 - val_accuracy: 0.5405\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6967 - accuracy: 0.7760 - val_loss: 2.2574 - val_accuracy: 0.5270\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.6321 - accuracy: 0.7937 - val_loss: 1.9529 - val_accuracy: 0.5338\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.5990 - accuracy: 0.7980 - val_loss: 2.2519 - val_accuracy: 0.5338\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6326 - accuracy: 0.7781 - val_loss: 2.0748 - val_accuracy: 0.5473\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.5799 - accuracy: 0.8101 - val_loss: 2.2722 - val_accuracy: 0.4932\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.5990 - accuracy: 0.8023 - val_loss: 1.9422 - val_accuracy: 0.5338\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.6285 - accuracy: 0.7859 - val_loss: 1.9572 - val_accuracy: 0.4797\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.6475 - accuracy: 0.7930 - val_loss: 2.0712 - val_accuracy: 0.5405\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.5631 - accuracy: 0.8158 - val_loss: 2.2000 - val_accuracy: 0.5135\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_9_Nov21_04-53-07\\ckpts\\cp_31.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_9\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 8\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [256, 256]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_10: as seen in class, FC has 2 hidden layers of 256 units + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 2,266,724\n",
      "Trainable params: 2,266,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 72s 410ms/step - loss: 4.1082 - accuracy: 0.0555 - val_loss: 3.1137 - val_accuracy: 0.0676\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.9995 - accuracy: 0.0825 - val_loss: 2.8786 - val_accuracy: 0.0946\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 72s 406ms/step - loss: 2.8607 - accuracy: 0.1053 - val_loss: 2.7642 - val_accuracy: 0.1284\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 2.7790 - accuracy: 0.1131 - val_loss: 2.7221 - val_accuracy: 0.1284\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.7190 - accuracy: 0.1302 - val_loss: 2.7580 - val_accuracy: 0.1757\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.6908 - accuracy: 0.1472 - val_loss: 2.6613 - val_accuracy: 0.1284\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.6493 - accuracy: 0.1550 - val_loss: 2.6194 - val_accuracy: 0.1351\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.6362 - accuracy: 0.1536 - val_loss: 2.6011 - val_accuracy: 0.1892\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.6047 - accuracy: 0.1778 - val_loss: 2.5755 - val_accuracy: 0.1757\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.5778 - accuracy: 0.1871 - val_loss: 2.5728 - val_accuracy: 0.1824\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 2.5615 - accuracy: 0.1892 - val_loss: 2.6703 - val_accuracy: 0.1351\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.5405 - accuracy: 0.1885 - val_loss: 2.5831 - val_accuracy: 0.2162\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.5009 - accuracy: 0.2127 - val_loss: 2.6093 - val_accuracy: 0.1959\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 72s 406ms/step - loss: 2.5244 - accuracy: 0.2205 - val_loss: 2.5157 - val_accuracy: 0.2230\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.4603 - accuracy: 0.2454 - val_loss: 2.4528 - val_accuracy: 0.2365\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 2.4580 - accuracy: 0.2404 - val_loss: 2.3659 - val_accuracy: 0.2500\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.4025 - accuracy: 0.2475 - val_loss: 2.4172 - val_accuracy: 0.2432\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 2.3905 - accuracy: 0.2553 - val_loss: 2.4819 - val_accuracy: 0.2432\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.3619 - accuracy: 0.2809 - val_loss: 2.3805 - val_accuracy: 0.2162\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.3211 - accuracy: 0.2888 - val_loss: 2.3392 - val_accuracy: 0.2838\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.3394 - accuracy: 0.2767 - val_loss: 2.2994 - val_accuracy: 0.3108\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.2590 - accuracy: 0.3094 - val_loss: 2.2245 - val_accuracy: 0.2905\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.2398 - accuracy: 0.3186 - val_loss: 2.3079 - val_accuracy: 0.3378\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.2199 - accuracy: 0.3400 - val_loss: 2.1431 - val_accuracy: 0.3243\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 2.1954 - accuracy: 0.3421 - val_loss: 2.2113 - val_accuracy: 0.3649\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.1718 - accuracy: 0.3407 - val_loss: 2.0827 - val_accuracy: 0.3446\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.1544 - accuracy: 0.3499 - val_loss: 2.2326 - val_accuracy: 0.3716\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.1211 - accuracy: 0.3720 - val_loss: 2.1279 - val_accuracy: 0.3446\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 2.1300 - accuracy: 0.3691 - val_loss: 2.0824 - val_accuracy: 0.3784\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.0635 - accuracy: 0.3876 - val_loss: 2.0209 - val_accuracy: 0.3851\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.0145 - accuracy: 0.4083 - val_loss: 2.0773 - val_accuracy: 0.3243\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.0230 - accuracy: 0.3962 - val_loss: 2.1045 - val_accuracy: 0.3581\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.9684 - accuracy: 0.4175 - val_loss: 2.1083 - val_accuracy: 0.3649\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.9525 - accuracy: 0.4211 - val_loss: 2.1473 - val_accuracy: 0.3581\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 1.9771 - accuracy: 0.4111 - val_loss: 1.9989 - val_accuracy: 0.4459\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 1.9264 - accuracy: 0.4374 - val_loss: 1.9534 - val_accuracy: 0.3784\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 72s 406ms/step - loss: 1.8909 - accuracy: 0.4467 - val_loss: 1.9548 - val_accuracy: 0.3851\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.9176 - accuracy: 0.4417 - val_loss: 1.9764 - val_accuracy: 0.3919\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.8773 - accuracy: 0.4403 - val_loss: 1.9307 - val_accuracy: 0.4459\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.8873 - accuracy: 0.4552 - val_loss: 1.9208 - val_accuracy: 0.4122\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.8423 - accuracy: 0.4765 - val_loss: 1.8684 - val_accuracy: 0.4459\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 1.8383 - accuracy: 0.4637 - val_loss: 1.9830 - val_accuracy: 0.4730\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 1.8024 - accuracy: 0.4616 - val_loss: 2.0260 - val_accuracy: 0.4054\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 73s 417ms/step - loss: 1.8162 - accuracy: 0.4822 - val_loss: 1.9011 - val_accuracy: 0.3986\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 73s 414ms/step - loss: 1.7882 - accuracy: 0.4708 - val_loss: 1.8696 - val_accuracy: 0.4595\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 73s 417ms/step - loss: 1.7680 - accuracy: 0.4829 - val_loss: 1.9727 - val_accuracy: 0.4189\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 74s 419ms/step - loss: 1.7426 - accuracy: 0.4943 - val_loss: 1.9116 - val_accuracy: 0.5135\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 74s 419ms/step - loss: 1.7043 - accuracy: 0.5121 - val_loss: 1.9169 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.7385 - accuracy: 0.4915 - val_loss: 1.9391 - val_accuracy: 0.4730\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.7143 - accuracy: 0.5021 - val_loss: 1.8973 - val_accuracy: 0.5068\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.7163 - accuracy: 0.5092 - val_loss: 1.9723 - val_accuracy: 0.4595\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 1.6708 - accuracy: 0.5220 - val_loss: 1.7557 - val_accuracy: 0.5405\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.6442 - accuracy: 0.5306 - val_loss: 1.8687 - val_accuracy: 0.4595\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 72s 409ms/step - loss: 1.6320 - accuracy: 0.5228 - val_loss: 1.9537 - val_accuracy: 0.4459\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.6369 - accuracy: 0.5484 - val_loss: 2.0100 - val_accuracy: 0.4595\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 72s 409ms/step - loss: 1.6470 - accuracy: 0.5356 - val_loss: 2.0400 - val_accuracy: 0.4459\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 73s 416ms/step - loss: 1.5835 - accuracy: 0.5413 - val_loss: 1.9842 - val_accuracy: 0.4324\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 1.5848 - accuracy: 0.5498 - val_loss: 1.9441 - val_accuracy: 0.5135\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 1.6184 - accuracy: 0.5391 - val_loss: 1.9405 - val_accuracy: 0.4527\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 1.5441 - accuracy: 0.5477 - val_loss: 1.8794 - val_accuracy: 0.5203\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5809 - accuracy: 0.5576 - val_loss: 1.9734 - val_accuracy: 0.4662\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5753 - accuracy: 0.5469 - val_loss: 1.7964 - val_accuracy: 0.5405\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5617 - accuracy: 0.5576 - val_loss: 2.0551 - val_accuracy: 0.4189\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5429 - accuracy: 0.5519 - val_loss: 2.0688 - val_accuracy: 0.4189\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5050 - accuracy: 0.5846 - val_loss: 1.8669 - val_accuracy: 0.5068\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5527 - accuracy: 0.5640 - val_loss: 1.9348 - val_accuracy: 0.4865\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4778 - accuracy: 0.5925 - val_loss: 1.9028 - val_accuracy: 0.4595\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.5526 - accuracy: 0.5576 - val_loss: 1.9018 - val_accuracy: 0.5135\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5205 - accuracy: 0.5690 - val_loss: 1.8753 - val_accuracy: 0.5135\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4986 - accuracy: 0.5804 - val_loss: 2.1196 - val_accuracy: 0.4797\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 1.4732 - accuracy: 0.5967 - val_loss: 2.0280 - val_accuracy: 0.5541\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4930 - accuracy: 0.5789 - val_loss: 1.9945 - val_accuracy: 0.4730\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.4670 - accuracy: 0.5747 - val_loss: 1.8194 - val_accuracy: 0.5676\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4382 - accuracy: 0.6074 - val_loss: 1.8923 - val_accuracy: 0.4797\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4673 - accuracy: 0.5861 - val_loss: 1.9488 - val_accuracy: 0.5068\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4361 - accuracy: 0.6017 - val_loss: 2.2256 - val_accuracy: 0.5135\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4172 - accuracy: 0.6110 - val_loss: 1.9147 - val_accuracy: 0.4865\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4180 - accuracy: 0.6110 - val_loss: 1.8859 - val_accuracy: 0.5203\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4245 - accuracy: 0.6124 - val_loss: 1.8321 - val_accuracy: 0.4797\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4193 - accuracy: 0.6031 - val_loss: 2.1523 - val_accuracy: 0.4662\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 1.3974 - accuracy: 0.6159 - val_loss: 1.7192 - val_accuracy: 0.5878\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3737 - accuracy: 0.6110 - val_loss: 1.9075 - val_accuracy: 0.5068\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3938 - accuracy: 0.6088 - val_loss: 1.8439 - val_accuracy: 0.5473\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3976 - accuracy: 0.6053 - val_loss: 1.9369 - val_accuracy: 0.4932\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3703 - accuracy: 0.6323 - val_loss: 1.9971 - val_accuracy: 0.5203\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3868 - accuracy: 0.6216 - val_loss: 1.9004 - val_accuracy: 0.5473\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 72s 409ms/step - loss: 1.3503 - accuracy: 0.6287 - val_loss: 1.8992 - val_accuracy: 0.5676\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 72s 406ms/step - loss: 1.3882 - accuracy: 0.6046 - val_loss: 2.0163 - val_accuracy: 0.5068\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3661 - accuracy: 0.6159 - val_loss: 1.8874 - val_accuracy: 0.4865\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3384 - accuracy: 0.6323 - val_loss: 1.9764 - val_accuracy: 0.4730\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3694 - accuracy: 0.6216 - val_loss: 1.8220 - val_accuracy: 0.5270\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3244 - accuracy: 0.6302 - val_loss: 1.7486 - val_accuracy: 0.5270\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3723 - accuracy: 0.6259 - val_loss: 1.8243 - val_accuracy: 0.5135\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3536 - accuracy: 0.6273 - val_loss: 2.2214 - val_accuracy: 0.4932\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3265 - accuracy: 0.6373 - val_loss: 2.0034 - val_accuracy: 0.4797\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3418 - accuracy: 0.6330 - val_loss: 2.2096 - val_accuracy: 0.5135\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3096 - accuracy: 0.6472 - val_loss: 1.8850 - val_accuracy: 0.5270\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3499 - accuracy: 0.6266 - val_loss: 2.0334 - val_accuracy: 0.4797\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3434 - accuracy: 0.6174 - val_loss: 2.0085 - val_accuracy: 0.4797\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3082 - accuracy: 0.6358 - val_loss: 2.0868 - val_accuracy: 0.4932\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_10_Nov21_05-46-39\\ckpts\\cp_81.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_10\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 8\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [256, 256]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#alpha = 0.01\n",
    "#kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units, \n",
    "#                   kernel_regularizer = kernel_regularizer,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_11: start_num_filters = 16, fc_units = [256,256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 4,658,100\n",
      "Trainable params: 4,658,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 65s 370ms/step - loss: 2.9955 - accuracy: 0.0590 - val_loss: 2.9578 - val_accuracy: 0.0676\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 55s 315ms/step - loss: 2.9089 - accuracy: 0.0903 - val_loss: 2.7666 - val_accuracy: 0.1149\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 55s 313ms/step - loss: 2.7472 - accuracy: 0.1316 - val_loss: 2.6873 - val_accuracy: 0.1216\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 55s 313ms/step - loss: 2.6365 - accuracy: 0.1430 - val_loss: 2.6397 - val_accuracy: 0.1757\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 55s 313ms/step - loss: 2.5124 - accuracy: 0.2112 - val_loss: 2.4819 - val_accuracy: 0.1959\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 55s 312ms/step - loss: 2.3255 - accuracy: 0.2489 - val_loss: 2.3427 - val_accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 55s 315ms/step - loss: 2.1950 - accuracy: 0.2959 - val_loss: 2.1720 - val_accuracy: 0.3446\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 54s 309ms/step - loss: 2.0633 - accuracy: 0.3357 - val_loss: 2.1843 - val_accuracy: 0.2973\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 1.9643 - accuracy: 0.3499 - val_loss: 2.1824 - val_accuracy: 0.3041\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 55s 315ms/step - loss: 1.8649 - accuracy: 0.3997 - val_loss: 1.9479 - val_accuracy: 0.4324\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 54s 310ms/step - loss: 1.7772 - accuracy: 0.4303 - val_loss: 1.9884 - val_accuracy: 0.3851\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 55s 313ms/step - loss: 1.7001 - accuracy: 0.4623 - val_loss: 1.8268 - val_accuracy: 0.4459\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 54s 309ms/step - loss: 1.6508 - accuracy: 0.4723 - val_loss: 1.7894 - val_accuracy: 0.4257\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 54s 309ms/step - loss: 1.5860 - accuracy: 0.4893 - val_loss: 1.7735 - val_accuracy: 0.4189\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 55s 313ms/step - loss: 1.5065 - accuracy: 0.5206 - val_loss: 1.6903 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 55s 314ms/step - loss: 1.4820 - accuracy: 0.5100 - val_loss: 1.5715 - val_accuracy: 0.5068\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 55s 312ms/step - loss: 1.4101 - accuracy: 0.5533 - val_loss: 1.5540 - val_accuracy: 0.5338\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 54s 310ms/step - loss: 1.3868 - accuracy: 0.5597 - val_loss: 1.6572 - val_accuracy: 0.4932\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 54s 309ms/step - loss: 1.3383 - accuracy: 0.5669 - val_loss: 1.7247 - val_accuracy: 0.4932\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 54s 309ms/step - loss: 1.2644 - accuracy: 0.5953 - val_loss: 1.5680 - val_accuracy: 0.4797\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 1.2139 - accuracy: 0.6067 - val_loss: 1.6100 - val_accuracy: 0.4730\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 1.1500 - accuracy: 0.6337 - val_loss: 1.8330 - val_accuracy: 0.4459\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 1.1491 - accuracy: 0.6223 - val_loss: 1.6931 - val_accuracy: 0.5270\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 55s 313ms/step - loss: 1.0848 - accuracy: 0.6451 - val_loss: 1.5160 - val_accuracy: 0.5473\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 55s 313ms/step - loss: 1.0939 - accuracy: 0.6465 - val_loss: 1.5593 - val_accuracy: 0.5676\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 1.0123 - accuracy: 0.6721 - val_loss: 1.6146 - val_accuracy: 0.5541\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 54s 310ms/step - loss: 1.0117 - accuracy: 0.6807 - val_loss: 1.6783 - val_accuracy: 0.5135\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.9365 - accuracy: 0.6970 - val_loss: 1.6871 - val_accuracy: 0.5338\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.9543 - accuracy: 0.6899 - val_loss: 1.7727 - val_accuracy: 0.5473\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.8966 - accuracy: 0.7063 - val_loss: 1.8465 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.8997 - accuracy: 0.7084 - val_loss: 1.6044 - val_accuracy: 0.5135\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 55s 311ms/step - loss: 0.8466 - accuracy: 0.7248 - val_loss: 1.6608 - val_accuracy: 0.5338\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.8364 - accuracy: 0.7269 - val_loss: 1.7304 - val_accuracy: 0.5541\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.8246 - accuracy: 0.7240 - val_loss: 1.6341 - val_accuracy: 0.5270\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.8250 - accuracy: 0.7276 - val_loss: 1.9483 - val_accuracy: 0.4797\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 55s 313ms/step - loss: 0.7913 - accuracy: 0.7568 - val_loss: 1.6187 - val_accuracy: 0.5946\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 55s 311ms/step - loss: 0.7853 - accuracy: 0.7368 - val_loss: 1.7286 - val_accuracy: 0.5270\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 54s 309ms/step - loss: 0.7185 - accuracy: 0.7617 - val_loss: 1.7637 - val_accuracy: 0.5541\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.7107 - accuracy: 0.7696 - val_loss: 1.6991 - val_accuracy: 0.5405\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 54s 310ms/step - loss: 0.6770 - accuracy: 0.7760 - val_loss: 1.8620 - val_accuracy: 0.4932\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.6973 - accuracy: 0.7717 - val_loss: 1.7707 - val_accuracy: 0.5541\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 55s 312ms/step - loss: 0.5871 - accuracy: 0.8044 - val_loss: 1.6929 - val_accuracy: 0.6149\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.6006 - accuracy: 0.7980 - val_loss: 1.7940 - val_accuracy: 0.5203\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.6593 - accuracy: 0.7767 - val_loss: 1.8246 - val_accuracy: 0.4797\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.6526 - accuracy: 0.7838 - val_loss: 1.9602 - val_accuracy: 0.5541\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 54s 309ms/step - loss: 0.5774 - accuracy: 0.8065 - val_loss: 2.3040 - val_accuracy: 0.4865\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 54s 310ms/step - loss: 0.6152 - accuracy: 0.8065 - val_loss: 1.8231 - val_accuracy: 0.5676\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 55s 310ms/step - loss: 0.5335 - accuracy: 0.8158 - val_loss: 2.1913 - val_accuracy: 0.5338\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 55s 314ms/step - loss: 0.5656 - accuracy: 0.8080 - val_loss: 1.7665 - val_accuracy: 0.6216\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 54s 310ms/step - loss: 0.5054 - accuracy: 0.8265 - val_loss: 2.1604 - val_accuracy: 0.5676\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 55s 314ms/step - loss: 0.5114 - accuracy: 0.8343 - val_loss: 1.8183 - val_accuracy: 0.5608\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 58s 331ms/step - loss: 0.4799 - accuracy: 0.8457 - val_loss: 2.2772 - val_accuracy: 0.4865\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 57s 324ms/step - loss: 0.5423 - accuracy: 0.8151 - val_loss: 2.0782 - val_accuracy: 0.5743\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 60s 341ms/step - loss: 0.5202 - accuracy: 0.8236 - val_loss: 2.0526 - val_accuracy: 0.5203\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 60s 340ms/step - loss: 0.4905 - accuracy: 0.8378 - val_loss: 2.2131 - val_accuracy: 0.5405\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 59s 336ms/step - loss: 0.5289 - accuracy: 0.8229 - val_loss: 1.9301 - val_accuracy: 0.5608\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 58s 332ms/step - loss: 0.4501 - accuracy: 0.8684 - val_loss: 2.0864 - val_accuracy: 0.5676\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 58s 330ms/step - loss: 0.4212 - accuracy: 0.8620 - val_loss: 2.1710 - val_accuracy: 0.5743\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 59s 335ms/step - loss: 0.4626 - accuracy: 0.8385 - val_loss: 1.9044 - val_accuracy: 0.5473\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 60s 342ms/step - loss: 0.4374 - accuracy: 0.8528 - val_loss: 2.0293 - val_accuracy: 0.5270\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 59s 336ms/step - loss: 0.4027 - accuracy: 0.8634 - val_loss: 2.4412 - val_accuracy: 0.5405\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 59s 333ms/step - loss: 0.4498 - accuracy: 0.8528 - val_loss: 2.0725 - val_accuracy: 0.5878\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 58s 330ms/step - loss: 0.4820 - accuracy: 0.8329 - val_loss: 2.1134 - val_accuracy: 0.5541\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 58s 330ms/step - loss: 0.4114 - accuracy: 0.8656 - val_loss: 2.2226 - val_accuracy: 0.5473\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 58s 332ms/step - loss: 0.4818 - accuracy: 0.8485 - val_loss: 1.9602 - val_accuracy: 0.5541\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 63s 359ms/step - loss: 0.4311 - accuracy: 0.8578 - val_loss: 2.0254 - val_accuracy: 0.5811\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 68s 387ms/step - loss: 0.3558 - accuracy: 0.8862 - val_loss: 2.1257 - val_accuracy: 0.5541\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 61s 348ms/step - loss: 0.3909 - accuracy: 0.8727 - val_loss: 1.9626 - val_accuracy: 0.5878\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 58s 331ms/step - loss: 0.3749 - accuracy: 0.8869 - val_loss: 1.9753 - val_accuracy: 0.6014\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_11_Nov21_20-25-44\\ckpts\\cp_49.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_11\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 16\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [256, 256]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_12: start_num_filters = 16, fc_units = [256,256], regularization [REMOVED]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_13: start_num_filters = 16, conv_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 5,777,844\n",
      "Trainable params: 5,777,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 2.9950 - accuracy: 0.0555 - val_loss: 2.9819 - val_accuracy: 0.0676\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 63s 360ms/step - loss: 2.9909 - accuracy: 0.0633 - val_loss: 2.9704 - val_accuracy: 0.0676\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.9610 - accuracy: 0.0797 - val_loss: 2.8816 - val_accuracy: 0.1149\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 64s 365ms/step - loss: 2.7980 - accuracy: 0.1330 - val_loss: 2.6819 - val_accuracy: 0.1419\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 2.6859 - accuracy: 0.1323 - val_loss: 2.6196 - val_accuracy: 0.1757\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 65s 367ms/step - loss: 2.5777 - accuracy: 0.1849 - val_loss: 2.5288 - val_accuracy: 0.2027\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 63s 360ms/step - loss: 2.4823 - accuracy: 0.2226 - val_loss: 2.4280 - val_accuracy: 0.2027\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 66s 375ms/step - loss: 2.3560 - accuracy: 0.2646 - val_loss: 2.3690 - val_accuracy: 0.2297\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 65s 371ms/step - loss: 2.3103 - accuracy: 0.2624 - val_loss: 2.3033 - val_accuracy: 0.2635\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.1829 - accuracy: 0.3101 - val_loss: 2.1104 - val_accuracy: 0.3243\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.1267 - accuracy: 0.3257 - val_loss: 2.1030 - val_accuracy: 0.3649\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 64s 361ms/step - loss: 2.0165 - accuracy: 0.3663 - val_loss: 2.0136 - val_accuracy: 0.3919\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 63s 358ms/step - loss: 1.9768 - accuracy: 0.3755 - val_loss: 1.9577 - val_accuracy: 0.3851\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8547 - accuracy: 0.4168 - val_loss: 1.9201 - val_accuracy: 0.3986\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 64s 361ms/step - loss: 1.8030 - accuracy: 0.4225 - val_loss: 1.9499 - val_accuracy: 0.4189\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 63s 358ms/step - loss: 1.7234 - accuracy: 0.4580 - val_loss: 1.8355 - val_accuracy: 0.3986\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 63s 358ms/step - loss: 1.6680 - accuracy: 0.4780 - val_loss: 1.7018 - val_accuracy: 0.4595\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.5816 - accuracy: 0.4957 - val_loss: 1.8079 - val_accuracy: 0.4527\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.5607 - accuracy: 0.4929 - val_loss: 1.8902 - val_accuracy: 0.4392\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 63s 358ms/step - loss: 1.4905 - accuracy: 0.5128 - val_loss: 1.8467 - val_accuracy: 0.5135\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.4149 - accuracy: 0.5590 - val_loss: 1.6790 - val_accuracy: 0.4662\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.3805 - accuracy: 0.5583 - val_loss: 1.8432 - val_accuracy: 0.4527\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 63s 360ms/step - loss: 1.3661 - accuracy: 0.5683 - val_loss: 2.0239 - val_accuracy: 0.4527\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 63s 360ms/step - loss: 1.3170 - accuracy: 0.5789 - val_loss: 1.7670 - val_accuracy: 0.4797\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 1.2798 - accuracy: 0.5747 - val_loss: 1.8059 - val_accuracy: 0.4730\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.1991 - accuracy: 0.6159 - val_loss: 1.7197 - val_accuracy: 0.4730\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.1879 - accuracy: 0.6152 - val_loss: 1.6392 - val_accuracy: 0.4932\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 63s 360ms/step - loss: 1.1243 - accuracy: 0.6373 - val_loss: 1.8706 - val_accuracy: 0.5135\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 66s 374ms/step - loss: 1.0965 - accuracy: 0.6472 - val_loss: 1.8144 - val_accuracy: 0.4662\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 1.0927 - accuracy: 0.6515 - val_loss: 1.7367 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 65s 369ms/step - loss: 1.0652 - accuracy: 0.6664 - val_loss: 1.6368 - val_accuracy: 0.4797\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 65s 367ms/step - loss: 1.0024 - accuracy: 0.6664 - val_loss: 1.8419 - val_accuracy: 0.4797\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 0.9983 - accuracy: 0.6842 - val_loss: 1.7700 - val_accuracy: 0.4932\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 66s 374ms/step - loss: 0.9886 - accuracy: 0.6792 - val_loss: 1.7572 - val_accuracy: 0.5068\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 0.9047 - accuracy: 0.7176 - val_loss: 1.7585 - val_accuracy: 0.5203\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 0.8918 - accuracy: 0.6892 - val_loss: 1.6609 - val_accuracy: 0.5068\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 63s 360ms/step - loss: 0.9119 - accuracy: 0.7055 - val_loss: 1.7955 - val_accuracy: 0.4797\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 0.8989 - accuracy: 0.7063 - val_loss: 1.8384 - val_accuracy: 0.4595\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 0.7729 - accuracy: 0.7368 - val_loss: 2.0193 - val_accuracy: 0.4797\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 0.7944 - accuracy: 0.7390 - val_loss: 1.7775 - val_accuracy: 0.5878\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.7521 - accuracy: 0.7511 - val_loss: 1.7353 - val_accuracy: 0.5135\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 0.7241 - accuracy: 0.7660 - val_loss: 1.8376 - val_accuracy: 0.4662\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.7372 - accuracy: 0.7624 - val_loss: 1.8924 - val_accuracy: 0.5270\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 0.7480 - accuracy: 0.7489 - val_loss: 1.9153 - val_accuracy: 0.4797\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.6897 - accuracy: 0.7731 - val_loss: 1.8045 - val_accuracy: 0.5405\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6644 - accuracy: 0.7866 - val_loss: 1.8104 - val_accuracy: 0.5203\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6566 - accuracy: 0.7859 - val_loss: 1.7656 - val_accuracy: 0.5338\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 63s 359ms/step - loss: 0.6497 - accuracy: 0.7873 - val_loss: 1.8439 - val_accuracy: 0.5405\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6776 - accuracy: 0.7738 - val_loss: 1.8995 - val_accuracy: 0.5203\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6011 - accuracy: 0.7994 - val_loss: 1.7157 - val_accuracy: 0.5473\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6113 - accuracy: 0.7973 - val_loss: 1.7963 - val_accuracy: 0.5473\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.5402 - accuracy: 0.8172 - val_loss: 1.7713 - val_accuracy: 0.5608\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 0.5645 - accuracy: 0.8080 - val_loss: 1.9272 - val_accuracy: 0.5338\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.5956 - accuracy: 0.8044 - val_loss: 1.8821 - val_accuracy: 0.5338\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.5879 - accuracy: 0.8087 - val_loss: 2.2076 - val_accuracy: 0.4595\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 0.5864 - accuracy: 0.8030 - val_loss: 1.9416 - val_accuracy: 0.5135\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.5313 - accuracy: 0.8144 - val_loss: 2.0945 - val_accuracy: 0.5338\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 63s 358ms/step - loss: 0.5393 - accuracy: 0.8215 - val_loss: 2.2861 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 63s 358ms/step - loss: 0.5082 - accuracy: 0.8393 - val_loss: 1.9127 - val_accuracy: 0.5946\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.5198 - accuracy: 0.8265 - val_loss: 2.1825 - val_accuracy: 0.5338\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4696 - accuracy: 0.8407 - val_loss: 2.3040 - val_accuracy: 0.4797\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4778 - accuracy: 0.8514 - val_loss: 2.3760 - val_accuracy: 0.5270\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4705 - accuracy: 0.8414 - val_loss: 2.0631 - val_accuracy: 0.5676\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 0.4749 - accuracy: 0.8435 - val_loss: 1.9227 - val_accuracy: 0.5811\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.3847 - accuracy: 0.8691 - val_loss: 1.9370 - val_accuracy: 0.5608\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.5304 - accuracy: 0.8265 - val_loss: 2.1683 - val_accuracy: 0.5405\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4408 - accuracy: 0.8634 - val_loss: 2.0488 - val_accuracy: 0.5405\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4735 - accuracy: 0.8450 - val_loss: 2.0148 - val_accuracy: 0.5135\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.3703 - accuracy: 0.8933 - val_loss: 1.8507 - val_accuracy: 0.5676\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4203 - accuracy: 0.8585 - val_loss: 2.0057 - val_accuracy: 0.5473\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4313 - accuracy: 0.8649 - val_loss: 2.0109 - val_accuracy: 0.5135\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4360 - accuracy: 0.8677 - val_loss: 2.0622 - val_accuracy: 0.5608\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.3929 - accuracy: 0.8677 - val_loss: 2.1234 - val_accuracy: 0.5270\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.4007 - accuracy: 0.8720 - val_loss: 1.9984 - val_accuracy: 0.5541\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.3956 - accuracy: 0.8727 - val_loss: 2.7011 - val_accuracy: 0.5068\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 0.4182 - accuracy: 0.8620 - val_loss: 2.1638 - val_accuracy: 0.5338\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.3910 - accuracy: 0.8706 - val_loss: 2.3788 - val_accuracy: 0.5878\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.3760 - accuracy: 0.8777 - val_loss: 2.3460 - val_accuracy: 0.5473\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.3755 - accuracy: 0.8727 - val_loss: 2.2022 - val_accuracy: 0.5000\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_13_Nov21_21-51-06\\ckpts\\cp_59.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_13\"\n",
    "#conv_depth = 6\n",
    "#start_num_filters = 16\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_14: start_num_filters = 16, conv_depth = 6, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 5,777,844\n",
      "Trainable params: 5,777,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 90s 512ms/step - loss: 3.6362 - accuracy: 0.0569 - val_loss: 3.0053 - val_accuracy: 0.0676\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 2.9778 - accuracy: 0.0669 - val_loss: 2.9175 - val_accuracy: 0.0878\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 89s 505ms/step - loss: 2.8615 - accuracy: 0.0967 - val_loss: 2.7802 - val_accuracy: 0.1351\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 2.7862 - accuracy: 0.1166 - val_loss: 2.7224 - val_accuracy: 0.1284\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 2.7443 - accuracy: 0.1330 - val_loss: 2.7055 - val_accuracy: 0.1284\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 88s 500ms/step - loss: 2.7135 - accuracy: 0.1558 - val_loss: 2.6399 - val_accuracy: 0.1622\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 88s 502ms/step - loss: 2.6591 - accuracy: 0.1728 - val_loss: 2.6485 - val_accuracy: 0.1757\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 2.6017 - accuracy: 0.1956 - val_loss: 2.5808 - val_accuracy: 0.2500\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 2.5377 - accuracy: 0.2119 - val_loss: 2.4402 - val_accuracy: 0.2635\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 2.4788 - accuracy: 0.2482 - val_loss: 2.3758 - val_accuracy: 0.2973\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 2.4229 - accuracy: 0.2738 - val_loss: 2.4687 - val_accuracy: 0.2770\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 86s 490ms/step - loss: 2.3127 - accuracy: 0.3037 - val_loss: 2.4288 - val_accuracy: 0.2635\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 2.3033 - accuracy: 0.3108 - val_loss: 2.3671 - val_accuracy: 0.3446\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 87s 495ms/step - loss: 2.2508 - accuracy: 0.3186 - val_loss: 2.1469 - val_accuracy: 0.3581\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 2.1987 - accuracy: 0.3499 - val_loss: 2.2985 - val_accuracy: 0.3243\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 2.1494 - accuracy: 0.3528 - val_loss: 2.3493 - val_accuracy: 0.3176\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 2.0886 - accuracy: 0.3855 - val_loss: 2.2237 - val_accuracy: 0.3851\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 2.0382 - accuracy: 0.4061 - val_loss: 2.2922 - val_accuracy: 0.3784\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 1.9629 - accuracy: 0.4147 - val_loss: 1.9084 - val_accuracy: 0.4257\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.9101 - accuracy: 0.4395 - val_loss: 2.0302 - val_accuracy: 0.3919\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.9017 - accuracy: 0.4481 - val_loss: 2.3962 - val_accuracy: 0.3716\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 1.8781 - accuracy: 0.4701 - val_loss: 1.9420 - val_accuracy: 0.4797\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 1.8872 - accuracy: 0.4637 - val_loss: 1.9183 - val_accuracy: 0.4932\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.8077 - accuracy: 0.4772 - val_loss: 2.0839 - val_accuracy: 0.4122\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.7782 - accuracy: 0.4986 - val_loss: 1.9450 - val_accuracy: 0.4595\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.7014 - accuracy: 0.5114 - val_loss: 1.9622 - val_accuracy: 0.4797\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.7241 - accuracy: 0.5121 - val_loss: 2.3124 - val_accuracy: 0.4122\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.6399 - accuracy: 0.5469 - val_loss: 2.1749 - val_accuracy: 0.4662\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 87s 496ms/step - loss: 1.6833 - accuracy: 0.5327 - val_loss: 1.8569 - val_accuracy: 0.5405\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.6201 - accuracy: 0.5491 - val_loss: 1.9601 - val_accuracy: 0.5203\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.6008 - accuracy: 0.5533 - val_loss: 2.0469 - val_accuracy: 0.4865\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.5720 - accuracy: 0.5569 - val_loss: 2.0835 - val_accuracy: 0.4797\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.5125 - accuracy: 0.5832 - val_loss: 2.1465 - val_accuracy: 0.4797\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.4955 - accuracy: 0.5868 - val_loss: 1.8340 - val_accuracy: 0.5270\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.4806 - accuracy: 0.6003 - val_loss: 1.8944 - val_accuracy: 0.4932\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.4606 - accuracy: 0.5910 - val_loss: 1.9443 - val_accuracy: 0.5135\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.4681 - accuracy: 0.5839 - val_loss: 1.8116 - val_accuracy: 0.5270\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.3892 - accuracy: 0.6209 - val_loss: 1.9131 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.3646 - accuracy: 0.6316 - val_loss: 1.9033 - val_accuracy: 0.5135\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 88s 497ms/step - loss: 1.3547 - accuracy: 0.6373 - val_loss: 1.8266 - val_accuracy: 0.5473\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 1.3730 - accuracy: 0.6366 - val_loss: 1.9363 - val_accuracy: 0.5270\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.3382 - accuracy: 0.6387 - val_loss: 1.7646 - val_accuracy: 0.5338\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 1.2823 - accuracy: 0.6764 - val_loss: 1.9312 - val_accuracy: 0.5608\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 88s 501ms/step - loss: 1.3138 - accuracy: 0.6501 - val_loss: 2.0197 - val_accuracy: 0.5203\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.3003 - accuracy: 0.6430 - val_loss: 1.8582 - val_accuracy: 0.5473\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.2538 - accuracy: 0.6615 - val_loss: 1.6909 - val_accuracy: 0.5270\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 1.2334 - accuracy: 0.6693 - val_loss: 1.8559 - val_accuracy: 0.5405\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.2388 - accuracy: 0.6849 - val_loss: 2.1157 - val_accuracy: 0.4865\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 1.2550 - accuracy: 0.6735 - val_loss: 1.9110 - val_accuracy: 0.5878\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.2053 - accuracy: 0.6856 - val_loss: 2.0428 - val_accuracy: 0.5473\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 1.2123 - accuracy: 0.6835 - val_loss: 1.9281 - val_accuracy: 0.5270\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.1435 - accuracy: 0.7027 - val_loss: 1.7901 - val_accuracy: 0.5676\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.1780 - accuracy: 0.6906 - val_loss: 2.0864 - val_accuracy: 0.4932\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.1921 - accuracy: 0.7112 - val_loss: 1.9996 - val_accuracy: 0.5541\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.1374 - accuracy: 0.7183 - val_loss: 1.8229 - val_accuracy: 0.5135\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 1.1178 - accuracy: 0.7091 - val_loss: 1.9068 - val_accuracy: 0.5068\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 1.0928 - accuracy: 0.7262 - val_loss: 1.8902 - val_accuracy: 0.5338\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 1.0939 - accuracy: 0.7240 - val_loss: 1.9946 - val_accuracy: 0.4932\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.1588 - accuracy: 0.6984 - val_loss: 1.8001 - val_accuracy: 0.5811\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 1.1167 - accuracy: 0.7233 - val_loss: 2.0822 - val_accuracy: 0.5473\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.0512 - accuracy: 0.7176 - val_loss: 1.8054 - val_accuracy: 0.5541\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.0514 - accuracy: 0.7290 - val_loss: 2.1135 - val_accuracy: 0.5473\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 1.0573 - accuracy: 0.7248 - val_loss: 1.8316 - val_accuracy: 0.5946\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.0484 - accuracy: 0.7269 - val_loss: 1.9030 - val_accuracy: 0.4797\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 87s 492ms/step - loss: 1.0571 - accuracy: 0.7333 - val_loss: 2.0607 - val_accuracy: 0.5608\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.0570 - accuracy: 0.7319 - val_loss: 1.9602 - val_accuracy: 0.5946\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.0144 - accuracy: 0.7432 - val_loss: 1.9163 - val_accuracy: 0.5608\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.0206 - accuracy: 0.7454 - val_loss: 1.9701 - val_accuracy: 0.5608\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 88s 498ms/step - loss: 1.0327 - accuracy: 0.7368 - val_loss: 1.7614 - val_accuracy: 0.6081\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 1.0108 - accuracy: 0.7376 - val_loss: 2.0169 - val_accuracy: 0.5676\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 87s 495ms/step - loss: 0.9927 - accuracy: 0.7354 - val_loss: 1.8786 - val_accuracy: 0.5946\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.9609 - accuracy: 0.7624 - val_loss: 1.9667 - val_accuracy: 0.6081\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.9575 - accuracy: 0.7660 - val_loss: 1.9054 - val_accuracy: 0.5743\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 87s 497ms/step - loss: 0.9387 - accuracy: 0.7731 - val_loss: 1.7626 - val_accuracy: 0.6149\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 87s 496ms/step - loss: 0.9852 - accuracy: 0.7525 - val_loss: 1.6884 - val_accuracy: 0.6284\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.9221 - accuracy: 0.7639 - val_loss: 1.7747 - val_accuracy: 0.6216\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.9389 - accuracy: 0.7824 - val_loss: 1.8716 - val_accuracy: 0.5608\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.9125 - accuracy: 0.7809 - val_loss: 1.6210 - val_accuracy: 0.6216\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.9852 - accuracy: 0.7632 - val_loss: 2.0753 - val_accuracy: 0.5338\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.9807 - accuracy: 0.7596 - val_loss: 1.9005 - val_accuracy: 0.5811\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.8977 - accuracy: 0.7873 - val_loss: 2.0691 - val_accuracy: 0.5473\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.9117 - accuracy: 0.7809 - val_loss: 1.7334 - val_accuracy: 0.5608\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.8703 - accuracy: 0.7916 - val_loss: 2.1503 - val_accuracy: 0.5541\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.9379 - accuracy: 0.7560 - val_loss: 2.0058 - val_accuracy: 0.5878\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.8999 - accuracy: 0.7831 - val_loss: 2.0706 - val_accuracy: 0.5541\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.8835 - accuracy: 0.7852 - val_loss: 1.9337 - val_accuracy: 0.5541\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.8934 - accuracy: 0.7817 - val_loss: 2.1613 - val_accuracy: 0.5068\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.8484 - accuracy: 0.8044 - val_loss: 1.9936 - val_accuracy: 0.5946\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.8598 - accuracy: 0.7994 - val_loss: 1.8779 - val_accuracy: 0.5541\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.8523 - accuracy: 0.8001 - val_loss: 2.0444 - val_accuracy: 0.6014\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 87s 495ms/step - loss: 0.8912 - accuracy: 0.7788 - val_loss: 2.1079 - val_accuracy: 0.5473\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 87s 494ms/step - loss: 0.8771 - accuracy: 0.8001 - val_loss: 1.8220 - val_accuracy: 0.5878\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.8087 - accuracy: 0.8080 - val_loss: 1.8961 - val_accuracy: 0.5608\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.8528 - accuracy: 0.7916 - val_loss: 2.2032 - val_accuracy: 0.5405\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 87s 493ms/step - loss: 0.8445 - accuracy: 0.8094 - val_loss: 1.9504 - val_accuracy: 0.5743\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_14_Nov21_23-14-41\\ckpts\\cp_75.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_14\"\n",
    "#conv_depth = 6\n",
    "#start_num_filters = 16\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#alpha = 0.01\n",
    "#kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes,\n",
    "#                   kernel_regularizer = kernel_regularizer)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_15: start_num_filters = 16, kernel_size = (5,5) [REMOVED]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_16: start_num_filters = 16, dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 8,791,988\n",
      "Trainable params: 8,791,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/150\n",
      "176/176 [==============================] - 80s 456ms/step - loss: 2.9513 - accuracy: 0.0811 - val_loss: 2.7664 - val_accuracy: 0.0743\n",
      "Epoch 2/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.7364 - accuracy: 0.1259 - val_loss: 2.6022 - val_accuracy: 0.1351\n",
      "Epoch 3/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.5613 - accuracy: 0.2098 - val_loss: 2.4484 - val_accuracy: 0.2635\n",
      "Epoch 4/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 2.3597 - accuracy: 0.2589 - val_loss: 2.2379 - val_accuracy: 0.2770\n",
      "Epoch 5/150\n",
      "176/176 [==============================] - 66s 374ms/step - loss: 2.1994 - accuracy: 0.3158 - val_loss: 2.3835 - val_accuracy: 0.2365\n",
      "Epoch 6/150\n",
      "176/176 [==============================] - 69s 391ms/step - loss: 2.1109 - accuracy: 0.3293 - val_loss: 1.8660 - val_accuracy: 0.3986\n",
      "Epoch 7/150\n",
      "176/176 [==============================] - 75s 425ms/step - loss: 2.0338 - accuracy: 0.3841 - val_loss: 1.8189 - val_accuracy: 0.4189\n",
      "Epoch 8/150\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 1.9380 - accuracy: 0.3876 - val_loss: 1.8231 - val_accuracy: 0.4054\n",
      "Epoch 9/150\n",
      "176/176 [==============================] - 72s 409ms/step - loss: 1.8752 - accuracy: 0.4111 - val_loss: 1.9067 - val_accuracy: 0.3581\n",
      "Epoch 10/150\n",
      "176/176 [==============================] - 73s 414ms/step - loss: 1.8215 - accuracy: 0.4246 - val_loss: 1.7692 - val_accuracy: 0.4324\n",
      "Epoch 11/150\n",
      "176/176 [==============================] - 69s 391ms/step - loss: 1.7585 - accuracy: 0.4438 - val_loss: 1.8437 - val_accuracy: 0.4595\n",
      "Epoch 12/150\n",
      "176/176 [==============================] - 67s 378ms/step - loss: 1.6544 - accuracy: 0.4844 - val_loss: 1.8263 - val_accuracy: 0.4392\n",
      "Epoch 13/150\n",
      "176/176 [==============================] - 71s 402ms/step - loss: 1.6312 - accuracy: 0.4822 - val_loss: 1.5541 - val_accuracy: 0.5338\n",
      "Epoch 14/150\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.6009 - accuracy: 0.5007 - val_loss: 1.7446 - val_accuracy: 0.4865\n",
      "Epoch 15/150\n",
      "176/176 [==============================] - 70s 399ms/step - loss: 1.5435 - accuracy: 0.5164 - val_loss: 1.4967 - val_accuracy: 0.4932\n",
      "Epoch 16/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 1.4701 - accuracy: 0.5377 - val_loss: 1.5607 - val_accuracy: 0.4595\n",
      "Epoch 17/150\n",
      "176/176 [==============================] - 68s 385ms/step - loss: 1.4726 - accuracy: 0.5327 - val_loss: 1.5367 - val_accuracy: 0.5203\n",
      "Epoch 18/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 1.4322 - accuracy: 0.5505 - val_loss: 1.7111 - val_accuracy: 0.4797\n",
      "Epoch 19/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 1.3600 - accuracy: 0.5804 - val_loss: 1.5602 - val_accuracy: 0.5203\n",
      "Epoch 20/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 1.3004 - accuracy: 0.5967 - val_loss: 1.4094 - val_accuracy: 0.5270\n",
      "Epoch 21/150\n",
      "176/176 [==============================] - 68s 386ms/step - loss: 1.2866 - accuracy: 0.5932 - val_loss: 1.5402 - val_accuracy: 0.5608\n",
      "Epoch 22/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 1.2229 - accuracy: 0.6216 - val_loss: 1.6293 - val_accuracy: 0.5338\n",
      "Epoch 23/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 1.2549 - accuracy: 0.5910 - val_loss: 1.5708 - val_accuracy: 0.5270\n",
      "Epoch 24/150\n",
      "176/176 [==============================] - 68s 387ms/step - loss: 1.1939 - accuracy: 0.6238 - val_loss: 1.4398 - val_accuracy: 0.5743\n",
      "Epoch 25/150\n",
      "176/176 [==============================] - 68s 387ms/step - loss: 1.1539 - accuracy: 0.6437 - val_loss: 1.5131 - val_accuracy: 0.6014\n",
      "Epoch 26/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 1.1257 - accuracy: 0.6437 - val_loss: 1.6494 - val_accuracy: 0.4932\n",
      "Epoch 27/150\n",
      "176/176 [==============================] - 68s 386ms/step - loss: 1.1428 - accuracy: 0.6245 - val_loss: 1.5560 - val_accuracy: 0.5811\n",
      "Epoch 28/150\n",
      "176/176 [==============================] - 67s 379ms/step - loss: 1.0765 - accuracy: 0.6728 - val_loss: 1.5219 - val_accuracy: 0.5473\n",
      "Epoch 29/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 1.0568 - accuracy: 0.6622 - val_loss: 1.4393 - val_accuracy: 0.5878\n",
      "Epoch 30/150\n",
      "176/176 [==============================] - 67s 380ms/step - loss: 1.0103 - accuracy: 0.6906 - val_loss: 1.6307 - val_accuracy: 0.5405\n",
      "Epoch 31/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 1.0549 - accuracy: 0.6686 - val_loss: 1.7803 - val_accuracy: 0.5068\n",
      "Epoch 32/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 1.0143 - accuracy: 0.6792 - val_loss: 1.5500 - val_accuracy: 0.5203\n",
      "Epoch 33/150\n",
      "176/176 [==============================] - 67s 380ms/step - loss: 0.9937 - accuracy: 0.6778 - val_loss: 1.4881 - val_accuracy: 0.5743\n",
      "Epoch 34/150\n",
      "176/176 [==============================] - 68s 385ms/step - loss: 1.1251 - accuracy: 0.6401 - val_loss: 1.6842 - val_accuracy: 0.5405\n",
      "Epoch 35/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 1.0213 - accuracy: 0.6771 - val_loss: 1.8854 - val_accuracy: 0.4797\n",
      "Epoch 36/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.9877 - accuracy: 0.6785 - val_loss: 1.4623 - val_accuracy: 0.5541\n",
      "Epoch 37/150\n",
      "176/176 [==============================] - 67s 379ms/step - loss: 0.9126 - accuracy: 0.7091 - val_loss: 1.5651 - val_accuracy: 0.5676\n",
      "Epoch 38/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.8855 - accuracy: 0.7276 - val_loss: 1.6060 - val_accuracy: 0.5946\n",
      "Epoch 39/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.8562 - accuracy: 0.7312 - val_loss: 1.6058 - val_accuracy: 0.5608\n",
      "Epoch 40/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.9068 - accuracy: 0.7198 - val_loss: 1.7326 - val_accuracy: 0.5473\n",
      "Epoch 41/150\n",
      "176/176 [==============================] - 68s 388ms/step - loss: 0.8872 - accuracy: 0.7041 - val_loss: 1.5103 - val_accuracy: 0.6081\n",
      "Epoch 42/150\n",
      "176/176 [==============================] - 67s 380ms/step - loss: 0.8510 - accuracy: 0.7276 - val_loss: 1.8259 - val_accuracy: 0.5338\n",
      "Epoch 43/150\n",
      "176/176 [==============================] - 68s 387ms/step - loss: 0.8500 - accuracy: 0.7205 - val_loss: 1.4630 - val_accuracy: 0.6351\n",
      "Epoch 44/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 0.7986 - accuracy: 0.7340 - val_loss: 1.6468 - val_accuracy: 0.5541\n",
      "Epoch 45/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 0.8378 - accuracy: 0.7304 - val_loss: 1.8520 - val_accuracy: 0.5811\n",
      "Epoch 46/150\n",
      "176/176 [==============================] - 67s 380ms/step - loss: 0.8134 - accuracy: 0.7397 - val_loss: 2.0466 - val_accuracy: 0.5135\n",
      "Epoch 47/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.8119 - accuracy: 0.7368 - val_loss: 1.7149 - val_accuracy: 0.5946\n",
      "Epoch 48/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.7363 - accuracy: 0.7496 - val_loss: 1.4973 - val_accuracy: 0.5878\n",
      "Epoch 49/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 0.7764 - accuracy: 0.7496 - val_loss: 1.4987 - val_accuracy: 0.5676\n",
      "Epoch 50/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.7767 - accuracy: 0.7582 - val_loss: 1.6123 - val_accuracy: 0.5608\n",
      "Epoch 51/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 0.7809 - accuracy: 0.7532 - val_loss: 1.8101 - val_accuracy: 0.5878\n",
      "Epoch 52/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.7889 - accuracy: 0.7461 - val_loss: 1.6452 - val_accuracy: 0.6351\n",
      "Epoch 53/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 0.7331 - accuracy: 0.7674 - val_loss: 1.7702 - val_accuracy: 0.5743\n",
      "Epoch 54/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.7727 - accuracy: 0.7482 - val_loss: 1.6883 - val_accuracy: 0.5541\n",
      "Epoch 55/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.7806 - accuracy: 0.7617 - val_loss: 1.6954 - val_accuracy: 0.5473\n",
      "Epoch 56/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 0.6761 - accuracy: 0.7831 - val_loss: 1.8392 - val_accuracy: 0.5473\n",
      "Epoch 57/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.6923 - accuracy: 0.7667 - val_loss: 1.6300 - val_accuracy: 0.5878\n",
      "Epoch 58/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 0.7502 - accuracy: 0.7489 - val_loss: 1.6996 - val_accuracy: 0.5270\n",
      "Epoch 59/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.6762 - accuracy: 0.7831 - val_loss: 1.7631 - val_accuracy: 0.6081\n",
      "Epoch 60/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.6731 - accuracy: 0.7845 - val_loss: 1.6377 - val_accuracy: 0.6284\n",
      "Epoch 61/150\n",
      "176/176 [==============================] - 67s 380ms/step - loss: 0.6677 - accuracy: 0.7760 - val_loss: 1.8761 - val_accuracy: 0.5743\n",
      "Epoch 62/150\n",
      "176/176 [==============================] - 67s 381ms/step - loss: 0.6818 - accuracy: 0.7909 - val_loss: 1.5824 - val_accuracy: 0.6351\n",
      "Epoch 63/150\n",
      "176/176 [==============================] - 67s 380ms/step - loss: 0.6678 - accuracy: 0.7895 - val_loss: 1.8841 - val_accuracy: 0.6149\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_16_Nov24_20-05-21\\ckpts\\cp_43.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_16\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 16\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#dropout = 0.3\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes,\n",
    "#                   dropout = dropout)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_17: start_num_filters = 16, fc_units = [512, 512], dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 9,054,644\n",
      "Trainable params: 9,054,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/150\n",
      "176/176 [==============================] - 69s 395ms/step - loss: 2.9946 - accuracy: 0.0576 - val_loss: 2.9803 - val_accuracy: 0.0676\n",
      "Epoch 2/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 2.9801 - accuracy: 0.0626 - val_loss: 2.9664 - val_accuracy: 0.0676\n",
      "Epoch 3/150\n",
      "176/176 [==============================] - 69s 389ms/step - loss: 2.9196 - accuracy: 0.0761 - val_loss: 2.7226 - val_accuracy: 0.1351\n",
      "Epoch 4/150\n",
      "176/176 [==============================] - 69s 390ms/step - loss: 2.7748 - accuracy: 0.1138 - val_loss: 2.6876 - val_accuracy: 0.1554\n",
      "Epoch 5/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.6845 - accuracy: 0.1437 - val_loss: 2.6007 - val_accuracy: 0.1419\n",
      "Epoch 6/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 2.6222 - accuracy: 0.1764 - val_loss: 2.9405 - val_accuracy: 0.1486\n",
      "Epoch 7/150\n",
      "176/176 [==============================] - 69s 389ms/step - loss: 2.5289 - accuracy: 0.2041 - val_loss: 2.3538 - val_accuracy: 0.2230\n",
      "Epoch 8/150\n",
      "176/176 [==============================] - 69s 390ms/step - loss: 2.4647 - accuracy: 0.2226 - val_loss: 2.2840 - val_accuracy: 0.2703\n",
      "Epoch 9/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.3607 - accuracy: 0.2376 - val_loss: 2.2068 - val_accuracy: 0.2568\n",
      "Epoch 10/150\n",
      "176/176 [==============================] - 68s 389ms/step - loss: 2.2942 - accuracy: 0.2525 - val_loss: 2.2318 - val_accuracy: 0.3784\n",
      "Epoch 11/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.2353 - accuracy: 0.2923 - val_loss: 2.1186 - val_accuracy: 0.3649\n",
      "Epoch 12/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.1955 - accuracy: 0.3051 - val_loss: 2.0250 - val_accuracy: 0.3649\n",
      "Epoch 13/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.1203 - accuracy: 0.3329 - val_loss: 2.0972 - val_accuracy: 0.3243\n",
      "Epoch 14/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.1072 - accuracy: 0.3400 - val_loss: 2.0589 - val_accuracy: 0.3649\n",
      "Epoch 15/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 2.0111 - accuracy: 0.3549 - val_loss: 2.0491 - val_accuracy: 0.3243\n",
      "Epoch 16/150\n",
      "176/176 [==============================] - 69s 390ms/step - loss: 1.9408 - accuracy: 0.3613 - val_loss: 1.9961 - val_accuracy: 0.4122\n",
      "Epoch 17/150\n",
      "176/176 [==============================] - 69s 390ms/step - loss: 1.9183 - accuracy: 0.3670 - val_loss: 1.8572 - val_accuracy: 0.4459\n",
      "Epoch 18/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 1.8768 - accuracy: 0.4104 - val_loss: 1.8589 - val_accuracy: 0.4392\n",
      "Epoch 19/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.8572 - accuracy: 0.4132 - val_loss: 1.8496 - val_accuracy: 0.4257\n",
      "Epoch 20/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.8229 - accuracy: 0.4083 - val_loss: 2.0414 - val_accuracy: 0.3784\n",
      "Epoch 21/150\n",
      "176/176 [==============================] - 68s 386ms/step - loss: 1.7603 - accuracy: 0.4267 - val_loss: 1.9917 - val_accuracy: 0.3986\n",
      "Epoch 22/150\n",
      "176/176 [==============================] - 69s 390ms/step - loss: 1.7092 - accuracy: 0.4772 - val_loss: 1.7678 - val_accuracy: 0.4662\n",
      "Epoch 23/150\n",
      "176/176 [==============================] - 69s 391ms/step - loss: 1.6949 - accuracy: 0.4673 - val_loss: 1.6551 - val_accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "176/176 [==============================] - 69s 391ms/step - loss: 1.6556 - accuracy: 0.4701 - val_loss: 1.6578 - val_accuracy: 0.5068\n",
      "Epoch 25/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.6157 - accuracy: 0.4765 - val_loss: 1.8609 - val_accuracy: 0.4595\n",
      "Epoch 26/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.6178 - accuracy: 0.4936 - val_loss: 1.7826 - val_accuracy: 0.5000\n",
      "Epoch 27/150\n",
      "176/176 [==============================] - 68s 385ms/step - loss: 1.5896 - accuracy: 0.5057 - val_loss: 1.7619 - val_accuracy: 0.4797\n",
      "Epoch 28/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.5609 - accuracy: 0.5149 - val_loss: 1.6184 - val_accuracy: 0.5068\n",
      "Epoch 29/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.5135 - accuracy: 0.5156 - val_loss: 1.5617 - val_accuracy: 0.5000\n",
      "Epoch 30/150\n",
      "176/176 [==============================] - 69s 391ms/step - loss: 1.4525 - accuracy: 0.5533 - val_loss: 1.5941 - val_accuracy: 0.5541\n",
      "Epoch 31/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.4792 - accuracy: 0.5256 - val_loss: 1.5598 - val_accuracy: 0.4865\n",
      "Epoch 32/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.4736 - accuracy: 0.5284 - val_loss: 1.7250 - val_accuracy: 0.4797\n",
      "Epoch 33/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.4006 - accuracy: 0.5640 - val_loss: 1.4831 - val_accuracy: 0.5541\n",
      "Epoch 34/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.3960 - accuracy: 0.5519 - val_loss: 1.6819 - val_accuracy: 0.5270\n",
      "Epoch 35/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.3840 - accuracy: 0.5526 - val_loss: 1.5869 - val_accuracy: 0.5270\n",
      "Epoch 36/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.3843 - accuracy: 0.5541 - val_loss: 1.6826 - val_accuracy: 0.5338\n",
      "Epoch 37/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.3282 - accuracy: 0.5619 - val_loss: 1.5750 - val_accuracy: 0.5203\n",
      "Epoch 38/150\n",
      "176/176 [==============================] - 68s 385ms/step - loss: 1.3222 - accuracy: 0.5846 - val_loss: 1.6776 - val_accuracy: 0.4797\n",
      "Epoch 39/150\n",
      "176/176 [==============================] - 68s 385ms/step - loss: 1.3058 - accuracy: 0.5832 - val_loss: 1.5852 - val_accuracy: 0.5338\n",
      "Epoch 40/150\n",
      "176/176 [==============================] - 68s 385ms/step - loss: 1.2870 - accuracy: 0.5925 - val_loss: 1.5304 - val_accuracy: 0.5203\n",
      "Epoch 41/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.2811 - accuracy: 0.5967 - val_loss: 1.6959 - val_accuracy: 0.5338\n",
      "Epoch 42/150\n",
      "176/176 [==============================] - 68s 385ms/step - loss: 1.2349 - accuracy: 0.6024 - val_loss: 1.6156 - val_accuracy: 0.4730\n",
      "Epoch 43/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.2456 - accuracy: 0.6038 - val_loss: 1.6077 - val_accuracy: 0.5338\n",
      "Epoch 44/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.2628 - accuracy: 0.5946 - val_loss: 1.5442 - val_accuracy: 0.5135\n",
      "Epoch 45/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.2080 - accuracy: 0.6380 - val_loss: 1.6012 - val_accuracy: 0.4932\n",
      "Epoch 46/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.2331 - accuracy: 0.6174 - val_loss: 1.5928 - val_accuracy: 0.5473\n",
      "Epoch 47/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.1943 - accuracy: 0.6245 - val_loss: 1.5268 - val_accuracy: 0.5541\n",
      "Epoch 48/150\n",
      "176/176 [==============================] - 69s 390ms/step - loss: 1.1546 - accuracy: 0.6380 - val_loss: 1.3344 - val_accuracy: 0.5946\n",
      "Epoch 49/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 1.1055 - accuracy: 0.6444 - val_loss: 1.5798 - val_accuracy: 0.5473\n",
      "Epoch 50/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.1675 - accuracy: 0.6287 - val_loss: 1.5232 - val_accuracy: 0.5608\n",
      "Epoch 51/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.1347 - accuracy: 0.6529 - val_loss: 1.5517 - val_accuracy: 0.5338\n",
      "Epoch 52/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.1917 - accuracy: 0.6302 - val_loss: 1.5462 - val_accuracy: 0.5608\n",
      "Epoch 53/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.1314 - accuracy: 0.6394 - val_loss: 1.6129 - val_accuracy: 0.5338\n",
      "Epoch 54/150\n",
      "176/176 [==============================] - 68s 385ms/step - loss: 1.0864 - accuracy: 0.6550 - val_loss: 1.4749 - val_accuracy: 0.5541\n",
      "Epoch 55/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.0801 - accuracy: 0.6650 - val_loss: 1.5589 - val_accuracy: 0.5338\n",
      "Epoch 56/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.0826 - accuracy: 0.6494 - val_loss: 1.6915 - val_accuracy: 0.5608\n",
      "Epoch 57/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 1.0921 - accuracy: 0.6451 - val_loss: 1.5428 - val_accuracy: 0.5135\n",
      "Epoch 58/150\n",
      "176/176 [==============================] - 68s 384ms/step - loss: 1.1075 - accuracy: 0.6472 - val_loss: 1.7172 - val_accuracy: 0.4865\n",
      "Epoch 59/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 1.0227 - accuracy: 0.6615 - val_loss: 1.5665 - val_accuracy: 0.5135\n",
      "Epoch 60/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 1.0331 - accuracy: 0.6764 - val_loss: 1.4384 - val_accuracy: 0.5608\n",
      "Epoch 61/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 1.0238 - accuracy: 0.6920 - val_loss: 1.5324 - val_accuracy: 0.5473\n",
      "Epoch 62/150\n",
      "176/176 [==============================] - 68s 389ms/step - loss: 0.9815 - accuracy: 0.6885 - val_loss: 1.3017 - val_accuracy: 0.6081\n",
      "Epoch 63/150\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 1.0292 - accuracy: 0.6764 - val_loss: 1.5359 - val_accuracy: 0.5608\n",
      "Epoch 64/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 1.0132 - accuracy: 0.6757 - val_loss: 1.5210 - val_accuracy: 0.5946\n",
      "Epoch 65/150\n",
      "176/176 [==============================] - 67s 383ms/step - loss: 0.9922 - accuracy: 0.6821 - val_loss: 1.6727 - val_accuracy: 0.5270\n",
      "Epoch 66/150\n",
      "176/176 [==============================] - 71s 401ms/step - loss: 0.9846 - accuracy: 0.6799 - val_loss: 1.5824 - val_accuracy: 0.5811\n",
      "Epoch 67/150\n",
      "176/176 [==============================] - 73s 417ms/step - loss: 0.9828 - accuracy: 0.6871 - val_loss: 1.4233 - val_accuracy: 0.6014\n",
      "Epoch 68/150\n",
      "176/176 [==============================] - 73s 415ms/step - loss: 0.9325 - accuracy: 0.7077 - val_loss: 1.5174 - val_accuracy: 0.5541\n",
      "Epoch 69/150\n",
      "176/176 [==============================] - 73s 414ms/step - loss: 0.9649 - accuracy: 0.6863 - val_loss: 1.5475 - val_accuracy: 0.5203\n",
      "Epoch 70/150\n",
      "176/176 [==============================] - 72s 411ms/step - loss: 0.9558 - accuracy: 0.6835 - val_loss: 1.4135 - val_accuracy: 0.5946\n",
      "Epoch 71/150\n",
      "176/176 [==============================] - 72s 410ms/step - loss: 1.0000 - accuracy: 0.6814 - val_loss: 1.6149 - val_accuracy: 0.5541\n",
      "Epoch 72/150\n",
      "176/176 [==============================] - 72s 410ms/step - loss: 0.9627 - accuracy: 0.6977 - val_loss: 1.7829 - val_accuracy: 0.5135\n",
      "Epoch 73/150\n",
      "176/176 [==============================] - 72s 411ms/step - loss: 0.9541 - accuracy: 0.6849 - val_loss: 1.4617 - val_accuracy: 0.5811\n",
      "Epoch 74/150\n",
      "176/176 [==============================] - 72s 410ms/step - loss: 0.9157 - accuracy: 0.7098 - val_loss: 1.5420 - val_accuracy: 0.5743\n",
      "Epoch 75/150\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 0.9483 - accuracy: 0.7148 - val_loss: 1.5572 - val_accuracy: 0.5608\n",
      "Epoch 76/150\n",
      "176/176 [==============================] - 72s 409ms/step - loss: 0.8959 - accuracy: 0.7077 - val_loss: 1.6201 - val_accuracy: 0.5473\n",
      "Epoch 77/150\n",
      "176/176 [==============================] - 73s 414ms/step - loss: 0.9542 - accuracy: 0.7183 - val_loss: 1.4644 - val_accuracy: 0.5608\n",
      "Epoch 78/150\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 0.9424 - accuracy: 0.7162 - val_loss: 1.6565 - val_accuracy: 0.5135\n",
      "Epoch 79/150\n",
      "176/176 [==============================] - 74s 418ms/step - loss: 0.8678 - accuracy: 0.7183 - val_loss: 1.5019 - val_accuracy: 0.5743\n",
      "Epoch 80/150\n",
      "176/176 [==============================] - 74s 418ms/step - loss: 0.9102 - accuracy: 0.7233 - val_loss: 1.8386 - val_accuracy: 0.5270\n",
      "Epoch 81/150\n",
      "176/176 [==============================] - 73s 415ms/step - loss: 0.8858 - accuracy: 0.7148 - val_loss: 1.4857 - val_accuracy: 0.5203\n",
      "Epoch 82/150\n",
      "176/176 [==============================] - 73s 414ms/step - loss: 0.8433 - accuracy: 0.7397 - val_loss: 1.6150 - val_accuracy: 0.5608\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_17_Nov24_21-17-03\\ckpts\\cp_62.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_17\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 16\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512, 512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#dropout = 0.3\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes,\n",
    "#                   dropout = dropout)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_18: start_num_filters = 16, dropout = 0.3, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 8,791,988\n",
      "Trainable params: 8,791,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 73s 415ms/step - loss: 3.6434 - accuracy: 0.0619 - val_loss: 3.0532 - val_accuracy: 0.0676\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 3.0177 - accuracy: 0.0512 - val_loss: 2.9944 - val_accuracy: 0.0405\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 67s 382ms/step - loss: 2.9990 - accuracy: 0.0740 - val_loss: 2.9165 - val_accuracy: 0.1149\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 65s 367ms/step - loss: 2.8823 - accuracy: 0.1095 - val_loss: 2.7886 - val_accuracy: 0.1622\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 63s 359ms/step - loss: 2.8078 - accuracy: 0.1302 - val_loss: 2.6780 - val_accuracy: 0.1216\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 63s 359ms/step - loss: 2.7966 - accuracy: 0.1451 - val_loss: 2.7421 - val_accuracy: 0.1284\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 69s 394ms/step - loss: 2.7383 - accuracy: 0.1394 - val_loss: 2.6554 - val_accuracy: 0.1351\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 68s 386ms/step - loss: 2.7165 - accuracy: 0.1508 - val_loss: 2.6836 - val_accuracy: 0.1419\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.7192 - accuracy: 0.1600 - val_loss: 2.6093 - val_accuracy: 0.1689\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 70s 398ms/step - loss: 2.6921 - accuracy: 0.1671 - val_loss: 2.6015 - val_accuracy: 0.1959\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 66s 376ms/step - loss: 2.6821 - accuracy: 0.1821 - val_loss: 2.5203 - val_accuracy: 0.2770\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 63s 358ms/step - loss: 2.6040 - accuracy: 0.2105 - val_loss: 2.4806 - val_accuracy: 0.2635\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 2.5646 - accuracy: 0.2347 - val_loss: 2.4018 - val_accuracy: 0.2905\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 2.5748 - accuracy: 0.2418 - val_loss: 2.3175 - val_accuracy: 0.2973\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 63s 359ms/step - loss: 2.5072 - accuracy: 0.2489 - val_loss: 2.4239 - val_accuracy: 0.2500\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 2.5260 - accuracy: 0.2539 - val_loss: 2.3903 - val_accuracy: 0.2635\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 2.5121 - accuracy: 0.2589 - val_loss: 2.4174 - val_accuracy: 0.2973\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 2.4887 - accuracy: 0.2653 - val_loss: 2.3612 - val_accuracy: 0.3176\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 64s 365ms/step - loss: 2.4912 - accuracy: 0.2738 - val_loss: 2.2727 - val_accuracy: 0.3378\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 63s 358ms/step - loss: 2.4933 - accuracy: 0.2859 - val_loss: 2.2275 - val_accuracy: 0.3041\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 63s 359ms/step - loss: 2.4433 - accuracy: 0.2752 - val_loss: 2.3297 - val_accuracy: 0.3311\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 64s 365ms/step - loss: 2.4596 - accuracy: 0.2973 - val_loss: 2.2701 - val_accuracy: 0.3851\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 63s 359ms/step - loss: 2.4083 - accuracy: 0.2895 - val_loss: 2.2236 - val_accuracy: 0.3716\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 63s 359ms/step - loss: 2.4053 - accuracy: 0.3279 - val_loss: 2.2892 - val_accuracy: 0.3581\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 63s 360ms/step - loss: 2.4270 - accuracy: 0.3329 - val_loss: 2.3223 - val_accuracy: 0.3378\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 63s 360ms/step - loss: 2.3683 - accuracy: 0.3364 - val_loss: 2.1928 - val_accuracy: 0.3716\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 65s 367ms/step - loss: 2.3950 - accuracy: 0.3400 - val_loss: 2.1827 - val_accuracy: 0.4122\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 2.3828 - accuracy: 0.3257 - val_loss: 2.1525 - val_accuracy: 0.4324\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 65s 369ms/step - loss: 2.2742 - accuracy: 0.3599 - val_loss: 2.1189 - val_accuracy: 0.4662\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 2.2382 - accuracy: 0.3826 - val_loss: 2.2930 - val_accuracy: 0.3581\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.2899 - accuracy: 0.3656 - val_loss: 2.2730 - val_accuracy: 0.4122\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.2228 - accuracy: 0.3734 - val_loss: 2.1639 - val_accuracy: 0.4595\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 65s 367ms/step - loss: 2.2231 - accuracy: 0.3940 - val_loss: 2.0609 - val_accuracy: 0.4797\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.1910 - accuracy: 0.4090 - val_loss: 2.1810 - val_accuracy: 0.4595\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 64s 361ms/step - loss: 2.1540 - accuracy: 0.4196 - val_loss: 2.1107 - val_accuracy: 0.4527\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 64s 361ms/step - loss: 2.1631 - accuracy: 0.4189 - val_loss: 2.1414 - val_accuracy: 0.4257\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 2.0854 - accuracy: 0.4310 - val_loss: 2.1940 - val_accuracy: 0.4932\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 2.1255 - accuracy: 0.4346 - val_loss: 2.0296 - val_accuracy: 0.4257\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 64s 364ms/step - loss: 2.0727 - accuracy: 0.4516 - val_loss: 2.1218 - val_accuracy: 0.4257\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 2.1003 - accuracy: 0.4374 - val_loss: 2.0193 - val_accuracy: 0.5135\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 2.0848 - accuracy: 0.4481 - val_loss: 2.0173 - val_accuracy: 0.4797\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 2.0508 - accuracy: 0.4523 - val_loss: 2.1731 - val_accuracy: 0.4527\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 65s 369ms/step - loss: 2.0262 - accuracy: 0.4708 - val_loss: 2.0649 - val_accuracy: 0.5541\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.0289 - accuracy: 0.4659 - val_loss: 2.0095 - val_accuracy: 0.5270\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.0093 - accuracy: 0.4751 - val_loss: 2.0422 - val_accuracy: 0.4865\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.0408 - accuracy: 0.4602 - val_loss: 1.9467 - val_accuracy: 0.5270\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.0228 - accuracy: 0.4694 - val_loss: 2.1215 - val_accuracy: 0.5135\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.9896 - accuracy: 0.4758 - val_loss: 2.0564 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 1.9629 - accuracy: 0.4630 - val_loss: 2.0129 - val_accuracy: 0.4797\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 1.9420 - accuracy: 0.4780 - val_loss: 1.9045 - val_accuracy: 0.4932\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 65s 369ms/step - loss: 1.9430 - accuracy: 0.5036 - val_loss: 2.0543 - val_accuracy: 0.4865\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.9491 - accuracy: 0.4908 - val_loss: 2.0046 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8966 - accuracy: 0.5164 - val_loss: 1.9557 - val_accuracy: 0.5473\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.9102 - accuracy: 0.5171 - val_loss: 1.8640 - val_accuracy: 0.5405\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 1.8882 - accuracy: 0.5000 - val_loss: 1.9108 - val_accuracy: 0.5270\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.9440 - accuracy: 0.5220 - val_loss: 2.0344 - val_accuracy: 0.5203\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 1.8889 - accuracy: 0.5135 - val_loss: 2.0338 - val_accuracy: 0.5743\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 1.9563 - accuracy: 0.5007 - val_loss: 2.0413 - val_accuracy: 0.5068\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8366 - accuracy: 0.5498 - val_loss: 1.9679 - val_accuracy: 0.5135\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.9641 - accuracy: 0.5128 - val_loss: 1.9476 - val_accuracy: 0.5203\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8965 - accuracy: 0.5128 - val_loss: 2.0792 - val_accuracy: 0.5068\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 64s 361ms/step - loss: 1.8893 - accuracy: 0.5206 - val_loss: 1.9223 - val_accuracy: 0.5676\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 64s 364ms/step - loss: 1.8501 - accuracy: 0.5391 - val_loss: 1.9049 - val_accuracy: 0.5676\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.9472 - accuracy: 0.5213 - val_loss: 2.0693 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 64s 361ms/step - loss: 1.9268 - accuracy: 0.5256 - val_loss: 2.0770 - val_accuracy: 0.5608\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8767 - accuracy: 0.5277 - val_loss: 1.9650 - val_accuracy: 0.5338\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8102 - accuracy: 0.5363 - val_loss: 2.0280 - val_accuracy: 0.5338\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8304 - accuracy: 0.5100 - val_loss: 1.8877 - val_accuracy: 0.5405\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.7706 - accuracy: 0.5612 - val_loss: 2.0766 - val_accuracy: 0.5541\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 64s 361ms/step - loss: 1.8447 - accuracy: 0.5498 - val_loss: 1.9193 - val_accuracy: 0.5541\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8254 - accuracy: 0.5491 - val_loss: 2.0180 - val_accuracy: 0.5405\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 1.7903 - accuracy: 0.5747 - val_loss: 2.0727 - val_accuracy: 0.5878\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8025 - accuracy: 0.5654 - val_loss: 1.9154 - val_accuracy: 0.5338\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.7801 - accuracy: 0.5690 - val_loss: 2.1042 - val_accuracy: 0.5203\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.7485 - accuracy: 0.5832 - val_loss: 2.0835 - val_accuracy: 0.5135\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.8133 - accuracy: 0.5725 - val_loss: 2.0834 - val_accuracy: 0.5743\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 64s 364ms/step - loss: 1.7709 - accuracy: 0.5782 - val_loss: 2.1443 - val_accuracy: 0.5270\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 1.7740 - accuracy: 0.5789 - val_loss: 1.9668 - val_accuracy: 0.5946\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 1.7904 - accuracy: 0.5697 - val_loss: 1.9856 - val_accuracy: 0.5270\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 1.7278 - accuracy: 0.5917 - val_loss: 2.0608 - val_accuracy: 0.5338\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 1.7753 - accuracy: 0.5789 - val_loss: 2.0616 - val_accuracy: 0.5338\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.7866 - accuracy: 0.5832 - val_loss: 1.9127 - val_accuracy: 0.5676\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.7043 - accuracy: 0.5925 - val_loss: 2.1184 - val_accuracy: 0.5338\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 64s 363ms/step - loss: 1.7222 - accuracy: 0.5932 - val_loss: 2.1065 - val_accuracy: 0.5541\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.7593 - accuracy: 0.5761 - val_loss: 2.4900 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 1.8295 - accuracy: 0.5740 - val_loss: 1.9449 - val_accuracy: 0.6014\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 64s 364ms/step - loss: 1.6703 - accuracy: 0.6024 - val_loss: 2.0342 - val_accuracy: 0.5473\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 65s 368ms/step - loss: 1.7405 - accuracy: 0.5818 - val_loss: 1.9969 - val_accuracy: 0.5878\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 64s 364ms/step - loss: 1.7164 - accuracy: 0.5925 - val_loss: 2.1456 - val_accuracy: 0.5068\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.7542 - accuracy: 0.5896 - val_loss: 2.2130 - val_accuracy: 0.5608\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 1.7796 - accuracy: 0.5761 - val_loss: 2.3233 - val_accuracy: 0.4797\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 67s 380ms/step - loss: 1.7602 - accuracy: 0.5896 - val_loss: 1.9737 - val_accuracy: 0.6486\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 65s 372ms/step - loss: 1.7362 - accuracy: 0.6067 - val_loss: 2.1877 - val_accuracy: 0.5608\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 65s 369ms/step - loss: 1.6861 - accuracy: 0.6060 - val_loss: 2.1321 - val_accuracy: 0.5743\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 1.7190 - accuracy: 0.5917 - val_loss: 2.0105 - val_accuracy: 0.5338\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 1.7086 - accuracy: 0.6017 - val_loss: 2.0341 - val_accuracy: 0.5811\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 64s 366ms/step - loss: 1.6835 - accuracy: 0.6088 - val_loss: 1.9781 - val_accuracy: 0.5811\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 64s 365ms/step - loss: 1.6831 - accuracy: 0.6166 - val_loss: 2.1506 - val_accuracy: 0.5878\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 64s 365ms/step - loss: 1.6801 - accuracy: 0.6209 - val_loss: 1.9952 - val_accuracy: 0.5473\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 64s 365ms/step - loss: 1.6755 - accuracy: 0.6159 - val_loss: 2.0128 - val_accuracy: 0.5541\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_18_Nov23_15-42-22\\ckpts\\cp_92.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"CNN_18\"\n",
    "#conv_depth = 5\n",
    "#start_num_filters = 16\n",
    "#kernel_size = (3, 3)\n",
    "#pool_size = (2, 2)\n",
    "#fc_units = [512]\n",
    "#num_classes = len(classes)\n",
    "#\n",
    "#dropout = 0.3\n",
    "#alpha = 0.01\n",
    "#kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "#\n",
    "#lr = 1e-3\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "#loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#metrics = ['accuracy']\n",
    "#\n",
    "#model = build_model(input_shape = (img_w, img_h, 3),\n",
    "#                   conv_depth = conv_depth,\n",
    "#                   start_num_filters = start_num_filters,\n",
    "#                   kernel_size = kernel_size,\n",
    "#                   pool_size = pool_size,\n",
    "#                   fc_units = fc_units,\n",
    "#                   num_classes = num_classes,\n",
    "#                   kernel_regularizer = kernel_regularizer,\n",
    "#                   dropout = dropout)\n",
    "#\n",
    "#model.compile(optimizer = optimizer,\n",
    "#             loss = loss,\n",
    "#             metrics = metrics)\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "#\n",
    "#predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
