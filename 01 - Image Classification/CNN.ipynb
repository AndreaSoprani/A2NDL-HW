{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Found 1406 images belonging to 20 classes.\n",
      "\n",
      "Validation\n",
      "Found 148 images belonging to 20 classes.\n",
      "\n",
      "To predict\n",
      "Found 500 images.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "bs = 8\n",
    "img_w = 256\n",
    "img_h = 256\n",
    "validation_split = 0.1\n",
    "\n",
    "classes = [\n",
    "    'owl',              # 0\n",
    "    'galaxy',           # 1\n",
    "    'lightning',        # 2\n",
    "    'wine-bottle',      # 3\n",
    "    't-shirt',          # 4\n",
    "    'waterfall',        # 5\n",
    "    'sword',            # 6\n",
    "    'school-bus',       # 7\n",
    "    'calculator',       # 8\n",
    "    'sheet-music',      # 9\n",
    "    'airplanes',        # 10\n",
    "    'lightbulb',        # 11\n",
    "    'skyscraper',       # 12\n",
    "    'mountain-bike',    # 13\n",
    "    'fireworks',        # 14\n",
    "    'computer-monitor', # 15\n",
    "    'bear',             # 16\n",
    "    'grand-piano',      # 17\n",
    "    'kangaroo',         # 18\n",
    "    'laptop'            # 19\n",
    "]\n",
    "\n",
    "# LOAD TRAINING AND VALIDATION SETS\n",
    "\n",
    "data_gen = ImageDataGenerator(rotation_range = 10,\n",
    "                              width_shift_range = 10,\n",
    "                              height_shift_range = 10,\n",
    "                              zoom_range = 0.3,\n",
    "                              horizontal_flip = True,\n",
    "                              vertical_flip = True,\n",
    "                              rescale = 1./255, \n",
    "                              validation_split = validation_split)\n",
    "\n",
    "training_dir = os.path.join(cwd, \"Classification_Dataset\", \"training\")\n",
    "\n",
    "print(\"Training\")\n",
    "\n",
    "training_generator = data_gen.flow_from_directory(training_dir,\n",
    "                                        batch_size = bs,\n",
    "                                        classes = classes,\n",
    "                                        class_mode = 'categorical',\n",
    "                                        shuffle = True,\n",
    "                                        seed = SEED,\n",
    "                                        subset = 'training')\n",
    "\n",
    "print(\"\\nValidation\")\n",
    "\n",
    "validation_generator = data_gen.flow_from_directory(training_dir,\n",
    "                                        batch_size = bs,\n",
    "                                        classes = classes,\n",
    "                                        class_mode = 'categorical',\n",
    "                                        shuffle = True,\n",
    "                                        seed = SEED,\n",
    "                                        subset = 'validation')\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_generator(lambda: training_generator,\n",
    "                                              output_types = (tf.float32, tf.float32),\n",
    "                                              output_shapes = ([None, img_w, img_h, 3], [None, len(classes)]))\n",
    "validation_dataset = tf.data.Dataset.from_generator(lambda: validation_generator,\n",
    "                                              output_types = (tf.float32, tf.float32),\n",
    "                                              output_shapes = ([None, img_w, img_h, 3], [None, len(classes)]))\n",
    "\n",
    "training_dataset = training_dataset.repeat()\n",
    "validation_dataset = validation_dataset.repeat()\n",
    "\n",
    "# WRITE FILENAMES TO JSON FILE\n",
    "\n",
    "filenames = {\n",
    "    \"training\" : {},\n",
    "    \"validation\" : {}\n",
    "}\n",
    "\n",
    "for c in classes:\n",
    "    filenames[\"training\"][c] = []\n",
    "    filenames[\"validation\"][c] = []\n",
    "    \n",
    "    for fn in training_generator.filenames:\n",
    "        if c in fn:\n",
    "            filenames[\"training\"][c].append(fn.replace(c + \"/\", \"\"))\n",
    "    \n",
    "    for fn in validation_generator.filenames:\n",
    "        if c in fn:\n",
    "            filenames[\"validation\"][c].append(fn.replace(c + \"/\", \"\"))\n",
    "\n",
    "with open('dataset_split.json', 'w') as file:\n",
    "    json.dump(filenames, file, indent=4)\n",
    "    \n",
    "\n",
    "# LOAD TEST SET filenames\n",
    "\n",
    "print(\"\\nTo predict\")\n",
    "\n",
    "test_dir = os.path.join(cwd, \"Classification_Dataset\", \"test\")\n",
    "test_filenames = next(os.walk(test_dir))[2]\n",
    "test_filenames = list(filter(lambda fn: fn[-4:] == '.jpg', test_filenames))\n",
    "\n",
    "print(\"Found \" + str(len(test_filenames)) + \" images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building, fitting and predicting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape, conv_depth, start_num_filters, kernel_size, pool_size, fc_units, num_classes, kernel_regularizer = None):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(conv_depth):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(filters = start_num_filters,\n",
    "                             kernel_size = kernel_size,\n",
    "                             strides = (1, 1),\n",
    "                             padding = 'same',\n",
    "                             activation = 'relu',\n",
    "                             input_shape = input_shape))\n",
    "        else:\n",
    "            model.add(Conv2D(filters = start_num_filters,\n",
    "                             kernel_size = kernel_size,\n",
    "                             strides = (1, 1),\n",
    "                             padding = 'same',\n",
    "                             activation = 'relu'))\n",
    "            \n",
    "        model.add(MaxPool2D(pool_size = pool_size))\n",
    "        start_num_filters *= 2\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for i in range(len(fc_units)):\n",
    "        model.add(Dense(units = fc_units[i], \n",
    "                        activation = 'relu', \n",
    "                        kernel_regularizer = kernel_regularizer))\n",
    "    \n",
    "    model.add(Dense(units = num_classes, \n",
    "                    activation = 'softmax', \n",
    "                    kernel_regularizer = kernel_regularizer))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(model, model_name = datetime.now().strftime('%b%d_%H-%M-%S')):\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # General experiments folder\n",
    "    exps_dir = os.path.join(cwd, 'classification_experiments')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "    \n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    \n",
    "    # This experiment folder\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "    \n",
    "    # Checpoints folder\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    \n",
    "    # Checkpoints callback, best one will be the last saved\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                       save_weights_only=True,\n",
    "                                                       save_best_only=True, \n",
    "                                                       monitor='val_accuracy', \n",
    "                                                       mode = 'max')\n",
    "    \n",
    "    # Tensorboard folder\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "    \n",
    "    # Tensorboard callback\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                                 profile_batch=0,\n",
    "                                                 histogram_freq=1)  # if 1 shows weights histograms\n",
    "    \n",
    "    # Early stopping callback\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                                   patience=20,\n",
    "                                                   mode = 'max')\n",
    "    \n",
    "    callbacks= [ckpt_callback, tb_callback, es_callback]\n",
    "    \n",
    "    model.fit(x=training_dataset,\n",
    "              epochs=100,\n",
    "              steps_per_epoch=len(training_generator),\n",
    "              validation_data=validation_dataset,\n",
    "              validation_steps=len(validation_generator), \n",
    "              callbacks=callbacks)\n",
    "    \n",
    "    # Load best model (last one saved)\n",
    "    latest = tf.train.latest_checkpoint(ckpt_dir)\n",
    "    print(\"Latest model: \" + latest)\n",
    "    model.load_weights(os.path.join(ckpt_dir, latest))\n",
    "    \n",
    "    return (model, exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, exp_dir):\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for image_name in test_filenames:\n",
    "        img = Image.open(os.path.join(test_dir,image_name)).convert('RGB').resize((img_w, img_h))\n",
    "        img_array = np.array(img)\n",
    "        img_array = np.expand_dims(img_array, 0)\n",
    "        img_array = np.divide(img_array,255)\n",
    "        tensor = tf.convert_to_tensor(img_array, dtype = tf.float32)\n",
    "        \n",
    "        prediction = np.argmax(model.predict(tensor))\n",
    "        results[image_name] = prediction\n",
    "\n",
    "    create_csv(results = results, results_dir=exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_1: as seen in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 4,303,460\n",
      "Trainable params: 4,303,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 49s 278ms/step - loss: 2.9091 - accuracy: 0.0932 - val_loss: 2.7470 - val_accuracy: 0.1284\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 46s 264ms/step - loss: 2.6566 - accuracy: 0.1743 - val_loss: 2.4705 - val_accuracy: 0.2635\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 48s 270ms/step - loss: 2.4184 - accuracy: 0.2404 - val_loss: 2.3710 - val_accuracy: 0.2770\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 44s 248ms/step - loss: 2.2187 - accuracy: 0.3065 - val_loss: 2.0683 - val_accuracy: 0.3311\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 2.0257 - accuracy: 0.3627 - val_loss: 2.0919 - val_accuracy: 0.3919\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 1.8869 - accuracy: 0.4054 - val_loss: 1.8476 - val_accuracy: 0.4189\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 43s 244ms/step - loss: 1.7507 - accuracy: 0.4545 - val_loss: 1.8178 - val_accuracy: 0.4324\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 1.5929 - accuracy: 0.4929 - val_loss: 1.7133 - val_accuracy: 0.4595\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 42s 241ms/step - loss: 1.5568 - accuracy: 0.5064 - val_loss: 1.8668 - val_accuracy: 0.3986\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 1.4564 - accuracy: 0.5391 - val_loss: 1.6456 - val_accuracy: 0.4662\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 43s 242ms/step - loss: 1.4543 - accuracy: 0.5519 - val_loss: 1.7438 - val_accuracy: 0.4595\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 43s 246ms/step - loss: 1.3034 - accuracy: 0.5889 - val_loss: 1.4958 - val_accuracy: 0.5676\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 44s 248ms/step - loss: 1.2498 - accuracy: 0.6124 - val_loss: 1.6282 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 1.1873 - accuracy: 0.6330 - val_loss: 1.5082 - val_accuracy: 0.5676\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 1.1158 - accuracy: 0.6565 - val_loss: 1.6930 - val_accuracy: 0.5135\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.1032 - accuracy: 0.6522 - val_loss: 1.6462 - val_accuracy: 0.4730\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 1.0305 - accuracy: 0.6664 - val_loss: 1.4605 - val_accuracy: 0.5946\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 45s 257ms/step - loss: 0.9556 - accuracy: 0.6735 - val_loss: 1.7085 - val_accuracy: 0.5676\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 45s 258ms/step - loss: 0.9341 - accuracy: 0.7006 - val_loss: 1.6849 - val_accuracy: 0.5338\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 45s 258ms/step - loss: 0.8112 - accuracy: 0.7468 - val_loss: 1.5701 - val_accuracy: 0.5270\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 47s 265ms/step - loss: 0.8645 - accuracy: 0.7226 - val_loss: 1.9257 - val_accuracy: 0.4730\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 47s 268ms/step - loss: 0.7766 - accuracy: 0.7518 - val_loss: 1.9539 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 46s 260ms/step - loss: 0.7639 - accuracy: 0.7532 - val_loss: 1.6760 - val_accuracy: 0.5068\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 45s 257ms/step - loss: 0.7693 - accuracy: 0.7468 - val_loss: 1.6980 - val_accuracy: 0.5473\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 0.7310 - accuracy: 0.7582 - val_loss: 1.7496 - val_accuracy: 0.5676\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 47s 265ms/step - loss: 0.6553 - accuracy: 0.7923 - val_loss: 2.2587 - val_accuracy: 0.5338\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 0.6446 - accuracy: 0.7824 - val_loss: 1.9974 - val_accuracy: 0.5405\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.6285 - accuracy: 0.7987 - val_loss: 2.2505 - val_accuracy: 0.5068\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 0.6305 - accuracy: 0.8080 - val_loss: 2.2138 - val_accuracy: 0.5068\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 0.5555 - accuracy: 0.8172 - val_loss: 2.3982 - val_accuracy: 0.5203\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.6043 - accuracy: 0.8137 - val_loss: 2.1700 - val_accuracy: 0.5270\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 43s 245ms/step - loss: 0.4836 - accuracy: 0.8428 - val_loss: 2.2218 - val_accuracy: 0.5541\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 42s 241ms/step - loss: 0.5085 - accuracy: 0.8343 - val_loss: 2.1356 - val_accuracy: 0.5135\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 42s 241ms/step - loss: 0.5110 - accuracy: 0.8279 - val_loss: 2.2120 - val_accuracy: 0.5541\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 42s 240ms/step - loss: 0.4993 - accuracy: 0.8421 - val_loss: 2.3426 - val_accuracy: 0.4797\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 42s 240ms/step - loss: 0.4390 - accuracy: 0.8677 - val_loss: 2.5547 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 42s 240ms/step - loss: 0.4191 - accuracy: 0.8599 - val_loss: 2.1964 - val_accuracy: 0.5068\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_1_Nov20_23-01-06\\ckpts\\cp_17.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_1\"\n",
    "conv_depth = 5\n",
    "start_num_filters = 8\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [512]\n",
    "num_classes = len(classes)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_2: as seen in class + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 4,303,460\n",
      "Trainable params: 4,303,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 3.6555 - accuracy: 0.0953 - val_loss: 3.0336 - val_accuracy: 0.0946\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.8511 - accuracy: 0.1166 - val_loss: 2.9256 - val_accuracy: 0.1216\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.7741 - accuracy: 0.1501 - val_loss: 2.7470 - val_accuracy: 0.1284\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.6950 - accuracy: 0.1686 - val_loss: 2.6644 - val_accuracy: 0.1419\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 45s 256ms/step - loss: 2.6162 - accuracy: 0.2034 - val_loss: 2.5293 - val_accuracy: 0.2365\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 2.5278 - accuracy: 0.2468 - val_loss: 2.5217 - val_accuracy: 0.2230\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.4525 - accuracy: 0.2532 - val_loss: 2.4113 - val_accuracy: 0.2162\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.4009 - accuracy: 0.2980 - val_loss: 2.3755 - val_accuracy: 0.2770\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 2.3341 - accuracy: 0.3001 - val_loss: 2.2431 - val_accuracy: 0.3514\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.3239 - accuracy: 0.3037 - val_loss: 2.2820 - val_accuracy: 0.3243\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.2490 - accuracy: 0.3414 - val_loss: 2.4800 - val_accuracy: 0.3243\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.2095 - accuracy: 0.3677 - val_loss: 2.1975 - val_accuracy: 0.3919\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 2.1268 - accuracy: 0.3855 - val_loss: 2.3122 - val_accuracy: 0.3378\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.0895 - accuracy: 0.3962 - val_loss: 2.1277 - val_accuracy: 0.4122\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.0541 - accuracy: 0.4225 - val_loss: 2.1966 - val_accuracy: 0.4122\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.0546 - accuracy: 0.4310 - val_loss: 2.1351 - val_accuracy: 0.4257\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.9891 - accuracy: 0.4516 - val_loss: 2.3153 - val_accuracy: 0.4392\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.9523 - accuracy: 0.4730 - val_loss: 2.0738 - val_accuracy: 0.4865\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.9167 - accuracy: 0.4744 - val_loss: 2.0532 - val_accuracy: 0.4932\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8842 - accuracy: 0.5028 - val_loss: 2.1231 - val_accuracy: 0.4122\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8600 - accuracy: 0.4865 - val_loss: 2.0460 - val_accuracy: 0.4662\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8132 - accuracy: 0.5220 - val_loss: 2.3096 - val_accuracy: 0.4730\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8401 - accuracy: 0.5178 - val_loss: 2.2290 - val_accuracy: 0.4459\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.8104 - accuracy: 0.5135 - val_loss: 2.1513 - val_accuracy: 0.4459\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.7850 - accuracy: 0.5292 - val_loss: 2.1144 - val_accuracy: 0.4595\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.7341 - accuracy: 0.5413 - val_loss: 1.9929 - val_accuracy: 0.5270\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.7097 - accuracy: 0.5512 - val_loss: 1.9775 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.6960 - accuracy: 0.5477 - val_loss: 2.0953 - val_accuracy: 0.4932\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.6734 - accuracy: 0.5683 - val_loss: 2.1239 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.6947 - accuracy: 0.5590 - val_loss: 2.1378 - val_accuracy: 0.4797\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.6428 - accuracy: 0.5882 - val_loss: 2.0345 - val_accuracy: 0.5203\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.6197 - accuracy: 0.5654 - val_loss: 2.1091 - val_accuracy: 0.4662\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.6154 - accuracy: 0.5846 - val_loss: 2.0825 - val_accuracy: 0.4595\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.6199 - accuracy: 0.5839 - val_loss: 1.8027 - val_accuracy: 0.5405\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.5769 - accuracy: 0.5946 - val_loss: 2.1531 - val_accuracy: 0.4865\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.5971 - accuracy: 0.5925 - val_loss: 1.9421 - val_accuracy: 0.5676\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.5824 - accuracy: 0.5925 - val_loss: 2.1518 - val_accuracy: 0.4797\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.5432 - accuracy: 0.5932 - val_loss: 2.0868 - val_accuracy: 0.4797\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.5563 - accuracy: 0.5775 - val_loss: 2.1136 - val_accuracy: 0.4865\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.5176 - accuracy: 0.6038 - val_loss: 2.1095 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.5354 - accuracy: 0.6095 - val_loss: 1.9282 - val_accuracy: 0.5473\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 1.5249 - accuracy: 0.6074 - val_loss: 2.1732 - val_accuracy: 0.4797\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.4778 - accuracy: 0.6166 - val_loss: 1.9621 - val_accuracy: 0.5676\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4746 - accuracy: 0.6287 - val_loss: 2.1180 - val_accuracy: 0.4932\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.5019 - accuracy: 0.6110 - val_loss: 2.0450 - val_accuracy: 0.5135\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4734 - accuracy: 0.6174 - val_loss: 2.0432 - val_accuracy: 0.4662\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4259 - accuracy: 0.6422 - val_loss: 2.4736 - val_accuracy: 0.4595\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 1.4535 - accuracy: 0.6181 - val_loss: 1.9619 - val_accuracy: 0.5541\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.3787 - accuracy: 0.6415 - val_loss: 2.1634 - val_accuracy: 0.5541\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 1.3837 - accuracy: 0.6430 - val_loss: 2.1950 - val_accuracy: 0.5135\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 44s 249ms/step - loss: 1.3766 - accuracy: 0.6550 - val_loss: 2.3018 - val_accuracy: 0.5338\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4334 - accuracy: 0.6430 - val_loss: 1.8959 - val_accuracy: 0.5270\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 44s 249ms/step - loss: 1.4178 - accuracy: 0.6323 - val_loss: 2.0797 - val_accuracy: 0.5338\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 44s 250ms/step - loss: 1.3697 - accuracy: 0.6643 - val_loss: 1.9166 - val_accuracy: 0.5541\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.3662 - accuracy: 0.6529 - val_loss: 1.9274 - val_accuracy: 0.5608\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.4100 - accuracy: 0.6358 - val_loss: 1.9789 - val_accuracy: 0.5541\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_2_Nov20_23-28-47\\ckpts\\cp_36.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_2\"\n",
    "conv_depth = 5\n",
    "start_num_filters = 8\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [512]\n",
    "num_classes = len(classes)\n",
    "\n",
    "alpha = 0.01\n",
    "kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units, \n",
    "                   kernel_regularizer = kernel_regularizer,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_3: 7 layers, start_num_filters = 4 [REMOVED]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_4: 7 layers, start_num_filters = 4, regularization [REMOVED]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_5: 6 layers, start_num_filters = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 2,501,476\n",
      "Trainable params: 2,501,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 45s 256ms/step - loss: 2.9838 - accuracy: 0.0690 - val_loss: 2.8412 - val_accuracy: 0.1149\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.8148 - accuracy: 0.1110 - val_loss: 2.8153 - val_accuracy: 0.1081\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 2.6576 - accuracy: 0.1479 - val_loss: 2.5510 - val_accuracy: 0.2095\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 2.5211 - accuracy: 0.2027 - val_loss: 2.4197 - val_accuracy: 0.1959\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 2.3724 - accuracy: 0.2546 - val_loss: 2.4009 - val_accuracy: 0.2230\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 2.2760 - accuracy: 0.2809 - val_loss: 2.3923 - val_accuracy: 0.2635\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 2.1928 - accuracy: 0.3065 - val_loss: 2.1146 - val_accuracy: 0.3514\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 2.0702 - accuracy: 0.3578 - val_loss: 2.0326 - val_accuracy: 0.4189\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 1.9805 - accuracy: 0.3826 - val_loss: 2.0510 - val_accuracy: 0.3986\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.9000 - accuracy: 0.3990 - val_loss: 1.9549 - val_accuracy: 0.3986\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.7965 - accuracy: 0.4452 - val_loss: 1.8950 - val_accuracy: 0.3986\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.7187 - accuracy: 0.4502 - val_loss: 1.8447 - val_accuracy: 0.3851\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 1.6715 - accuracy: 0.4680 - val_loss: 1.8762 - val_accuracy: 0.4595\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.5857 - accuracy: 0.4858 - val_loss: 1.8337 - val_accuracy: 0.4392\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 1.4982 - accuracy: 0.5256 - val_loss: 1.7891 - val_accuracy: 0.4189\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 1.5027 - accuracy: 0.5149 - val_loss: 1.8263 - val_accuracy: 0.4324\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 45s 255ms/step - loss: 1.4042 - accuracy: 0.5576 - val_loss: 1.7453 - val_accuracy: 0.4865\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.3626 - accuracy: 0.5733 - val_loss: 1.9205 - val_accuracy: 0.4257\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.2982 - accuracy: 0.5868 - val_loss: 1.6737 - val_accuracy: 0.4865\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.3054 - accuracy: 0.5733 - val_loss: 1.7532 - val_accuracy: 0.4797\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 1.2441 - accuracy: 0.6010 - val_loss: 1.7671 - val_accuracy: 0.4730\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 1.1893 - accuracy: 0.6309 - val_loss: 1.6640 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 1.1361 - accuracy: 0.6188 - val_loss: 1.7287 - val_accuracy: 0.4595\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.1158 - accuracy: 0.6259 - val_loss: 1.7721 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 1.0768 - accuracy: 0.6508 - val_loss: 1.7584 - val_accuracy: 0.5338\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 1.0429 - accuracy: 0.6735 - val_loss: 1.7848 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.0094 - accuracy: 0.6607 - val_loss: 1.9963 - val_accuracy: 0.4932\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 1.0031 - accuracy: 0.6721 - val_loss: 1.7169 - val_accuracy: 0.5203\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 0.9381 - accuracy: 0.6984 - val_loss: 1.7113 - val_accuracy: 0.5608\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.9056 - accuracy: 0.7034 - val_loss: 1.6554 - val_accuracy: 0.5135\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.9110 - accuracy: 0.7155 - val_loss: 1.8202 - val_accuracy: 0.4730\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.8730 - accuracy: 0.7169 - val_loss: 1.7981 - val_accuracy: 0.5135\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.8721 - accuracy: 0.7048 - val_loss: 1.7160 - val_accuracy: 0.5270\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.8349 - accuracy: 0.7105 - val_loss: 1.8651 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.7939 - accuracy: 0.7432 - val_loss: 1.9764 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.7029 - accuracy: 0.7653 - val_loss: 1.9269 - val_accuracy: 0.5135\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 0.7373 - accuracy: 0.7610 - val_loss: 1.8278 - val_accuracy: 0.5676\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.7062 - accuracy: 0.7596 - val_loss: 1.9294 - val_accuracy: 0.4662\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.6755 - accuracy: 0.7760 - val_loss: 1.8987 - val_accuracy: 0.5203\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.6954 - accuracy: 0.7724 - val_loss: 1.8681 - val_accuracy: 0.5676\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.6631 - accuracy: 0.7895 - val_loss: 2.0983 - val_accuracy: 0.4797\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 45s 253ms/step - loss: 0.6510 - accuracy: 0.7774 - val_loss: 1.9891 - val_accuracy: 0.4865\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.6201 - accuracy: 0.7930 - val_loss: 1.7770 - val_accuracy: 0.5135\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.6469 - accuracy: 0.7909 - val_loss: 1.8901 - val_accuracy: 0.5270\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.5802 - accuracy: 0.8073 - val_loss: 2.1137 - val_accuracy: 0.5203\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.6049 - accuracy: 0.8001 - val_loss: 1.7168 - val_accuracy: 0.5203\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.5772 - accuracy: 0.8080 - val_loss: 1.8568 - val_accuracy: 0.5068\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.5277 - accuracy: 0.8321 - val_loss: 2.4065 - val_accuracy: 0.4797\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.5233 - accuracy: 0.8265 - val_loss: 2.0271 - val_accuracy: 0.5270\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.5222 - accuracy: 0.8257 - val_loss: 1.9213 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.4986 - accuracy: 0.8421 - val_loss: 2.2352 - val_accuracy: 0.5270\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 44s 251ms/step - loss: 0.5086 - accuracy: 0.8279 - val_loss: 2.3813 - val_accuracy: 0.4865\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.5084 - accuracy: 0.8321 - val_loss: 2.2214 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.4766 - accuracy: 0.8528 - val_loss: 2.2990 - val_accuracy: 0.5203\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 44s 252ms/step - loss: 0.4883 - accuracy: 0.8329 - val_loss: 2.2449 - val_accuracy: 0.5270\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 44s 253ms/step - loss: 0.4589 - accuracy: 0.8435 - val_loss: 2.0119 - val_accuracy: 0.5270\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 45s 254ms/step - loss: 0.5056 - accuracy: 0.8407 - val_loss: 2.1454 - val_accuracy: 0.4595\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_5_Nov21_00-10-31\\ckpts\\cp_37.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_5\"\n",
    "conv_depth = 6\n",
    "start_num_filters = 8\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [512]\n",
    "num_classes = len(classes)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_6: 6 layers, start_num_filters = 8, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 2,501,476\n",
      "Trainable params: 2,501,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 47s 268ms/step - loss: 3.8180 - accuracy: 0.0754 - val_loss: 2.9566 - val_accuracy: 0.1014\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.8870 - accuracy: 0.1031 - val_loss: 2.8446 - val_accuracy: 0.1284\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 2.8250 - accuracy: 0.1230 - val_loss: 2.7682 - val_accuracy: 0.1216\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.7820 - accuracy: 0.1309 - val_loss: 2.7013 - val_accuracy: 0.1419\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.7217 - accuracy: 0.1408 - val_loss: 2.6878 - val_accuracy: 0.1554\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 2.6855 - accuracy: 0.1515 - val_loss: 2.6591 - val_accuracy: 0.1622\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 2.6357 - accuracy: 0.1693 - val_loss: 2.6431 - val_accuracy: 0.1689\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 2.5869 - accuracy: 0.2084 - val_loss: 2.5924 - val_accuracy: 0.1757\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.4863 - accuracy: 0.2404 - val_loss: 2.4729 - val_accuracy: 0.2568\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 2.4313 - accuracy: 0.2560 - val_loss: 2.5013 - val_accuracy: 0.2162\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 2.3832 - accuracy: 0.2760 - val_loss: 2.4477 - val_accuracy: 0.2365\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 49s 277ms/step - loss: 2.2972 - accuracy: 0.2909 - val_loss: 2.3036 - val_accuracy: 0.2703\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 46s 263ms/step - loss: 2.3105 - accuracy: 0.3058 - val_loss: 2.2529 - val_accuracy: 0.3041\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.2534 - accuracy: 0.3151 - val_loss: 2.3395 - val_accuracy: 0.3243\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 47s 264ms/step - loss: 2.2453 - accuracy: 0.3172 - val_loss: 2.1147 - val_accuracy: 0.3851\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 2.1526 - accuracy: 0.3535 - val_loss: 2.2049 - val_accuracy: 0.3378\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 2.1055 - accuracy: 0.3770 - val_loss: 2.0406 - val_accuracy: 0.4054\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 2.0314 - accuracy: 0.4054 - val_loss: 2.1495 - val_accuracy: 0.3514\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 49s 276ms/step - loss: 2.0179 - accuracy: 0.4083 - val_loss: 2.1311 - val_accuracy: 0.4122\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 48s 271ms/step - loss: 1.9772 - accuracy: 0.4218 - val_loss: 2.0199 - val_accuracy: 0.3919\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 47s 269ms/step - loss: 1.9145 - accuracy: 0.4467 - val_loss: 2.2352 - val_accuracy: 0.3986\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.9081 - accuracy: 0.4445 - val_loss: 2.1233 - val_accuracy: 0.3919\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 47s 267ms/step - loss: 1.8236 - accuracy: 0.4694 - val_loss: 1.9406 - val_accuracy: 0.4392\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 46s 260ms/step - loss: 1.8306 - accuracy: 0.4758 - val_loss: 2.0871 - val_accuracy: 0.4257\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 48s 271ms/step - loss: 1.7502 - accuracy: 0.4922 - val_loss: 2.1833 - val_accuracy: 0.3716\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.7479 - accuracy: 0.5050 - val_loss: 2.0103 - val_accuracy: 0.4392\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 48s 271ms/step - loss: 1.7171 - accuracy: 0.5206 - val_loss: 1.8724 - val_accuracy: 0.4459\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.6559 - accuracy: 0.5391 - val_loss: 1.9603 - val_accuracy: 0.4662\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.6429 - accuracy: 0.5533 - val_loss: 1.9266 - val_accuracy: 0.4122\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 46s 262ms/step - loss: 1.6641 - accuracy: 0.5341 - val_loss: 2.1091 - val_accuracy: 0.4527\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.5960 - accuracy: 0.5498 - val_loss: 1.9251 - val_accuracy: 0.4459\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.5975 - accuracy: 0.5583 - val_loss: 2.2008 - val_accuracy: 0.4392\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.6182 - accuracy: 0.5533 - val_loss: 1.9325 - val_accuracy: 0.4662\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 47s 264ms/step - loss: 1.5398 - accuracy: 0.5797 - val_loss: 1.9839 - val_accuracy: 0.5068\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 48s 272ms/step - loss: 1.5863 - accuracy: 0.5747 - val_loss: 2.0210 - val_accuracy: 0.4730\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 48s 270ms/step - loss: 1.5337 - accuracy: 0.5782 - val_loss: 2.0621 - val_accuracy: 0.4257\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 46s 259ms/step - loss: 1.4787 - accuracy: 0.6074 - val_loss: 1.9683 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 46s 260ms/step - loss: 1.4641 - accuracy: 0.6067 - val_loss: 1.9559 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 46s 261ms/step - loss: 1.4275 - accuracy: 0.6316 - val_loss: 1.7732 - val_accuracy: 0.4730\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.4783 - accuracy: 0.6017 - val_loss: 1.9598 - val_accuracy: 0.4595\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 49s 276ms/step - loss: 1.4090 - accuracy: 0.6145 - val_loss: 1.7292 - val_accuracy: 0.5676\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.4167 - accuracy: 0.6330 - val_loss: 1.8955 - val_accuracy: 0.5608\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.4311 - accuracy: 0.6138 - val_loss: 2.0268 - val_accuracy: 0.4932\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.3521 - accuracy: 0.6430 - val_loss: 1.8189 - val_accuracy: 0.5676\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.3208 - accuracy: 0.6565 - val_loss: 1.8182 - val_accuracy: 0.5338\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.3268 - accuracy: 0.6522 - val_loss: 2.2323 - val_accuracy: 0.5135\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.3518 - accuracy: 0.6501 - val_loss: 1.9879 - val_accuracy: 0.5068\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 49s 277ms/step - loss: 1.3167 - accuracy: 0.6558 - val_loss: 1.7400 - val_accuracy: 0.5878\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.3474 - accuracy: 0.6444 - val_loss: 2.1203 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.2378 - accuracy: 0.6757 - val_loss: 1.9985 - val_accuracy: 0.5203\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 49s 279ms/step - loss: 1.2902 - accuracy: 0.6572 - val_loss: 1.9804 - val_accuracy: 0.5946\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.2561 - accuracy: 0.6686 - val_loss: 2.0657 - val_accuracy: 0.5270\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 49s 277ms/step - loss: 1.2037 - accuracy: 0.6821 - val_loss: 1.9057 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 49s 277ms/step - loss: 1.2087 - accuracy: 0.6892 - val_loss: 1.9795 - val_accuracy: 0.5270\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 47s 266ms/step - loss: 1.2573 - accuracy: 0.6771 - val_loss: 1.8774 - val_accuracy: 0.5743\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.2460 - accuracy: 0.6707 - val_loss: 1.9330 - val_accuracy: 0.5270\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.2558 - accuracy: 0.6728 - val_loss: 1.8554 - val_accuracy: 0.5338\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.2106 - accuracy: 0.6892 - val_loss: 1.8759 - val_accuracy: 0.5878\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1811 - accuracy: 0.6977 - val_loss: 1.9851 - val_accuracy: 0.5608\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1834 - accuracy: 0.7013 - val_loss: 1.8546 - val_accuracy: 0.5270\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.1387 - accuracy: 0.7084 - val_loss: 1.9112 - val_accuracy: 0.6149\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1380 - accuracy: 0.7198 - val_loss: 2.0327 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.1552 - accuracy: 0.7084 - val_loss: 2.2612 - val_accuracy: 0.5135\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1430 - accuracy: 0.7176 - val_loss: 2.0367 - val_accuracy: 0.5473\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.1102 - accuracy: 0.7119 - val_loss: 1.9397 - val_accuracy: 0.5270\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 46s 261ms/step - loss: 1.0949 - accuracy: 0.7276 - val_loss: 1.7657 - val_accuracy: 0.5608\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.1005 - accuracy: 0.7191 - val_loss: 2.1581 - val_accuracy: 0.5608\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.0786 - accuracy: 0.7340 - val_loss: 1.7758 - val_accuracy: 0.5946\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.0812 - accuracy: 0.7454 - val_loss: 1.9042 - val_accuracy: 0.5338\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.0885 - accuracy: 0.7255 - val_loss: 2.0797 - val_accuracy: 0.5743\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.1048 - accuracy: 0.7269 - val_loss: 2.1508 - val_accuracy: 0.5068\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.0725 - accuracy: 0.7404 - val_loss: 1.8255 - val_accuracy: 0.5473\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.0760 - accuracy: 0.7290 - val_loss: 1.9802 - val_accuracy: 0.5676\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 49s 276ms/step - loss: 1.0730 - accuracy: 0.7361 - val_loss: 1.8091 - val_accuracy: 0.5946\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 49s 276ms/step - loss: 1.0546 - accuracy: 0.7404 - val_loss: 1.8101 - val_accuracy: 0.5878\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 48s 274ms/step - loss: 1.0219 - accuracy: 0.7432 - val_loss: 2.1542 - val_accuracy: 0.5270\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.0544 - accuracy: 0.7376 - val_loss: 2.0346 - val_accuracy: 0.5405\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.0331 - accuracy: 0.7440 - val_loss: 2.0019 - val_accuracy: 0.5608\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 48s 275ms/step - loss: 1.0286 - accuracy: 0.7440 - val_loss: 2.2923 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.0482 - accuracy: 0.7390 - val_loss: 1.8332 - val_accuracy: 0.5608\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 48s 273ms/step - loss: 1.0348 - accuracy: 0.7440 - val_loss: 2.1126 - val_accuracy: 0.5743\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_6_Nov21_00-53-02\\ckpts\\cp_61.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_6\"\n",
    "conv_depth = 6\n",
    "start_num_filters = 8\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [512]\n",
    "num_classes = len(classes)\n",
    "\n",
    "alpha = 0.01\n",
    "kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units, \n",
    "                   kernel_regularizer = kernel_regularizer,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_7: as seen in class, start_num_filters = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 8,791,988\n",
      "Trainable params: 8,791,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 99s 562ms/step - loss: 2.8972 - accuracy: 0.0875 - val_loss: 2.7022 - val_accuracy: 0.1081\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 98s 558ms/step - loss: 2.7065 - accuracy: 0.1316 - val_loss: 2.6947 - val_accuracy: 0.1757\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 98s 558ms/step - loss: 2.5516 - accuracy: 0.1949 - val_loss: 2.4172 - val_accuracy: 0.2095\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 98s 558ms/step - loss: 2.3640 - accuracy: 0.2532 - val_loss: 2.3124 - val_accuracy: 0.3041\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 98s 556ms/step - loss: 2.1954 - accuracy: 0.2966 - val_loss: 2.1619 - val_accuracy: 0.3581\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 98s 557ms/step - loss: 2.0998 - accuracy: 0.3471 - val_loss: 2.0640 - val_accuracy: 0.3784\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 1.9812 - accuracy: 0.3841 - val_loss: 2.0952 - val_accuracy: 0.3649\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 98s 557ms/step - loss: 1.9340 - accuracy: 0.3947 - val_loss: 1.9206 - val_accuracy: 0.3851\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 98s 556ms/step - loss: 1.8071 - accuracy: 0.4253 - val_loss: 1.9181 - val_accuracy: 0.3986\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 98s 558ms/step - loss: 1.6721 - accuracy: 0.4765 - val_loss: 1.7081 - val_accuracy: 0.4662\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 97s 551ms/step - loss: 1.5799 - accuracy: 0.5064 - val_loss: 1.7799 - val_accuracy: 0.4459\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 1.4793 - accuracy: 0.5405 - val_loss: 1.8082 - val_accuracy: 0.4662\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 1.4539 - accuracy: 0.5398 - val_loss: 1.6699 - val_accuracy: 0.4662\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 97s 552ms/step - loss: 1.3749 - accuracy: 0.5669 - val_loss: 1.6642 - val_accuracy: 0.4595\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 97s 553ms/step - loss: 1.2682 - accuracy: 0.5967 - val_loss: 1.6936 - val_accuracy: 0.5068\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 97s 548ms/step - loss: 1.2504 - accuracy: 0.5910 - val_loss: 1.6707 - val_accuracy: 0.4730\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 1.1581 - accuracy: 0.6273 - val_loss: 1.8111 - val_accuracy: 0.4392\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 97s 554ms/step - loss: 1.1469 - accuracy: 0.6337 - val_loss: 1.8391 - val_accuracy: 0.5203\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 1.0689 - accuracy: 0.6629 - val_loss: 1.7674 - val_accuracy: 0.5068\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 1.0130 - accuracy: 0.6735 - val_loss: 1.7317 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 96s 547ms/step - loss: 0.9506 - accuracy: 0.6899 - val_loss: 1.7209 - val_accuracy: 0.4932\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 97s 554ms/step - loss: 0.9485 - accuracy: 0.6771 - val_loss: 1.4913 - val_accuracy: 0.5676\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 97s 553ms/step - loss: 0.8763 - accuracy: 0.7134 - val_loss: 1.4843 - val_accuracy: 0.5946\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 0.8764 - accuracy: 0.7105 - val_loss: 1.7341 - val_accuracy: 0.5203\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.8133 - accuracy: 0.7326 - val_loss: 2.0408 - val_accuracy: 0.4595\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.7925 - accuracy: 0.7525 - val_loss: 1.5959 - val_accuracy: 0.5541\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 97s 548ms/step - loss: 0.8010 - accuracy: 0.7368 - val_loss: 1.8813 - val_accuracy: 0.5203\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 0.7249 - accuracy: 0.7667 - val_loss: 1.9638 - val_accuracy: 0.5068\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.7150 - accuracy: 0.7767 - val_loss: 1.9456 - val_accuracy: 0.5405\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.6578 - accuracy: 0.7845 - val_loss: 1.7925 - val_accuracy: 0.5608\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.6361 - accuracy: 0.7916 - val_loss: 1.9528 - val_accuracy: 0.5068\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.6222 - accuracy: 0.8051 - val_loss: 2.0748 - val_accuracy: 0.4932\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 0.5897 - accuracy: 0.8094 - val_loss: 1.9595 - val_accuracy: 0.5473\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.5774 - accuracy: 0.8016 - val_loss: 2.3125 - val_accuracy: 0.5203\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.6123 - accuracy: 0.7959 - val_loss: 1.9707 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.6161 - accuracy: 0.8037 - val_loss: 1.9784 - val_accuracy: 0.5541\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 97s 549ms/step - loss: 0.4835 - accuracy: 0.8457 - val_loss: 1.9426 - val_accuracy: 0.5541\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.5430 - accuracy: 0.8208 - val_loss: 2.0098 - val_accuracy: 0.5608\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.4652 - accuracy: 0.8407 - val_loss: 2.4830 - val_accuracy: 0.5608\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.4825 - accuracy: 0.8563 - val_loss: 2.1359 - val_accuracy: 0.5608\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.4558 - accuracy: 0.8556 - val_loss: 2.2354 - val_accuracy: 0.5473\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.4451 - accuracy: 0.8570 - val_loss: 1.9202 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 97s 550ms/step - loss: 0.4876 - accuracy: 0.8364 - val_loss: 2.1253 - val_accuracy: 0.6216\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.4237 - accuracy: 0.8556 - val_loss: 2.3714 - val_accuracy: 0.5203\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.4422 - accuracy: 0.8506 - val_loss: 2.2115 - val_accuracy: 0.5135\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.4104 - accuracy: 0.8684 - val_loss: 2.4195 - val_accuracy: 0.5135\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.4427 - accuracy: 0.8585 - val_loss: 2.3719 - val_accuracy: 0.5405\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 97s 551ms/step - loss: 0.3387 - accuracy: 0.8805 - val_loss: 2.3236 - val_accuracy: 0.5338\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3951 - accuracy: 0.8777 - val_loss: 2.3652 - val_accuracy: 0.5270\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3985 - accuracy: 0.8670 - val_loss: 2.2349 - val_accuracy: 0.5878\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3297 - accuracy: 0.8947 - val_loss: 2.5815 - val_accuracy: 0.5541\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.3746 - accuracy: 0.8734 - val_loss: 2.5103 - val_accuracy: 0.5135\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 96s 547ms/step - loss: 0.3577 - accuracy: 0.8798 - val_loss: 2.1850 - val_accuracy: 0.5473\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3043 - accuracy: 0.8940 - val_loss: 2.3108 - val_accuracy: 0.5405\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.4345 - accuracy: 0.8649 - val_loss: 2.3146 - val_accuracy: 0.5608\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.3068 - accuracy: 0.9004 - val_loss: 2.3883 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 96s 548ms/step - loss: 0.2962 - accuracy: 0.9040 - val_loss: 2.5287 - val_accuracy: 0.5608\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.2721 - accuracy: 0.9033 - val_loss: 2.5102 - val_accuracy: 0.5203\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 99s 560ms/step - loss: 0.3278 - accuracy: 0.8976 - val_loss: 2.2006 - val_accuracy: 0.5473\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 96s 545ms/step - loss: 0.3719 - accuracy: 0.8777 - val_loss: 2.1357 - val_accuracy: 0.5811\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.2796 - accuracy: 0.9104 - val_loss: 2.3019 - val_accuracy: 0.5946\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 96s 547ms/step - loss: 0.3339 - accuracy: 0.8947 - val_loss: 2.2726 - val_accuracy: 0.5743\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 96s 546ms/step - loss: 0.2582 - accuracy: 0.9189 - val_loss: 2.4863 - val_accuracy: 0.5743\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_7_Nov21_01-58-04\\ckpts\\cp_43.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_7\"\n",
    "conv_depth = 5\n",
    "start_num_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [512]\n",
    "num_classes = len(classes)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_8: as seen in class, start_num_filters = 16, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 4,303,460\n",
      "Trainable params: 4,303,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 3.8077 - accuracy: 0.0896 - val_loss: 2.9401 - val_accuracy: 0.0676\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.9023 - accuracy: 0.1159 - val_loss: 2.7589 - val_accuracy: 0.1486\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 2.7896 - accuracy: 0.1522 - val_loss: 2.6905 - val_accuracy: 0.1622\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.7107 - accuracy: 0.1543 - val_loss: 2.6429 - val_accuracy: 0.1757\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 2.6693 - accuracy: 0.1842 - val_loss: 2.6310 - val_accuracy: 0.1892\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.5683 - accuracy: 0.2119 - val_loss: 2.5806 - val_accuracy: 0.2095\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.5040 - accuracy: 0.2589 - val_loss: 2.4303 - val_accuracy: 0.2703\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.4327 - accuracy: 0.2660 - val_loss: 2.4072 - val_accuracy: 0.2838\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.3503 - accuracy: 0.3001 - val_loss: 2.3053 - val_accuracy: 0.2905\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.2938 - accuracy: 0.2930 - val_loss: 2.3028 - val_accuracy: 0.3311\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 2.2613 - accuracy: 0.3286 - val_loss: 2.1375 - val_accuracy: 0.3851\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 62s 351ms/step - loss: 2.1760 - accuracy: 0.3677 - val_loss: 2.1685 - val_accuracy: 0.3378\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.1641 - accuracy: 0.3784 - val_loss: 2.1020 - val_accuracy: 0.3919\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 62s 351ms/step - loss: 2.1191 - accuracy: 0.4018 - val_loss: 2.2493 - val_accuracy: 0.3716\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 2.0534 - accuracy: 0.4104 - val_loss: 2.0140 - val_accuracy: 0.4122\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.9932 - accuracy: 0.4239 - val_loss: 2.0964 - val_accuracy: 0.3784\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.9565 - accuracy: 0.4559 - val_loss: 2.1893 - val_accuracy: 0.4189\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.9769 - accuracy: 0.4410 - val_loss: 1.9917 - val_accuracy: 0.4189\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.9414 - accuracy: 0.4552 - val_loss: 1.9585 - val_accuracy: 0.4459\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.8828 - accuracy: 0.4858 - val_loss: 2.0643 - val_accuracy: 0.4189\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.9088 - accuracy: 0.4644 - val_loss: 2.0715 - val_accuracy: 0.4054\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.8331 - accuracy: 0.4893 - val_loss: 2.0594 - val_accuracy: 0.4662\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.8597 - accuracy: 0.4772 - val_loss: 1.9616 - val_accuracy: 0.4662\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.8421 - accuracy: 0.4851 - val_loss: 1.9951 - val_accuracy: 0.4122\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7920 - accuracy: 0.4893 - val_loss: 1.9081 - val_accuracy: 0.4527\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7860 - accuracy: 0.4964 - val_loss: 2.0751 - val_accuracy: 0.4324\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.7360 - accuracy: 0.5270 - val_loss: 1.8406 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7421 - accuracy: 0.5320 - val_loss: 1.8984 - val_accuracy: 0.4865\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7370 - accuracy: 0.5263 - val_loss: 1.9804 - val_accuracy: 0.4865\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.7143 - accuracy: 0.5477 - val_loss: 2.0025 - val_accuracy: 0.4730\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.7188 - accuracy: 0.5349 - val_loss: 1.8854 - val_accuracy: 0.4595\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.6967 - accuracy: 0.5647 - val_loss: 1.8538 - val_accuracy: 0.5270\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.7022 - accuracy: 0.5469 - val_loss: 1.9694 - val_accuracy: 0.4797\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.6908 - accuracy: 0.5405 - val_loss: 2.0002 - val_accuracy: 0.4595\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.6438 - accuracy: 0.5533 - val_loss: 2.0161 - val_accuracy: 0.4797\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.6574 - accuracy: 0.5498 - val_loss: 1.9146 - val_accuracy: 0.5068\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.6565 - accuracy: 0.5477 - val_loss: 2.0223 - val_accuracy: 0.4932\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.6532 - accuracy: 0.5526 - val_loss: 1.9164 - val_accuracy: 0.4865\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.5997 - accuracy: 0.5690 - val_loss: 1.9824 - val_accuracy: 0.4932\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.5744 - accuracy: 0.5875 - val_loss: 1.8777 - val_accuracy: 0.5135\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.5906 - accuracy: 0.5939 - val_loss: 1.7965 - val_accuracy: 0.5068\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.5810 - accuracy: 0.5875 - val_loss: 1.8336 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.5206 - accuracy: 0.5974 - val_loss: 1.7289 - val_accuracy: 0.5270\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.5814 - accuracy: 0.5825 - val_loss: 2.1436 - val_accuracy: 0.4527\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4928 - accuracy: 0.5882 - val_loss: 1.8292 - val_accuracy: 0.4865\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 62s 351ms/step - loss: 1.5310 - accuracy: 0.5982 - val_loss: 1.8768 - val_accuracy: 0.4459\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.5234 - accuracy: 0.5946 - val_loss: 1.9163 - val_accuracy: 0.4459\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 1.5213 - accuracy: 0.5789 - val_loss: 1.7765 - val_accuracy: 0.5676\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.5079 - accuracy: 0.6010 - val_loss: 1.8600 - val_accuracy: 0.5203\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.4742 - accuracy: 0.5982 - val_loss: 1.7211 - val_accuracy: 0.5743\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4960 - accuracy: 0.5925 - val_loss: 1.7788 - val_accuracy: 0.5541\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4928 - accuracy: 0.5853 - val_loss: 1.6626 - val_accuracy: 0.5405\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4026 - accuracy: 0.6266 - val_loss: 1.9449 - val_accuracy: 0.5068\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4888 - accuracy: 0.5932 - val_loss: 1.9188 - val_accuracy: 0.4865\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4580 - accuracy: 0.6152 - val_loss: 1.9861 - val_accuracy: 0.4730\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4559 - accuracy: 0.6181 - val_loss: 1.8127 - val_accuracy: 0.5270\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4699 - accuracy: 0.6202 - val_loss: 1.7536 - val_accuracy: 0.5608\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4006 - accuracy: 0.6358 - val_loss: 1.7146 - val_accuracy: 0.5338\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4178 - accuracy: 0.6373 - val_loss: 1.8840 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4248 - accuracy: 0.6273 - val_loss: 1.6822 - val_accuracy: 0.5270\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.4027 - accuracy: 0.6181 - val_loss: 1.8098 - val_accuracy: 0.5338\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3921 - accuracy: 0.6195 - val_loss: 1.8540 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4280 - accuracy: 0.6159 - val_loss: 1.7076 - val_accuracy: 0.5338\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3686 - accuracy: 0.6401 - val_loss: 1.7530 - val_accuracy: 0.5608\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.3591 - accuracy: 0.6430 - val_loss: 1.7438 - val_accuracy: 0.5338\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.3404 - accuracy: 0.6522 - val_loss: 1.9804 - val_accuracy: 0.5135\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3998 - accuracy: 0.6330 - val_loss: 1.7154 - val_accuracy: 0.5068\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 62s 352ms/step - loss: 1.3726 - accuracy: 0.6458 - val_loss: 1.8012 - val_accuracy: 0.5338\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3568 - accuracy: 0.6465 - val_loss: 1.9722 - val_accuracy: 0.5541\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.3060 - accuracy: 0.6358 - val_loss: 1.8379 - val_accuracy: 0.5541\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_8_Nov21_03-40-10\\ckpts\\cp_50.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_8\"\n",
    "conv_depth = 5\n",
    "start_num_filters = 8\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [512]\n",
    "num_classes = len(classes)\n",
    "\n",
    "alpha = 0.01\n",
    "kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units, \n",
    "                   kernel_regularizer = kernel_regularizer,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_9: as seen in class, FC has 2 hidden layers of 256 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 2,266,724\n",
      "Trainable params: 2,266,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 64s 362ms/step - loss: 2.8954 - accuracy: 0.0875 - val_loss: 2.7541 - val_accuracy: 0.1689\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 2.7251 - accuracy: 0.1294 - val_loss: 2.6430 - val_accuracy: 0.1419\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.6129 - accuracy: 0.1679 - val_loss: 2.5526 - val_accuracy: 0.2230\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 2.4453 - accuracy: 0.2162 - val_loss: 2.3719 - val_accuracy: 0.2905\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 2.3246 - accuracy: 0.2518 - val_loss: 2.2042 - val_accuracy: 0.2973\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 2.2635 - accuracy: 0.2774 - val_loss: 2.2870 - val_accuracy: 0.2905\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 2.1219 - accuracy: 0.3179 - val_loss: 2.2069 - val_accuracy: 0.2770\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 2.0564 - accuracy: 0.3492 - val_loss: 2.1044 - val_accuracy: 0.3446\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.9742 - accuracy: 0.3791 - val_loss: 2.0838 - val_accuracy: 0.3378\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.9022 - accuracy: 0.3983 - val_loss: 1.9358 - val_accuracy: 0.3851\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 1.8194 - accuracy: 0.4139 - val_loss: 2.0345 - val_accuracy: 0.3986\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.7637 - accuracy: 0.4381 - val_loss: 2.0052 - val_accuracy: 0.3919\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 1.6987 - accuracy: 0.4644 - val_loss: 1.8636 - val_accuracy: 0.4459\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.6232 - accuracy: 0.4794 - val_loss: 1.7792 - val_accuracy: 0.4054\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 1.5991 - accuracy: 0.4964 - val_loss: 1.6642 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.5248 - accuracy: 0.5220 - val_loss: 1.7828 - val_accuracy: 0.4392\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.4975 - accuracy: 0.5341 - val_loss: 1.8457 - val_accuracy: 0.4392\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 62s 353ms/step - loss: 1.4248 - accuracy: 0.5391 - val_loss: 1.8343 - val_accuracy: 0.4527\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.3669 - accuracy: 0.5683 - val_loss: 1.7407 - val_accuracy: 0.4932\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 1.3145 - accuracy: 0.5825 - val_loss: 1.7698 - val_accuracy: 0.4730\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 1.2694 - accuracy: 0.5832 - val_loss: 1.8082 - val_accuracy: 0.4730\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 1.1855 - accuracy: 0.6060 - val_loss: 1.7753 - val_accuracy: 0.4662\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 1.1841 - accuracy: 0.6273 - val_loss: 1.7687 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 1.1678 - accuracy: 0.6444 - val_loss: 1.5685 - val_accuracy: 0.5541\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.0855 - accuracy: 0.6572 - val_loss: 1.6074 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.1280 - accuracy: 0.6337 - val_loss: 1.6889 - val_accuracy: 0.5270\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.0282 - accuracy: 0.6558 - val_loss: 2.1262 - val_accuracy: 0.4392\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 1.0454 - accuracy: 0.6700 - val_loss: 1.8640 - val_accuracy: 0.4324\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.9873 - accuracy: 0.6707 - val_loss: 1.8557 - val_accuracy: 0.5135\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.9910 - accuracy: 0.6792 - val_loss: 1.7966 - val_accuracy: 0.5338\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 63s 357ms/step - loss: 0.9536 - accuracy: 0.6906 - val_loss: 1.5415 - val_accuracy: 0.5811\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.9990 - accuracy: 0.6835 - val_loss: 1.8048 - val_accuracy: 0.5135\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.9004 - accuracy: 0.6984 - val_loss: 1.7591 - val_accuracy: 0.4865\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.8793 - accuracy: 0.7020 - val_loss: 1.9547 - val_accuracy: 0.4595\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.7820 - accuracy: 0.7383 - val_loss: 1.7685 - val_accuracy: 0.4865\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.7627 - accuracy: 0.7504 - val_loss: 1.9211 - val_accuracy: 0.5203\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.8228 - accuracy: 0.7518 - val_loss: 1.8855 - val_accuracy: 0.5135\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.7787 - accuracy: 0.7440 - val_loss: 1.9532 - val_accuracy: 0.5541\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.7868 - accuracy: 0.7319 - val_loss: 2.1406 - val_accuracy: 0.4865\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.6835 - accuracy: 0.7674 - val_loss: 2.4387 - val_accuracy: 0.4324\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.7488 - accuracy: 0.7440 - val_loss: 2.1358 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.7739 - accuracy: 0.7397 - val_loss: 1.8341 - val_accuracy: 0.5405\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6967 - accuracy: 0.7760 - val_loss: 2.2574 - val_accuracy: 0.5270\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.6321 - accuracy: 0.7937 - val_loss: 1.9529 - val_accuracy: 0.5338\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.5990 - accuracy: 0.7980 - val_loss: 2.2519 - val_accuracy: 0.5338\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.6326 - accuracy: 0.7781 - val_loss: 2.0748 - val_accuracy: 0.5473\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 62s 355ms/step - loss: 0.5799 - accuracy: 0.8101 - val_loss: 2.2722 - val_accuracy: 0.4932\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 63s 356ms/step - loss: 0.5990 - accuracy: 0.8023 - val_loss: 1.9422 - val_accuracy: 0.5338\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.6285 - accuracy: 0.7859 - val_loss: 1.9572 - val_accuracy: 0.4797\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 63s 355ms/step - loss: 0.6475 - accuracy: 0.7930 - val_loss: 2.0712 - val_accuracy: 0.5405\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 62s 354ms/step - loss: 0.5631 - accuracy: 0.8158 - val_loss: 2.2000 - val_accuracy: 0.5135\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_9_Nov21_04-53-07\\ckpts\\cp_31.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_9\"\n",
    "conv_depth = 5\n",
    "start_num_filters = 8\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [256, 256]\n",
    "num_classes = len(classes)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_10: as seen in class, FC has 2 hidden layers of 256 units + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 2,266,724\n",
      "Trainable params: 2,266,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 176 steps, validate for 19 steps\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 72s 410ms/step - loss: 4.1082 - accuracy: 0.0555 - val_loss: 3.1137 - val_accuracy: 0.0676\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.9995 - accuracy: 0.0825 - val_loss: 2.8786 - val_accuracy: 0.0946\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 72s 406ms/step - loss: 2.8607 - accuracy: 0.1053 - val_loss: 2.7642 - val_accuracy: 0.1284\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 2.7790 - accuracy: 0.1131 - val_loss: 2.7221 - val_accuracy: 0.1284\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.7190 - accuracy: 0.1302 - val_loss: 2.7580 - val_accuracy: 0.1757\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.6908 - accuracy: 0.1472 - val_loss: 2.6613 - val_accuracy: 0.1284\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.6493 - accuracy: 0.1550 - val_loss: 2.6194 - val_accuracy: 0.1351\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.6362 - accuracy: 0.1536 - val_loss: 2.6011 - val_accuracy: 0.1892\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.6047 - accuracy: 0.1778 - val_loss: 2.5755 - val_accuracy: 0.1757\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 2.5778 - accuracy: 0.1871 - val_loss: 2.5728 - val_accuracy: 0.1824\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 2.5615 - accuracy: 0.1892 - val_loss: 2.6703 - val_accuracy: 0.1351\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.5405 - accuracy: 0.1885 - val_loss: 2.5831 - val_accuracy: 0.2162\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.5009 - accuracy: 0.2127 - val_loss: 2.6093 - val_accuracy: 0.1959\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 72s 406ms/step - loss: 2.5244 - accuracy: 0.2205 - val_loss: 2.5157 - val_accuracy: 0.2230\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.4603 - accuracy: 0.2454 - val_loss: 2.4528 - val_accuracy: 0.2365\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 2.4580 - accuracy: 0.2404 - val_loss: 2.3659 - val_accuracy: 0.2500\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.4025 - accuracy: 0.2475 - val_loss: 2.4172 - val_accuracy: 0.2432\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 2.3905 - accuracy: 0.2553 - val_loss: 2.4819 - val_accuracy: 0.2432\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.3619 - accuracy: 0.2809 - val_loss: 2.3805 - val_accuracy: 0.2162\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.3211 - accuracy: 0.2888 - val_loss: 2.3392 - val_accuracy: 0.2838\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.3394 - accuracy: 0.2767 - val_loss: 2.2994 - val_accuracy: 0.3108\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.2590 - accuracy: 0.3094 - val_loss: 2.2245 - val_accuracy: 0.2905\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.2398 - accuracy: 0.3186 - val_loss: 2.3079 - val_accuracy: 0.3378\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 2.2199 - accuracy: 0.3400 - val_loss: 2.1431 - val_accuracy: 0.3243\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 2.1954 - accuracy: 0.3421 - val_loss: 2.2113 - val_accuracy: 0.3649\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.1718 - accuracy: 0.3407 - val_loss: 2.0827 - val_accuracy: 0.3446\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.1544 - accuracy: 0.3499 - val_loss: 2.2326 - val_accuracy: 0.3716\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.1211 - accuracy: 0.3720 - val_loss: 2.1279 - val_accuracy: 0.3446\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 2.1300 - accuracy: 0.3691 - val_loss: 2.0824 - val_accuracy: 0.3784\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 2.0635 - accuracy: 0.3876 - val_loss: 2.0209 - val_accuracy: 0.3851\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.0145 - accuracy: 0.4083 - val_loss: 2.0773 - val_accuracy: 0.3243\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 2.0230 - accuracy: 0.3962 - val_loss: 2.1045 - val_accuracy: 0.3581\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.9684 - accuracy: 0.4175 - val_loss: 2.1083 - val_accuracy: 0.3649\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.9525 - accuracy: 0.4211 - val_loss: 2.1473 - val_accuracy: 0.3581\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 1.9771 - accuracy: 0.4111 - val_loss: 1.9989 - val_accuracy: 0.4459\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 1.9264 - accuracy: 0.4374 - val_loss: 1.9534 - val_accuracy: 0.3784\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 72s 406ms/step - loss: 1.8909 - accuracy: 0.4467 - val_loss: 1.9548 - val_accuracy: 0.3851\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.9176 - accuracy: 0.4417 - val_loss: 1.9764 - val_accuracy: 0.3919\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.8773 - accuracy: 0.4403 - val_loss: 1.9307 - val_accuracy: 0.4459\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.8873 - accuracy: 0.4552 - val_loss: 1.9208 - val_accuracy: 0.4122\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.8423 - accuracy: 0.4765 - val_loss: 1.8684 - val_accuracy: 0.4459\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 1.8383 - accuracy: 0.4637 - val_loss: 1.9830 - val_accuracy: 0.4730\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 72s 408ms/step - loss: 1.8024 - accuracy: 0.4616 - val_loss: 2.0260 - val_accuracy: 0.4054\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 73s 417ms/step - loss: 1.8162 - accuracy: 0.4822 - val_loss: 1.9011 - val_accuracy: 0.3986\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 73s 414ms/step - loss: 1.7882 - accuracy: 0.4708 - val_loss: 1.8696 - val_accuracy: 0.4595\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 73s 417ms/step - loss: 1.7680 - accuracy: 0.4829 - val_loss: 1.9727 - val_accuracy: 0.4189\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 74s 419ms/step - loss: 1.7426 - accuracy: 0.4943 - val_loss: 1.9116 - val_accuracy: 0.5135\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 74s 419ms/step - loss: 1.7043 - accuracy: 0.5121 - val_loss: 1.9169 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.7385 - accuracy: 0.4915 - val_loss: 1.9391 - val_accuracy: 0.4730\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.7143 - accuracy: 0.5021 - val_loss: 1.8973 - val_accuracy: 0.5068\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.7163 - accuracy: 0.5092 - val_loss: 1.9723 - val_accuracy: 0.4595\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 1.6708 - accuracy: 0.5220 - val_loss: 1.7557 - val_accuracy: 0.5405\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.6442 - accuracy: 0.5306 - val_loss: 1.8687 - val_accuracy: 0.4595\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 72s 409ms/step - loss: 1.6320 - accuracy: 0.5228 - val_loss: 1.9537 - val_accuracy: 0.4459\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.6369 - accuracy: 0.5484 - val_loss: 2.0100 - val_accuracy: 0.4595\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 72s 409ms/step - loss: 1.6470 - accuracy: 0.5356 - val_loss: 2.0400 - val_accuracy: 0.4459\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 73s 416ms/step - loss: 1.5835 - accuracy: 0.5413 - val_loss: 1.9842 - val_accuracy: 0.4324\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 1.5848 - accuracy: 0.5498 - val_loss: 1.9441 - val_accuracy: 0.5135\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 1.6184 - accuracy: 0.5391 - val_loss: 1.9405 - val_accuracy: 0.4527\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 71s 404ms/step - loss: 1.5441 - accuracy: 0.5477 - val_loss: 1.8794 - val_accuracy: 0.5203\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5809 - accuracy: 0.5576 - val_loss: 1.9734 - val_accuracy: 0.4662\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5753 - accuracy: 0.5469 - val_loss: 1.7964 - val_accuracy: 0.5405\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5617 - accuracy: 0.5576 - val_loss: 2.0551 - val_accuracy: 0.4189\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5429 - accuracy: 0.5519 - val_loss: 2.0688 - val_accuracy: 0.4189\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5050 - accuracy: 0.5846 - val_loss: 1.8669 - val_accuracy: 0.5068\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5527 - accuracy: 0.5640 - val_loss: 1.9348 - val_accuracy: 0.4865\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4778 - accuracy: 0.5925 - val_loss: 1.9028 - val_accuracy: 0.4595\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.5526 - accuracy: 0.5576 - val_loss: 1.9018 - val_accuracy: 0.5135\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.5205 - accuracy: 0.5690 - val_loss: 1.8753 - val_accuracy: 0.5135\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4986 - accuracy: 0.5804 - val_loss: 2.1196 - val_accuracy: 0.4797\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 1.4732 - accuracy: 0.5967 - val_loss: 2.0280 - val_accuracy: 0.5541\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4930 - accuracy: 0.5789 - val_loss: 1.9945 - val_accuracy: 0.4730\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.4670 - accuracy: 0.5747 - val_loss: 1.8194 - val_accuracy: 0.5676\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4382 - accuracy: 0.6074 - val_loss: 1.8923 - val_accuracy: 0.4797\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4673 - accuracy: 0.5861 - val_loss: 1.9488 - val_accuracy: 0.5068\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4361 - accuracy: 0.6017 - val_loss: 2.2256 - val_accuracy: 0.5135\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4172 - accuracy: 0.6110 - val_loss: 1.9147 - val_accuracy: 0.4865\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4180 - accuracy: 0.6110 - val_loss: 1.8859 - val_accuracy: 0.5203\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4245 - accuracy: 0.6124 - val_loss: 1.8321 - val_accuracy: 0.4797\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.4193 - accuracy: 0.6031 - val_loss: 2.1523 - val_accuracy: 0.4662\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 72s 407ms/step - loss: 1.3974 - accuracy: 0.6159 - val_loss: 1.7192 - val_accuracy: 0.5878\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3737 - accuracy: 0.6110 - val_loss: 1.9075 - val_accuracy: 0.5068\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3938 - accuracy: 0.6088 - val_loss: 1.8439 - val_accuracy: 0.5473\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3976 - accuracy: 0.6053 - val_loss: 1.9369 - val_accuracy: 0.4932\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3703 - accuracy: 0.6323 - val_loss: 1.9971 - val_accuracy: 0.5203\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3868 - accuracy: 0.6216 - val_loss: 1.9004 - val_accuracy: 0.5473\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 72s 409ms/step - loss: 1.3503 - accuracy: 0.6287 - val_loss: 1.8992 - val_accuracy: 0.5676\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 72s 406ms/step - loss: 1.3882 - accuracy: 0.6046 - val_loss: 2.0163 - val_accuracy: 0.5068\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3661 - accuracy: 0.6159 - val_loss: 1.8874 - val_accuracy: 0.4865\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3384 - accuracy: 0.6323 - val_loss: 1.9764 - val_accuracy: 0.4730\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3694 - accuracy: 0.6216 - val_loss: 1.8220 - val_accuracy: 0.5270\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3244 - accuracy: 0.6302 - val_loss: 1.7486 - val_accuracy: 0.5270\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3723 - accuracy: 0.6259 - val_loss: 1.8243 - val_accuracy: 0.5135\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3536 - accuracy: 0.6273 - val_loss: 2.2214 - val_accuracy: 0.4932\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 71s 406ms/step - loss: 1.3265 - accuracy: 0.6373 - val_loss: 2.0034 - val_accuracy: 0.4797\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3418 - accuracy: 0.6330 - val_loss: 2.2096 - val_accuracy: 0.5135\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3096 - accuracy: 0.6472 - val_loss: 1.8850 - val_accuracy: 0.5270\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3499 - accuracy: 0.6266 - val_loss: 2.0334 - val_accuracy: 0.4797\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3434 - accuracy: 0.6174 - val_loss: 2.0085 - val_accuracy: 0.4797\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 71s 405ms/step - loss: 1.3082 - accuracy: 0.6358 - val_loss: 2.0868 - val_accuracy: 0.4932\n",
      "Latest model: D:\\Documenti\\GitHub\\A2NDL-HW\\01 - Image Classification\\classification_experiments\\CNN_10_Nov21_05-46-39\\ckpts\\cp_81.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN_10\"\n",
    "conv_depth = 5\n",
    "start_num_filters = 8\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "fc_units = [256, 256]\n",
    "num_classes = len(classes)\n",
    "\n",
    "alpha = 0.01\n",
    "kernel_regularizer = tf.keras.regularizers.l2(alpha)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = build_model(input_shape = (img_w, img_h, 3),\n",
    "                   conv_depth = conv_depth,\n",
    "                   start_num_filters = start_num_filters,\n",
    "                   kernel_size = kernel_size,\n",
    "                   pool_size = pool_size,\n",
    "                   fc_units = fc_units, \n",
    "                   kernel_regularizer = kernel_regularizer,\n",
    "                   num_classes = num_classes)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = loss,\n",
    "             metrics = metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(model, exp_dir) = fit_model(model = model, model_name = model_name)\n",
    "\n",
    "predict(model = model, exp_dir = exp_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
